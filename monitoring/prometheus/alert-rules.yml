# Prometheus Alert Rules for IPA Platform
# Sprint 2 - Story S2-6: Alert Manager Integration

groups:
  - name: ipa_platform_availability
    interval: 30s
    rules:
      # Alert 1: Service Down
      - alert: ServiceDown
        expr: up{job="ipa-platform"} == 0
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "The IPA Platform service has been down for more than 2 minutes."
          runbook_url: "https://docs.ipa-platform.com/runbooks/service-down"

      # Alert 2: High API Error Rate
      - alert: HighAPIErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High API error rate detected"
          description: "API error rate is {{ $value | humanizePercentage }} for service {{ $labels.service }}."

  - name: ipa_platform_performance
    interval: 30s
    rules:
      # Alert 3: High Latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
          ) > 5
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High API latency detected"
          description: "P95 latency is {{ $value }}s for endpoint {{ $labels.endpoint }}."

      # Alert 4: High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (process_resident_memory_bytes / (1024 * 1024 * 1024)) > 2
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanize }}GB for {{ $labels.instance }}."

  - name: ipa_platform_database
    interval: 30s
    rules:
      # Alert 5: Database Connection Pool Exhausted
      - alert: DatabaseConnectionPoolExhausted
        expr: |
          (
            sum(pg_stat_activity_count) by (datname)
            /
            sum(pg_settings_max_connections) by ()
          ) > 0.8
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Database connection pool usage is high"
          description: "Connection pool is {{ $value | humanizePercentage }} full for database {{ $labels.datname }}."

      # Alert 6: Database Slow Queries
      - alert: DatabaseSlowQueries
        expr: |
          rate(pg_stat_statements_seconds_total[5m]) > 1
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Slow database queries detected"
          description: "Average query time is {{ $value }}s."

  - name: ipa_platform_business
    interval: 60s
    rules:
      # Alert 7: Workflow Execution Failures
      - alert: WorkflowExecutionFailures
        expr: |
          (
            sum(rate(workflow_executions_total{status="failed"}[1h])) by (workflow_id)
            /
            sum(rate(workflow_executions_total[1h])) by (workflow_id)
          ) > 0.1
        for: 15m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "High workflow failure rate"
          description: "Workflow {{ $labels.workflow_id }} has {{ $value | humanizePercentage }} failure rate."

      # Alert 8: Checkpoint Approval Timeout
      - alert: CheckpointApprovalTimeout
        expr: |
          count(checkpoint_wait_time_seconds > 3600) > 0
        for: 5m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "Checkpoint approvals pending too long"
          description: "There are checkpoints waiting for approval for more than 1 hour."

      # Alert 9: LLM API High Cost
      - alert: LLMAPICostHigh
        expr: |
          sum(increase(llm_cost_total[1h])) > 100
        for: 5m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "High LLM API cost detected"
          description: "LLM API cost in the last hour is ${{ $value }}."

  - name: ipa_platform_infrastructure
    interval: 30s
    rules:
      # Alert 10: Redis Connection Issues
      - alert: RedisConnectionIssues
        expr: redis_up == 0
        for: 2m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Redis is down"
          description: "Cannot connect to Redis for more than 2 minutes."

      # Alert 11: RabbitMQ Queue Backlog
      - alert: RabbitMQQueueBacklog
        expr: |
          rabbitmq_queue_messages_ready > 1000
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "RabbitMQ queue backlog detected"
          description: "Queue {{ $labels.queue }} has {{ $value }} messages waiting."

      # Alert 12: Disk Space Low
      - alert: DiskSpaceLow
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"}
            /
            node_filesystem_size_bytes{mountpoint="/"}
          ) < 0.1
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Disk space is running low"
          description: "Only {{ $value | humanizePercentage }} disk space remaining on {{ $labels.instance }}."
