# Sprint 2: Integrations & Extensions - Ë©≥Á¥∞Ë¶èÂäÉ

> ‚ÑπÔ∏è **ÈñãÁôºÁ≠ñÁï•**: Êú¨ Sprint ÁπºÁ∫å**Êú¨Âú∞ÂÑ™ÂÖàÈñãÁôº**  
> üê≥ **ÈñãÁôºÁí∞Â¢É**: Docker Compose (ÂÆåÂÖ®Êú¨Âú∞)  
> üîî **ÈÄöÁü•ÊñπÂºè**: Console/Mock Teams Notifications (Phase 1)  
> üìÅ **Êñá‰ª∂Â≠òÂÑ≤**: Êú¨Âú∞Êñá‰ª∂Á≥ªÁµ± (Phase 1) ‚Üí Azure Blob (Phase 2)  
> üí∞ **ÊàêÊú¨**: $0 Azure Ë≤ªÁî®

**ÁâàÊú¨**: 1.1 (Local-First)  
**ÂâµÂª∫Êó•Êúü**: 2025-11-19  
**Êõ¥Êñ∞Êó•Êúü**: 2025-11-20  
**Sprint ÊúüÈñì**: 2025-12-23 Ëá≥ 2026-01-03 (2ÈÄ±)  
**ÂúòÈöäË¶èÊ®°**: 8‰∫∫

**‚ö†Ô∏è Ê≥®ÊÑè**: Ê≠§ Sprint Ë∑®Ë∂äÂÅáÊúüÔºà12/23-1/3ÔºâÔºåÈ†êÊúüÂúòÈöäÂèØÁî®ÊÄßÈôç‰Ωé 30-40%

---

## üìã Sprint ÁõÆÊ®ô

ÂØ¶ÁèæÈóúÈçµÁöÑÂ§ñÈÉ®ÈõÜÊàêÂäüËÉΩÔºåÂåÖÊã¨ n8n Ëß∏ÁôºÂô®„ÄÅTeams ÈÄöÁü•„ÄÅÁõ£ÊéßÈõÜÊàêÂíåÂØ©Ë®àÊó•Ë™åÁ≥ªÁµ±„ÄÇ

### Ê†∏ÂøÉÁõÆÊ®ô
1. ‚úÖ ÈõÜÊàê n8n Webhook Ëß∏ÁôºÂô®
2. ‚úÖ ÂØ¶Áèæ Microsoft Teams ÈÄöÁü•
3. ‚úÖ Âª∫Á´ãÂÆåÊï¥ÁöÑÂØ©Ë®àÊó•Ë™åÁ≥ªÁµ±
4. ‚úÖ ÈõÜÊàêÁõ£ÊéßÂíåÂëäË≠¶Á≥ªÁµ±
5. ‚úÖ ÂØ¶Áèæ Admin Dashboard ÂæåÁ´Ø API

### ÊàêÂäüÊ®ôÊ∫ñ
- n8n ÂèØ‰ª•ÈÄöÈÅé Webhook Ëß∏ÁôºÂ∑•‰ΩúÊµÅ
- Âü∑Ë°åÂ§±Êïó/ÊàêÂäüÊôÇËá™ÂãïÁôºÈÄÅ Teams ÈÄöÁü•
- ÊâÄÊúâÁî®Êà∂Êìç‰ΩúË®òÈåÑÂà∞ÂØ©Ë®àÊó•Ë™å
- Prometheus Êî∂ÈõÜËá™ÂÆöÁæ©Ê•≠ÂãôÊåáÊ®ô
- Admin Dashboard API ËøîÂõûÂØ¶ÊôÇÁµ±Ë®àÊï∏Êìö

---

## üìä Story Points ÂàÜÈÖç

**Á∏ΩË®àÂäÉÈªûÊï∏**: 40  
**ÂÅáÊúüË™øÊï¥**: È†êË®àÂÆåÊàê 28-32 Èªû (70-80%)

**ÊåâÂÑ™ÂÖàÁ¥öÂàÜÈÖç**:
- P0 (Critical): 29 Èªû (73%)
- P1 (High): 11 Èªû (27%)

---

## üéØ Sprint Backlog

### S2-1: n8n Webhook Integration
**Story Points**: 8  
**ÂÑ™ÂÖàÁ¥ö**: P0 - Critical  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 1  
**‰æùË≥¥**: S1-3 (Execution Service)

#### ÊèèËø∞
ÂØ¶Áèæ n8n Webhook Êé•Êî∂Âô®ÔºåÊîØÊåÅ HMAC-SHA256 Á∞ΩÂêçÈ©óË≠âÔºåÂÖÅË®± n8n Â∑•‰ΩúÊµÅËß∏Áôº IPA Âπ≥Âè∞Âü∑Ë°å„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÂØ¶Áèæ POST /api/webhooks/n8n endpoint
- [ ] HMAC-SHA256 Á∞ΩÂêçÈ©óË≠â
- [ ] ÊîØÊåÅËá™ÂÆöÁæ© payload Ëß£Êûê
- [ ] Webhook ‰∫ã‰ª∂Ë®òÈåÑÂà∞ÂØ©Ë®àÊó•Ë™å
- [ ] ÈåØË™§ÊôÇËøîÂõûÊ®ôÊ∫ñÂåñÈüøÊáâ
- [ ] ÊîØÊåÅ webhook Ê∏¨Ë©¶Á´ØÈªû

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

```python
# n8n Webhook Handler
import hmac
import hashlib
from fastapi import Request, HTTPException

class N8nWebhookService:
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
    
    def verify_signature(self, payload: bytes, signature: str) -> bool:
        """È©óË≠â n8n webhook Á∞ΩÂêç"""
        expected_signature = hmac.new(
            self.secret_key.encode(),
            payload,
            hashlib.sha256
        ).hexdigest()
        
        return hmac.compare_digest(signature, expected_signature)
    
    async def handle_webhook(
        self,
        workflow_id: str,
        payload: dict,
        headers: dict
    ) -> dict:
        """ËôïÁêÜ n8n webhook"""
        # ÊèêÂèñËß∏ÁôºÊï∏Êìö
        trigger_data = {
            "source": "n8n",
            "workflow_id": workflow_id,
            "payload": payload,
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # ÂâµÂª∫Âü∑Ë°å
        execution_service = ExecutionService(db)
        execution = execution_service.create_execution(
            workflow_id=workflow_id,
            triggered_by="n8n-webhook",
            trigger_data=trigger_data
        )
        
        return {
            "execution_id": execution.id,
            "status": "started",
            "message": "Workflow execution triggered successfully"
        }

# API Endpoints
@router.post("/api/webhooks/n8n/{workflow_id}")
async def n8n_webhook(
    workflow_id: str,
    request: Request,
    db: Session = Depends(get_db)
):
    """
    Êé•Êî∂ n8n webhook Ëß∏Áôº
    
    Headers:
    - X-N8n-Signature: HMAC-SHA256 Á∞ΩÂêç
    """
    # Áç≤ÂèñË´ãÊ±ÇÈ´î
    body = await request.body()
    payload = await request.json()
    
    # È©óË≠âÁ∞ΩÂêç
    signature = request.headers.get("X-N8n-Signature")
    if not signature:
        raise HTTPException(status_code=401, detail="Missing signature")
    
    webhook_secret = os.getenv("N8N_WEBHOOK_SECRET")
    service = N8nWebhookService(webhook_secret)
    
    if not service.verify_signature(body, signature):
        # Ë®òÈåÑÂ§±ÊïóÁöÑÈ©óË≠âÂòóË©¶
        logger.warning(f"Invalid webhook signature for workflow {workflow_id}")
        raise HTTPException(status_code=401, detail="Invalid signature")
    
    # È©óË≠âÂ∑•‰ΩúÊµÅÂ≠òÂú®
    workflow = db.query(Workflow).filter(Workflow.id == workflow_id).first()
    if not workflow:
        raise HTTPException(status_code=404, detail="Workflow not found")
    
    # ËôïÁêÜ webhook
    result = await service.handle_webhook(
        workflow_id=workflow_id,
        payload=payload,
        headers=dict(request.headers)
    )
    
    # Ë®òÈåÑÂà∞ÂØ©Ë®àÊó•Ë™å
    audit_log = AuditLog(
        action="webhook_received",
        actor="n8n",
        details={
            "workflow_id": workflow_id,
            "execution_id": result["execution_id"]
        }
    )
    db.add(audit_log)
    db.commit()
    
    return result

# Webhook Ê∏¨Ë©¶Á´ØÈªû
@router.post("/api/webhooks/n8n/{workflow_id}/test")
async def test_n8n_webhook(
    workflow_id: str,
    test_payload: dict,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Ê∏¨Ë©¶ webhook (ÁÑ°ÈúÄÁ∞ΩÂêçÈ©óË≠â)"""
    service = N8nWebhookService("")
    result = await service.handle_webhook(
        workflow_id=workflow_id,
        payload=test_payload,
        headers={}
    )
    return {"test_mode": True, **result}
```

```yaml
# n8n Workflow ÈÖçÁΩÆÁ§∫‰æã
nodes:
  - name: "Trigger IPA Workflow"
    type: "n8n-nodes-base.httpRequest"
    parameters:
      method: "POST"
      url: "https://ipa-platform.example.com/api/webhooks/n8n/{{workflow_id}}"
      authentication: "genericCredentialType"
      genericAuthType: "httpHeaderAuth"
      headers:
        X-N8n-Signature: "{{$hmacSha256($binary.data, $env.N8N_WEBHOOK_SECRET)}}"
      bodyParameters:
        parameters:
          - name: "data"
            value: "={{$json}}"
```

#### Â≠ê‰ªªÂãô
1. [ ] ÂØ¶Áèæ N8nWebhookService È°û
2. [ ] ÂØ¶Áèæ HMAC-SHA256 Á∞ΩÂêçÈ©óË≠â
3. [ ] ÂâµÂª∫ webhook Êé•Êî∂ endpoint
4. [ ] ÂâµÂª∫ webhook Ê∏¨Ë©¶ endpoint
5. [ ] ÈõÜÊàêÂØ©Ë®àÊó•Ë™åË®òÈåÑ
6. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶ (Á∞ΩÂêçÈ©óË≠â)
7. [ ] Á∑®ÂØ´ÈõÜÊàêÊ∏¨Ë©¶ (ÂÆåÊï¥ webhook ÊµÅÁ®ã)
8. [ ] ÂâµÂª∫ n8n ÈõÜÊàêÊñáÊ™î

---

### S2-2: n8n Workflow Trigger (Outbound)
**Story Points**: 5  
**ÂÑ™ÂÖàÁ¥ö**: P0 - Critical  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 1  
**‰æùË≥¥**: S2-1

#### ÊèèËø∞
ÂØ¶ÁèæÂæû IPA Âπ≥Âè∞‰∏ªÂãïËß∏Áôº n8n Â∑•‰ΩúÊµÅÁöÑÂäüËÉΩ„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÂØ¶Áèæ n8n API ÂÆ¢Êà∂Á´Ø
- [ ] ÊîØÊåÅËß∏Áôº n8n workflow by ID
- [ ] ÂÇ≥ÈÅûÂü∑Ë°å‰∏ä‰∏ãÊñáÂà∞ n8n
- [ ] ËôïÁêÜ n8n API ÈåØË™§ÂíåÈáçË©¶
- [ ] Ë®òÈåÑËß∏ÁôºÁµêÊûú

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

```python
# n8n Client
class N8nClient:
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.client = httpx.AsyncClient(timeout=30.0)
    
    async def trigger_workflow(
        self,
        workflow_id: str,
        data: dict
    ) -> dict:
        """Ëß∏Áôº n8n Â∑•‰ΩúÊµÅ"""
        url = f"{self.base_url}/webhook/{workflow_id}"
        
        try:
            response = await self.client.post(
                url,
                json=data,
                headers={"X-N8N-API-KEY": self.api_key}
            )
            response.raise_for_status()
            
            return {
                "success": True,
                "status_code": response.status_code,
                "response": response.json()
            }
            
        except httpx.HTTPError as e:
            logger.error(f"Failed to trigger n8n workflow: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_workflow_status(self, execution_id: str) -> dict:
        """Áç≤Âèñ n8n Â∑•‰ΩúÊµÅÂü∑Ë°åÁãÄÊÖã"""
        url = f"{self.base_url}/executions/{execution_id}"
        
        response = await self.client.get(
            url,
            headers={"X-N8N-API-KEY": self.api_key}
        )
        response.raise_for_status()
        
        return response.json()

# API Endpoint
@router.post("/api/workflows/{workflow_id}/trigger-n8n")
async def trigger_n8n_workflow(
    workflow_id: str,
    n8n_workflow_id: str,
    data: dict,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Âæû IPA Ëß∏Áôº n8n Â∑•‰ΩúÊµÅ"""
    n8n_client = N8nClient(
        base_url=os.getenv("N8N_BASE_URL"),
        api_key=os.getenv("N8N_API_KEY")
    )
    
    result = await n8n_client.trigger_workflow(
        workflow_id=n8n_workflow_id,
        data=data
    )
    
    # Ë®òÈåÑÂà∞ÂØ©Ë®àÊó•Ë™å
    audit_log = AuditLog(
        action="n8n_workflow_triggered",
        actor=current_user.email,
        details={
            "ipa_workflow_id": workflow_id,
            "n8n_workflow_id": n8n_workflow_id,
            "success": result["success"]
        }
    )
    db.add(audit_log)
    db.commit()
    
    return result
```

#### Â≠ê‰ªªÂãô
1. [ ] ÂØ¶Áèæ N8nClient È°û
2. [ ] ÂØ¶Áèæ trigger_workflow ÊñπÊ≥ï
3. [ ] ÂØ¶Áèæ get_workflow_status ÊñπÊ≥ï
4. [ ] ÂâµÂª∫Ëß∏Áôº endpoint
5. [ ] ÂØ¶ÁèæÈåØË™§ËôïÁêÜÂíåÈáçË©¶
6. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶
7. [ ] Á∑®ÂØ´ÈõÜÊàêÊ∏¨Ë©¶ (‰ΩøÁî® n8n test instance)

---

### S2-3: Teams Notification Service
**Story Points**: 8  
**ÂÑ™ÂÖàÁ¥ö**: P0 - Critical  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 2  
**‰æùË≥¥**: S1-3 (Execution Service)

#### ÊèèËø∞
ÂØ¶Áèæ Microsoft Teams ÈÄöÁü•ÊúçÂãôÔºåÊîØÊåÅ Adaptive Cards Ê†ºÂºèÂåñÈÄöÁü•„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÂØ¶Áèæ Teams Webhook ÂÆ¢Êà∂Á´Ø
- [ ] ÊîØÊåÅ Adaptive Cards ÈÄöÁü•
- [ ] Âü∑Ë°åÊàêÂäü/Â§±ÊïóËá™ÂãïÈÄöÁü•
- [ ] Checkpoint ÂØ©ÊâπÈÄöÁü•
- [ ] ÊîØÊåÅÈÄöÁü•Ê®°ÊùøÁÆ°ÁêÜ
- [ ] ÈåØË™§ËôïÁêÜÂíåÈáçË©¶

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

```python
# Teams Notification Service
class TeamsNotificationService:
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url
        self.client = httpx.AsyncClient(timeout=10.0)
    
    async def send_notification(
        self,
        title: str,
        message: str,
        color: str = "0078D4",
        facts: List[dict] = None,
        actions: List[dict] = None
    ) -> bool:
        """ÁôºÈÄÅ Teams ÈÄöÁü• (Adaptive Card)"""
        card = {
            "type": "message",
            "attachments": [{
                "contentType": "application/vnd.microsoft.card.adaptive",
                "content": {
                    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                    "type": "AdaptiveCard",
                    "version": "1.4",
                    "body": [
                        {
                            "type": "Container",
                            "style": "emphasis",
                            "items": [
                                {
                                    "type": "TextBlock",
                                    "size": "Large",
                                    "weight": "Bolder",
                                    "text": title,
                                    "wrap": True,
                                    "color": "Accent"
                                }
                            ]
                        },
                        {
                            "type": "TextBlock",
                            "text": message,
                            "wrap": True,
                            "spacing": "Medium"
                        }
                    ]
                }
            }]
        }
        
        # Ê∑ªÂä† Facts (key-value pairs)
        if facts:
            fact_set = {
                "type": "FactSet",
                "facts": facts
            }
            card["attachments"][0]["content"]["body"].append(fact_set)
        
        # Ê∑ªÂä† Actions (buttons)
        if actions:
            card["attachments"][0]["content"]["actions"] = actions
        
        try:
            response = await self.client.post(
                self.webhook_url,
                json=card,
                headers={"Content-Type": "application/json"}
            )
            response.raise_for_status()
            return True
            
        except httpx.HTTPError as e:
            logger.error(f"Failed to send Teams notification: {str(e)}")
            return False
    
    async def send_execution_success(self, execution: Execution):
        """ÁôºÈÄÅÂü∑Ë°åÊàêÂäüÈÄöÁü•"""
        await self.send_notification(
            title="‚úÖ Workflow Execution Successful",
            message=f"Workflow **{execution.workflow.name}** completed successfully",
            color="28A745",
            facts=[
                {"title": "Execution ID", "value": str(execution.id)},
                {"title": "Duration", "value": f"{execution.duration_seconds}s"},
                {"title": "LLM Cost", "value": f"${execution.llm_cost:.4f}"},
                {"title": "Completed At", "value": execution.completed_at.strftime("%Y-%m-%d %H:%M:%S")}
            ],
            actions=[
                {
                    "type": "Action.OpenUrl",
                    "title": "View Details",
                    "url": f"{os.getenv('FRONTEND_URL')}/executions/{execution.id}"
                }
            ]
        )
    
    async def send_execution_failed(self, execution: Execution):
        """ÁôºÈÄÅÂü∑Ë°åÂ§±ÊïóÈÄöÁü•"""
        await self.send_notification(
            title="‚ùå Workflow Execution Failed",
            message=f"Workflow **{execution.workflow.name}** failed with error",
            color="DC3545",
            facts=[
                {"title": "Execution ID", "value": str(execution.id)},
                {"title": "Error", "value": execution.error[:200]},
                {"title": "Failed At", "value": execution.completed_at.strftime("%Y-%m-%d %H:%M:%S")}
            ],
            actions=[
                {
                    "type": "Action.OpenUrl",
                    "title": "View Error Details",
                    "url": f"{os.getenv('FRONTEND_URL')}/executions/{execution.id}"
                },
                {
                    "type": "Action.Http",
                    "title": "Retry Execution",
                    "method": "POST",
                    "url": f"{os.getenv('API_URL')}/api/executions/{execution.id}/retry"
                }
            ]
        )
    
    async def send_checkpoint_approval_request(
        self,
        checkpoint: Checkpoint,
        execution: Execution
    ):
        """ÁôºÈÄÅ Checkpoint ÂØ©ÊâπË´ãÊ±Ç"""
        await self.send_notification(
            title="‚è∏Ô∏è Workflow Approval Required",
            message=f"Workflow **{execution.workflow.name}** is waiting for approval at step {checkpoint.step}",
            color="FFC107",
            facts=[
                {"title": "Execution ID", "value": str(execution.id)},
                {"title": "Step", "value": str(checkpoint.step)},
                {"title": "Proposed Action", "value": checkpoint.state.get("proposed_action", "N/A")}
            ],
            actions=[
                {
                    "type": "Action.Http",
                    "title": "‚úÖ Approve",
                    "method": "POST",
                    "url": f"{os.getenv('API_URL')}/api/checkpoints/{checkpoint.id}/approve"
                },
                {
                    "type": "Action.Http",
                    "title": "‚ùå Reject",
                    "method": "POST",
                    "url": f"{os.getenv('API_URL')}/api/checkpoints/{checkpoint.id}/reject"
                }
            ]
        )

# ÈõÜÊàêÂà∞ Execution Service
class ExecutionService:
    def __init__(self, db: Session):
        self.db = db
        self.teams_service = TeamsNotificationService(
            webhook_url=os.getenv("TEAMS_WEBHOOK_URL")
        )
    
    async def complete_execution(self, execution_id: str, result: dict):
        """ÂÆåÊàêÂü∑Ë°å‰∏¶ÁôºÈÄÅÈÄöÁü•"""
        # ... existing code ...
        
        # ÁôºÈÄÅÊàêÂäüÈÄöÁü•
        await self.teams_service.send_execution_success(execution)
    
    async def fail_execution(self, execution_id: str, error: str):
        """Âü∑Ë°åÂ§±Êïó‰∏¶ÁôºÈÄÅÈÄöÁü•"""
        # ... existing code ...
        
        # ÁôºÈÄÅÂ§±ÊïóÈÄöÁü•
        await self.teams_service.send_execution_failed(execution)
```

#### Â≠ê‰ªªÂãô
1. [ ] ÂØ¶Áèæ TeamsNotificationService È°û
2. [ ] ÂØ¶Áèæ Adaptive Card Ê®°Êùø
3. [ ] ÂØ¶ÁèæÂü∑Ë°åÊàêÂäüÈÄöÁü•
4. [ ] ÂØ¶ÁèæÂü∑Ë°åÂ§±ÊïóÈÄöÁü•
5. [ ] ÂØ¶Áèæ Checkpoint ÂØ©ÊâπÈÄöÁü•
6. [ ] ÈõÜÊàêÂà∞ Execution Service
7. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶
8. [ ] Á∑®ÂØ´ÈõÜÊàêÊ∏¨Ë©¶ (‰ΩøÁî® test webhook)

---

### S2-4: Teams Approval Flow
**Story Points**: 8  
**ÂÑ™ÂÖàÁ¥ö**: P1 - High  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 2  
**‰æùË≥¥**: S2-3

#### ÊèèËø∞
ÂØ¶Áèæ Teams ÂØ©ÊâπÂ∑•‰ΩúÊµÅÔºåÊîØÊåÅÈÄöÈÅé Teams Ê∂àÊÅØÊåâÈàïÈÄ≤Ë°å Checkpoint ÂØ©Êâπ„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÂØ¶ÁèæÂØ©Êâπ/ÊãíÁµï webhook endpoints
- [ ] ÊîØÊåÅÂØ©ÊâπÊÑèË¶ãËº∏ÂÖ•
- [ ] ÂØ©ÊâπÂæåËá™ÂãïÊõ¥Êñ∞Âü∑Ë°åÁãÄÊÖã
- [ ] Ë®òÈåÑÂØ©Êâπ‰∫∫ÂíåÊôÇÈñì
- [ ] ÂØ©ÊâπÁµêÊûúÈÄöÁü•

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

```python
# Checkpoint Approval Endpoints
@router.post("/api/checkpoints/{checkpoint_id}/approve")
async def approve_checkpoint(
    checkpoint_id: str,
    approval_data: CheckpointApprovalRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ÂØ©Êâπ Checkpoint"""
    checkpoint = db.query(Checkpoint).filter(
        Checkpoint.id == checkpoint_id
    ).first()
    
    if not checkpoint:
        raise HTTPException(status_code=404, detail="Checkpoint not found")
    
    if checkpoint.status != "pending_approval":
        raise HTTPException(
            status_code=400,
            detail=f"Checkpoint is already {checkpoint.status}"
        )
    
    # Êõ¥Êñ∞ checkpoint ÁãÄÊÖã
    checkpoint.status = "approved"
    checkpoint.approved_by = current_user.id
    checkpoint.approved_at = datetime.utcnow()
    checkpoint.feedback = approval_data.feedback
    db.commit()
    
    # ÊÅ¢Âæ©Âü∑Ë°å
    execution_service = ExecutionService(db)
    await execution_service.resume_execution(checkpoint.execution_id)
    
    # ÁôºÈÄÅÂØ©ÊâπÁµêÊûúÈÄöÁü•
    teams_service = TeamsNotificationService(os.getenv("TEAMS_WEBHOOK_URL"))
    await teams_service.send_notification(
        title="‚úÖ Checkpoint Approved",
        message=f"Checkpoint at step {checkpoint.step} has been approved by {current_user.name}",
        color="28A745"
    )
    
    return {"message": "Checkpoint approved, execution resumed"}

@router.post("/api/checkpoints/{checkpoint_id}/reject")
async def reject_checkpoint(
    checkpoint_id: str,
    rejection_data: CheckpointRejectionRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ÊãíÁµï Checkpoint"""
    checkpoint = db.query(Checkpoint).filter(
        Checkpoint.id == checkpoint_id
    ).first()
    
    if not checkpoint:
        raise HTTPException(status_code=404, detail="Checkpoint not found")
    
    # Êõ¥Êñ∞ checkpoint ÁãÄÊÖã
    checkpoint.status = "rejected"
    checkpoint.approved_by = current_user.id
    checkpoint.approved_at = datetime.utcnow()
    checkpoint.feedback = rejection_data.reason
    db.commit()
    
    # ÁµÇÊ≠¢Âü∑Ë°å
    execution_service = ExecutionService(db)
    await execution_service.fail_execution(
        checkpoint.execution_id,
        f"Checkpoint rejected by {current_user.name}: {rejection_data.reason}"
    )
    
    # ÁôºÈÄÅÊãíÁµïÈÄöÁü•
    teams_service = TeamsNotificationService(os.getenv("TEAMS_WEBHOOK_URL"))
    await teams_service.send_notification(
        title="‚ùå Checkpoint Rejected",
        message=f"Checkpoint at step {checkpoint.step} has been rejected",
        color="DC3545",
        facts=[
            {"title": "Rejected By", "value": current_user.name},
            {"title": "Reason", "value": rejection_data.reason}
        ]
    )
    
    return {"message": "Checkpoint rejected, execution terminated"}
```

#### Â≠ê‰ªªÂãô
1. [ ] ÂâµÂª∫ CheckpointApprovalRequest schema
2. [ ] ÂØ¶Áèæ approve_checkpoint endpoint
3. [ ] ÂØ¶Áèæ reject_checkpoint endpoint
4. [ ] ÈõÜÊàêÂü∑Ë°åÊÅ¢Âæ©/ÁµÇÊ≠¢ÈÇèËºØ
5. [ ] ÂØ¶ÁèæÂØ©ÊâπÁµêÊûúÈÄöÁü•
6. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶
7. [ ] Á∑®ÂØ´ÈõÜÊàêÊ∏¨Ë©¶

---

### S2-5: Monitoring Integration Service
**Story Points**: 5  
**ÂÑ™ÂÖàÁ¥ö**: P1 - High  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 2  
**‰æùË≥¥**: S0-8 (Monitoring Stack)

#### ÊèèËø∞
ÂØ¶Áèæ OpenTelemetry Ëá™ÂãïÂåñÂÑÄË°®ÊùøÔºåÁÇ∫ÊâÄÊúâÊúçÂãôÊ∑ªÂä†ÂàÜ‰ΩàÂºèËøΩËπ§„ÄÅÊåáÊ®ôÊî∂ÈõÜÂíåÊó•Ë™åÈóúËÅØ„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÊâÄÊúâ API Ë´ãÊ±ÇËá™ÂãïË®òÈåÑ span
- [ ] Ëá™ÂÆöÁæ©Ê•≠ÂãôÊåáÊ®ôÂ∞éÂá∫Âà∞ Prometheus
- [ ] ËøΩËπ§‰∏ä‰∏ãÊñáÂú®ÊúçÂãôÈñìÂÇ≥Êí≠
- [ ] Jaeger UI ÂèØÊü•ÁúãÂÆåÊï¥Ë™øÁî®Èèà
- [ ] ÊåáÊ®ôÂåÖÂê´ÔºöË´ãÊ±ÇÈáè„ÄÅÂª∂ÈÅ≤„ÄÅÈåØË™§Áéá

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

**1. OpenTelemetry SDK Ë®≠ÁΩÆ**

```python
# app/core/telemetry.py
from opentelemetry import trace, metrics
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.exporter.prometheus import PrometheusMetricReader
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from prometheus_client import start_http_server

def setup_telemetry(app):
    # Ë®≠ÁΩÆ Tracer Provider (Jaeger)
    tracer_provider = TracerProvider()
    jaeger_exporter = JaegerExporter(
        agent_host_name=os.getenv("JAEGER_AGENT_HOST", "localhost"),
        agent_port=int(os.getenv("JAEGER_AGENT_PORT", "6831")),
    )
    tracer_provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
    trace.set_tracer_provider(tracer_provider)
    
    # Ë®≠ÁΩÆ Meter Provider (Prometheus)
    start_http_server(port=8001)  # Prometheus metrics endpoint
    meter_provider = MeterProvider(
        metric_readers=[PrometheusMetricReader()]
    )
    metrics.set_meter_provider(meter_provider)
    
    # Ëá™ÂãïÂÑÄË°®Âåñ FastAPI
    FastAPIInstrumentor.instrument_app(app)
    
    # Ëá™ÂãïÂÑÄË°®Âåñ SQLAlchemy
    SQLAlchemyInstrumentor().instrument(
        engine=engine,
        enable_commenter=True,
        commenter_options={"db_framework": "sqlalchemy"}
    )
    
    return tracer_provider, meter_provider
```

**2. Ëá™ÂÆöÁæ©Ê•≠ÂãôÊåáÊ®ô**

```python
# app/services/metrics_service.py
from opentelemetry import metrics

class MetricsService:
    def __init__(self):
        meter = metrics.get_meter(__name__)
        
        # Ë®àÊï∏Âô®ÔºöÂ∑•‰ΩúÊµÅÂü∑Ë°åÊ¨°Êï∏
        self.workflow_executions = meter.create_counter(
            name="workflow_executions_total",
            description="Total number of workflow executions",
            unit="1"
        )
        
        # Áõ¥ÊñπÂúñÔºöÂü∑Ë°åÊôÇÈï∑
        self.execution_duration = meter.create_histogram(
            name="execution_duration_seconds",
            description="Workflow execution duration",
            unit="s"
        )
        
        # Ë®àÊï∏Âô®ÔºöLLM API Ë™øÁî®Ê¨°Êï∏
        self.llm_api_calls = meter.create_counter(
            name="llm_api_calls_total",
            description="Total LLM API calls",
            unit="1"
        )
        
        # Ë®àÊï∏Âô®ÔºöLLM Token ‰ΩøÁî®Èáè
        self.llm_tokens_used = meter.create_counter(
            name="llm_tokens_used_total",
            description="Total LLM tokens consumed",
            unit="tokens"
        )
    
    def record_execution_start(self, workflow_id: str):
        self.workflow_executions.add(
            1, 
            {"workflow_id": workflow_id, "status": "started"}
        )
    
    def record_execution_complete(
        self, 
        workflow_id: str, 
        duration_seconds: float,
        status: str
    ):
        self.execution_duration.record(
            duration_seconds,
            {"workflow_id": workflow_id, "status": status}
        )
        self.workflow_executions.add(
            1,
            {"workflow_id": workflow_id, "status": status}
        )
    
    def record_llm_call(
        self, 
        model: str, 
        tokens_used: int,
        cost: float
    ):
        self.llm_api_calls.add(1, {"model": model})
        self.llm_tokens_used.add(tokens_used, {"model": model})
```

**3. ÊâãÂãï Span ÂâµÂª∫ÔºàË§áÈõúÊ•≠ÂãôÈÇèËºØÔºâ**

```python
# app/services/execution_service.py
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

class ExecutionService:
    async def execute_workflow(self, workflow_id: str):
        with tracer.start_as_current_span("execute_workflow") as span:
            span.set_attribute("workflow_id", workflow_id)
            
            # Â≠ê span: Âä†ËºâÂ∑•‰ΩúÊµÅ
            with tracer.start_as_current_span("load_workflow"):
                workflow = await self.load_workflow(workflow_id)
                span.set_attribute("workflow_version", workflow.version)
            
            # Â≠ê span: Âü∑Ë°åÊ≠•È©ü
            for step in workflow.steps:
                with tracer.start_as_current_span(f"execute_step_{step.order}") as step_span:
                    step_span.set_attribute("step_type", step.type)
                    try:
                        result = await self.execute_step(step)
                        step_span.set_status(trace.Status(trace.StatusCode.OK))
                    except Exception as e:
                        step_span.set_status(
                            trace.Status(trace.StatusCode.ERROR, str(e))
                        )
                        step_span.record_exception(e)
                        raise
```

#### Â≠ê‰ªªÂãô

1. [ ] ÂÆâË£ù OpenTelemetry SDK Âíå exporters
2. [ ] ÈÖçÁΩÆ Tracer Provider (Jaeger)
3. [ ] ÈÖçÁΩÆ Meter Provider (Prometheus)
4. [ ] ÂØ¶Áèæ MetricsService È°û
5. [ ] Âú®ÈóúÈçµÊ•≠ÂãôÈÇèËºØÊ∑ªÂä† span
6. [ ] ÈÖçÁΩÆ Prometheus ÊäìÂèñÁ´ØÈªû
7. [ ] È©óË≠â Jaeger UI È°ØÁ§∫ËøΩËπ§

#### Ê∏¨Ë©¶Ë®àÂäÉ

```python
# tests/integration/test_telemetry.py
import pytest
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter

def test_workflow_execution_creates_spans():
    # Ë®≠ÁΩÆÂÖßÂ≠ò span exporter
    span_exporter = InMemorySpanExporter()
    tracer_provider = TracerProvider()
    tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))
    trace.set_tracer_provider(tracer_provider)
    
    # Âü∑Ë°åÂ∑•‰ΩúÊµÅ
    execution_service = ExecutionService(db)
    await execution_service.execute_workflow("test-workflow-123")
    
    # È©óË≠â spans
    spans = span_exporter.get_finished_spans()
    assert len(spans) > 0
    assert any(s.name == "execute_workflow" for s in spans)
    assert any(s.attributes.get("workflow_id") == "test-workflow-123" for s in spans)
```

---

### S2-6: Alert Manager Integration
**Story Points**: 3  
**ÂÑ™ÂÖàÁ¥ö**: P1 - High  
**Ë≤†Ë≤¨‰∫∫**: DevOps Engineer  
**‰æùË≥¥**: S0-8 (Monitoring Stack), S2-5 (Monitoring Integration)

#### ÊèèËø∞
ÈÖçÁΩÆ Prometheus AlertManagerÔºåË®≠ÁΩÆÈóúÈçµÊåáÊ®ôÁöÑÂëäË≠¶Ë¶èÂâáÔºå‰∏¶ÈõÜÊàêÈÄöÁü•Ê∏†ÈÅìÔºàEmail„ÄÅTeamsÔºâ„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] AlertManager ÈÉ®ÁΩ≤‰∏¶ÈÅãË°å
- [ ] ÈÖçÁΩÆ 5+ ÂëäË≠¶Ë¶èÂâáÔºàÊúçÂãô‰∏ãÁ∑ö„ÄÅÈ´òÈåØË™§ÁéáÁ≠âÔºâ
- [ ] ÂëäË≠¶ÈÄöÁü•ÁôºÈÄÅÂà∞ Teams Âíå Email
- [ ] Grafana È°ØÁ§∫ÂëäË≠¶Ê≠∑Âè≤
- [ ] ÂëäË≠¶Ë¶èÂâáÂèØÈÄöÈÅé ConfigMap Êõ¥Êñ∞

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

**1. Prometheus ÂëäË≠¶Ë¶èÂâá**

```yaml
# k8s/monitoring/prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ipa-platform-alerts
  namespace: monitoring
spec:
  groups:
    - name: ipa_platform
      interval: 30s
      rules:
        # ÂëäË≠¶ 1: API È´òÈåØË™§Áéá
        - alert: HighAPIErrorRate
          expr: |
            rate(http_requests_total{status=~"5.."}[5m]) 
            / 
            rate(http_requests_total[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "High API error rate detected"
            description: "API error rate is {{ $value | humanizePercentage }} for {{ $labels.endpoint }}"
        
        # ÂëäË≠¶ 2: ÊúçÂãô‰∏ãÁ∑ö
        - alert: ServiceDown
          expr: up{job="ipa-platform"} == 0
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Service {{ $labels.instance }} is down"
            description: "Service has been down for more than 2 minutes"
        
        # ÂëäË≠¶ 3: È´òÂª∂ÈÅ≤
        - alert: HighLatency
          expr: |
            histogram_quantile(0.95, 
              rate(http_request_duration_seconds_bucket[5m])
            ) > 5
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High API latency detected"
            description: "P95 latency is {{ $value }}s for {{ $labels.endpoint }}"
        
        # ÂëäË≠¶ 4: Êï∏ÊìöÂ∫´ÈÄ£Êé•Ê±†ËÄóÁõ°
        - alert: DatabaseConnectionPoolExhausted
          expr: |
            (pg_stat_activity_count / pg_settings_max_connections) > 0.8
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Database connection pool usage is high"
            description: "Connection pool is {{ $value | humanizePercentage }} full"
        
        # ÂëäË≠¶ 5: Á£ÅÁõ§Á©∫Èñì‰∏çË∂≥
        - alert: DiskSpaceLow
          expr: |
            (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Disk space is running low"
            description: "Only {{ $value | humanizePercentage }} disk space remaining"
```

**2. AlertManager ÈÖçÁΩÆ**

```yaml
# k8s/monitoring/alertmanager-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'severity']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'teams-notifications'
      routes:
        - match:
            severity: critical
          receiver: 'teams-critical'
          continue: true
        - match:
            severity: warning
          receiver: 'teams-warnings'
    
    receivers:
      - name: 'teams-critical'
        webhook_configs:
          - url: 'http://prometheus-msteams:2000/alertmanager'
            send_resolved: true
      
      - name: 'teams-warnings'
        webhook_configs:
          - url: 'http://prometheus-msteams:2000/alertmanager-warnings'
            send_resolved: true
      
      - name: 'teams-notifications'
        webhook_configs:
          - url: 'http://prometheus-msteams:2000/alertmanager'
            send_resolved: true
```

**3. Prometheus-MSTeams ÈÉ®ÁΩ≤**

```yaml
# k8s/monitoring/prometheus-msteams.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-msteams
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-msteams
  template:
    metadata:
      labels:
        app: prometheus-msteams
    spec:
      containers:
        - name: prometheus-msteams
          image: bzon/prometheus-msteams:v1.5.1
          ports:
            - containerPort: 2000
          env:
            - name: TEAMS_INCOMING_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: teams-webhook-secret
                  key: webhook_url
            - name: TEAMS_REQUEST_URI
              value: "alertmanager"
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus-msteams
  namespace: monitoring
spec:
  selector:
    app: prometheus-msteams
  ports:
    - port: 2000
      targetPort: 2000
```

#### Â≠ê‰ªªÂãô

1. [ ] ÂâµÂª∫ Prometheus ÂëäË≠¶Ë¶èÂâá
2. [ ] ÈÉ®ÁΩ≤ AlertManager
3. [ ] ÈÖçÁΩÆ AlertManager Ë∑ØÁî±
4. [ ] ÈÉ®ÁΩ≤ prometheus-msteams
5. [ ] Ê∏¨Ë©¶ÂëäË≠¶Ëß∏ÁôºÂíåÈÄöÁü•
6. [ ] Âú® Grafana Ê∑ªÂä†ÂëäË≠¶Èù¢Êùø

#### Ê∏¨Ë©¶Ë®àÂäÉ

- ÊâãÂãïËß∏ÁôºÂëäË≠¶Ôºà‰æãÂ¶ÇÔºöÂÅúÊ≠¢ÊúçÂãôÔºâ
- È©óË≠â Teams Êî∂Âà∞ÈÄöÁü•
- È©óË≠âÂëäË≠¶Ëß£Ê±∫ÂæåÊî∂Âà∞ÊÅ¢Âæ©ÈÄöÁü•
- Ê∏¨Ë©¶‰∏çÂêå severity Á¥öÂà•ÁöÑË∑ØÁî±

---

### S2-7: Audit Log Service
**Story Points**: 5  
**ÂÑ™ÂÖàÁ¥ö**: P0 - Critical  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 1  
**‰æùË≥¥**: S0-4 (Database), S0-9 (Logging Infrastructure)

#### ÊèèËø∞
ÂØ¶ÁèæÂÆåÊï¥ÁöÑÂØ©Ë®àÊó•Ë™åÁ≥ªÁµ±ÔºåË®òÈåÑÊâÄÊúâÁî®Êà∂Êìç‰Ωú„ÄÅAPI Ë™øÁî®„ÄÅÂ∑•‰ΩúÊµÅËÆäÊõ¥Á≠âÔºåÁî®ÊñºÂêàË¶èÊÄßÂíåÂÆâÂÖ®ÂØ©Ë®à„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] ÊâÄÊúâ API Ë´ãÊ±ÇË®òÈåÑÂà∞ÂØ©Ë®àÊó•Ë™å
- [ ] Êó•Ë™åÂåÖÂê´ÔºöÁî®Êà∂„ÄÅÊôÇÈñìÊà≥„ÄÅÊìç‰Ωú„ÄÅË≥áÊ∫ê„ÄÅIP„ÄÅÁµêÊûú
- [ ] ÂØ©Ë®àÊó•Ë™å‰∏çÂèØÂà™Èô§ÔºàÂè™ËÉΩÊ®ôË®òÁÇ∫Â∑≤Ê≠∏Ê™îÔºâ
- [ ] Êèê‰æõÂØ©Ë®àÊó•Ë™åÊü•Ë©¢ API
- [ ] Êó•Ë™åËá™ÂãïËº™ËΩâÔºà‰øùÁïô 1 Âπ¥Ôºâ

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

**1. ÂØ©Ë®àÊó•Ë™åÊï∏ÊìöÊ®°Âûã**

```python
# app/models/audit_log.py
from sqlalchemy import Column, String, DateTime, JSON, Text, Index
from sqlalchemy.dialects.postgresql import UUID
from app.db.base_class import Base
import uuid
from datetime import datetime

class AuditLog(Base):
    __tablename__ = "audit_logs"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    
    # Áî®Êà∂‰ø°ÊÅØ
    user_id = Column(UUID(as_uuid=True), nullable=False, index=True)
    user_email = Column(String(255), nullable=False)
    
    # Êìç‰Ωú‰ø°ÊÅØ
    action = Column(String(100), nullable=False, index=True)  # CREATE, UPDATE, DELETE, EXECUTE
    resource_type = Column(String(50), nullable=False, index=True)  # workflow, execution, agent
    resource_id = Column(String(255), nullable=True, index=True)
    
    # Ë´ãÊ±Ç‰ø°ÊÅØ
    method = Column(String(10), nullable=False)  # GET, POST, PUT, DELETE
    endpoint = Column(String(500), nullable=False)
    request_body = Column(JSON, nullable=True)
    response_status = Column(Integer, nullable=False)
    
    # ‰∏ä‰∏ãÊñá‰ø°ÊÅØ
    ip_address = Column(String(45), nullable=False)  # IPv6 support
    user_agent = Column(Text, nullable=True)
    request_id = Column(String(100), nullable=True, index=True)
    
    # ËÆäÊõ¥‰ø°ÊÅØ
    old_values = Column(JSON, nullable=True)
    new_values = Column(JSON, nullable=True)
    
    # ÊôÇÈñìÊà≥
    timestamp = Column(DateTime, nullable=False, default=datetime.utcnow, index=True)
    
    # ËªüÂà™Èô§ÔºàÂØ©Ë®àÊó•Ë™å‰∏çÂèØÁúüÊ≠£Âà™Èô§Ôºâ
    archived = Column(Boolean, default=False, index=True)
    archived_at = Column(DateTime, nullable=True)
    
    __table_args__ = (
        Index('idx_audit_user_time', 'user_id', 'timestamp'),
        Index('idx_audit_resource_time', 'resource_type', 'resource_id', 'timestamp'),
    )
```

**2. ÂØ©Ë®àÊó•Ë™åÊúçÂãô**

```python
# app/services/audit_service.py
from app.models.audit_log import AuditLog
from sqlalchemy.orm import Session
from fastapi import Request
import json

class AuditService:
    def __init__(self, db: Session):
        self.db = db
    
    async def log_api_call(
        self,
        request: Request,
        user_id: str,
        user_email: str,
        action: str,
        resource_type: str,
        resource_id: str = None,
        request_body: dict = None,
        response_status: int = 200,
        old_values: dict = None,
        new_values: dict = None
    ):
        audit_log = AuditLog(
            user_id=user_id,
            user_email=user_email,
            action=action,
            resource_type=resource_type,
            resource_id=resource_id,
            method=request.method,
            endpoint=str(request.url),
            request_body=request_body,
            response_status=response_status,
            ip_address=request.client.host,
            user_agent=request.headers.get("user-agent"),
            request_id=request.headers.get("x-request-id"),
            old_values=old_values,
            new_values=new_values
        )
        
        self.db.add(audit_log)
        self.db.commit()
        
        return audit_log
    
    def query_logs(
        self,
        user_id: str = None,
        resource_type: str = None,
        resource_id: str = None,
        action: str = None,
        start_time: datetime = None,
        end_time: datetime = None,
        limit: int = 100,
        offset: int = 0
    ):
        query = self.db.query(AuditLog).filter(AuditLog.archived == False)
        
        if user_id:
            query = query.filter(AuditLog.user_id == user_id)
        if resource_type:
            query = query.filter(AuditLog.resource_type == resource_type)
        if resource_id:
            query = query.filter(AuditLog.resource_id == resource_id)
        if action:
            query = query.filter(AuditLog.action == action)
        if start_time:
            query = query.filter(AuditLog.timestamp >= start_time)
        if end_time:
            query = query.filter(AuditLog.timestamp <= end_time)
        
        total = query.count()
        logs = query.order_by(AuditLog.timestamp.desc()).offset(offset).limit(limit).all()
        
        return {"total": total, "logs": logs}
```

**3. FastAPI MiddlewareÔºàËá™ÂãïÂØ©Ë®àÔºâ**

```python
# app/middleware/audit_middleware.py
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware
import json
import time

class AuditMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # Ë∑≥ÈÅéÂÅ•Â∫∑Ê™¢Êü•ÂíåÈùúÊÖãÊñá‰ª∂
        if request.url.path in ["/health", "/metrics"]:
            return await call_next(request)
        
        # Ë®òÈåÑË´ãÊ±ÇÊôÇÈñì
        start_time = time.time()
        
        # ËÆÄÂèñË´ãÊ±Ç bodyÔºàÈúÄË¶ÅÁ∑©Â≠òÔºâ
        body = None
        if request.method in ["POST", "PUT", "PATCH"]:
            body = await request.body()
            request._body = body  # Á∑©Â≠ò‰æõÂæåÁ∫å‰ΩøÁî®
        
        # ËôïÁêÜË´ãÊ±Ç
        response = await call_next(request)
        
        # Ë®àÁÆóËôïÁêÜÊôÇÈñì
        process_time = time.time() - start_time
        
        # Ë®òÈåÑÂØ©Ë®àÊó•Ë™åÔºàÁï∞Ê≠•Ôºå‰∏çÈòªÂ°ûÈüøÊáâÔºâ
        if hasattr(request.state, "user"):
            user = request.state.user
            audit_service = AuditService(request.state.db)
            
            # Ëß£Êûê action Âíå resource
            action, resource_type = self._parse_endpoint(request.method, request.url.path)
            
            await audit_service.log_api_call(
                request=request,
                user_id=user.id,
                user_email=user.email,
                action=action,
                resource_type=resource_type,
                request_body=json.loads(body) if body else None,
                response_status=response.status_code
            )
        
        return response
    
    def _parse_endpoint(self, method: str, path: str):
        # Ê†πÊìö method Âíå path Êé®Êñ∑ action Âíå resource_type
        if "workflows" in path:
            resource_type = "workflow"
            if method == "POST":
                action = "CREATE"
            elif method == "PUT" or method == "PATCH":
                action = "UPDATE"
            elif method == "DELETE":
                action = "DELETE"
            else:
                action = "READ"
        elif "executions" in path:
            resource_type = "execution"
            action = "EXECUTE" if method == "POST" else "READ"
        # ... ÂÖ∂‰ªñË≥áÊ∫êÈ°ûÂûã
        else:
            resource_type = "unknown"
            action = method
        
        return action, resource_type
```

**4. ÂØ©Ë®àÊó•Ë™å API**

```python
# app/api/v1/audit_logs.py
from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session
from app.api.deps import get_db, get_current_user
from app.services.audit_service import AuditService
from datetime import datetime

router = APIRouter()

@router.get("/api/audit-logs/")
async def list_audit_logs(
    user_id: str = Query(None),
    resource_type: str = Query(None),
    resource_id: str = Query(None),
    action: str = Query(None),
    start_time: datetime = Query(None),
    end_time: datetime = Query(None),
    limit: int = Query(100, le=500),
    offset: int = Query(0),
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    # Âè™ÊúâÁÆ°ÁêÜÂì°ÂèØ‰ª•Êü•ÁúãÊâÄÊúâÁî®Êà∂ÁöÑÊó•Ë™å
    if not current_user.is_admin and user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Forbidden")
    
    audit_service = AuditService(db)
    result = audit_service.query_logs(
        user_id=user_id or current_user.id,
        resource_type=resource_type,
        resource_id=resource_id,
        action=action,
        start_time=start_time,
        end_time=end_time,
        limit=limit,
        offset=offset
    )
    
    return result

@router.get("/api/audit-logs/{log_id}")
async def get_audit_log(
    log_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    audit_service = AuditService(db)
    log = db.query(AuditLog).filter(AuditLog.id == log_id).first()
    
    if not log:
        raise HTTPException(status_code=404, detail="Audit log not found")
    
    # Âè™ÊúâÁÆ°ÁêÜÂì°ÊàñÊó•Ë™åÊâÄÊúâËÄÖÂèØ‰ª•Êü•Áúã
    if not current_user.is_admin and log.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Forbidden")
    
    return log
```

#### Â≠ê‰ªªÂãô

1. [ ] ÂâµÂª∫ AuditLog Êï∏ÊìöÊ®°ÂûãÂíåÈÅ∑Áßª
2. [ ] ÂØ¶Áèæ AuditService
3. [ ] ÂâµÂª∫ AuditMiddleware
4. [ ] ÂØ¶ÁèæÂØ©Ë®àÊó•Ë™åÊü•Ë©¢ API
5. [ ] ÈÖçÁΩÆÊó•Ë™åËº™ËΩâÔºàPostgreSQL partitioningÔºâ
6. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶
7. [ ] Á∑®ÂØ´ÈõÜÊàêÊ∏¨Ë©¶

#### Ê∏¨Ë©¶Ë®àÂäÉ

```python
# tests/integration/test_audit_logs.py
def test_api_call_creates_audit_log(client, db, test_user):
    # ÂâµÂª∫Â∑•‰ΩúÊµÅ
    response = client.post(
        "/api/workflows/",
        json={"name": "Test Workflow"},
        headers={"Authorization": f"Bearer {test_user.token}"}
    )
    
    assert response.status_code == 201
    
    # È©óË≠âÂØ©Ë®àÊó•Ë™å
    audit_log = db.query(AuditLog).filter(
        AuditLog.user_id == test_user.id,
        AuditLog.action == "CREATE",
        AuditLog.resource_type == "workflow"
    ).first()
    
    assert audit_log is not None
    assert audit_log.method == "POST"
    assert "workflows" in audit_log.endpoint
    assert audit_log.response_status == 201
```

---

### S2-8: Admin Dashboard APIs
**Story Points**: 5  
**ÂÑ™ÂÖàÁ¥ö**: P1 - High  
**Ë≤†Ë≤¨‰∫∫**: Backend Engineer 2  
**‰æùË≥¥**: S1-1 (Workflow Service), S1-3 (Execution Service)

#### ÊèèËø∞
ÂâµÂª∫ Admin Dashboard ÊâÄÈúÄÁöÑÂæåÁ´Ø REST APIÔºåÊèê‰æõÁµ±Ë®àÊï∏Êìö„ÄÅÂØ¶ÊôÇÊåáÊ®ô„ÄÅÁî®Êà∂ÁÆ°ÁêÜÁ≠âÂäüËÉΩ„ÄÇ

#### È©óÊî∂Ê®ôÊ∫ñ
- [ ] Áµ±Ë®à API ËøîÂõûÂ∑•‰ΩúÊµÅ/Âü∑Ë°åÊï∏Èáè
- [ ] ÂØ¶ÊôÇÊåáÊ®ô API ËøîÂõûÁï∂ÂâçÈÅãË°åÁãÄÊÖã
- [ ] Áî®Êà∂ÁÆ°ÁêÜ API ÊîØÊåÅ CRUD
- [ ] Á≥ªÁµ±ÂÅ•Â∫∑ÁãÄÊÖã API
- [ ] ÊâÄÊúâ API ÊúâÈÅ©Áï∂ÁöÑÁ∑©Â≠òÁ≠ñÁï•

#### ÊäÄË°ìÂØ¶ÁèæÁ¥∞ÁØÄ

**1. Áµ±Ë®àÊï∏Êìö API**

```python
# app/api/v1/admin/statistics.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from sqlalchemy import func
from app.api.deps import get_db, require_admin
from app.models.workflow import Workflow
from app.models.execution import Execution
from datetime import datetime, timedelta
from app.core.cache import cache

router = APIRouter()

@router.get("/api/admin/statistics/overview")
@cache(expire=60)  # Á∑©Â≠ò 1 ÂàÜÈêò
async def get_overview_statistics(
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    # Â∑•‰ΩúÊµÅÁµ±Ë®à
    total_workflows = db.query(func.count(Workflow.id)).scalar()
    active_workflows = db.query(func.count(Workflow.id)).filter(
        Workflow.is_active == True
    ).scalar()
    
    # Âü∑Ë°åÁµ±Ë®à
    total_executions = db.query(func.count(Execution.id)).scalar()
    successful_executions = db.query(func.count(Execution.id)).filter(
        Execution.status == "completed"
    ).scalar()
    failed_executions = db.query(func.count(Execution.id)).filter(
        Execution.status == "failed"
    ).scalar()
    
    # ‰ªäÊó•Âü∑Ë°å
    today = datetime.utcnow().date()
    today_executions = db.query(func.count(Execution.id)).filter(
        func.date(Execution.created_at) == today
    ).scalar()
    
    # ÊàêÂäüÁéá
    success_rate = (successful_executions / total_executions * 100) if total_executions > 0 else 0
    
    return {
        "workflows": {
            "total": total_workflows,
            "active": active_workflows
        },
        "executions": {
            "total": total_executions,
            "successful": successful_executions,
            "failed": failed_executions,
            "today": today_executions,
            "success_rate": round(success_rate, 2)
        }
    }

@router.get("/api/admin/statistics/trend")
@cache(expire=300)  # Á∑©Â≠ò 5 ÂàÜÈêò
async def get_execution_trend(
    days: int = 7,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    # ÈÅéÂéª N Â§©ÁöÑÂü∑Ë°åË∂®Âã¢
    start_date = datetime.utcnow() - timedelta(days=days)
    
    trend_data = db.query(
        func.date(Execution.created_at).label("date"),
        func.count(Execution.id).label("total"),
        func.sum(case((Execution.status == "completed", 1), else_=0)).label("successful"),
        func.sum(case((Execution.status == "failed", 1), else_=0)).label("failed")
    ).filter(
        Execution.created_at >= start_date
    ).group_by(
        func.date(Execution.created_at)
    ).order_by(
        func.date(Execution.created_at)
    ).all()
    
    return {
        "period": f"Last {days} days",
        "data": [
            {
                "date": str(row.date),
                "total": row.total,
                "successful": row.successful,
                "failed": row.failed
            }
            for row in trend_data
        ]
    }
```

**2. ÂØ¶ÊôÇÊåáÊ®ô API**

```python
# app/api/v1/admin/metrics.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.api.deps import get_db, require_admin
from app.models.execution import Execution

router = APIRouter()

@router.get("/api/admin/metrics/realtime")
async def get_realtime_metrics(
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    # Áï∂ÂâçÈÅãË°å‰∏≠ÁöÑÂü∑Ë°å
    running_executions = db.query(Execution).filter(
        Execution.status == "running"
    ).all()
    
    # ÂæÖËôïÁêÜÁöÑÂü∑Ë°å
    pending_executions = db.query(func.count(Execution.id)).filter(
        Execution.status == "pending"
    ).scalar()
    
    # ÈÅéÂéª 5 ÂàÜÈêòÁöÑÂü∑Ë°å
    five_minutes_ago = datetime.utcnow() - timedelta(minutes=5)
    recent_executions = db.query(func.count(Execution.id)).filter(
        Execution.created_at >= five_minutes_ago
    ).scalar()
    
    # Âπ≥ÂùáÂü∑Ë°åÊôÇÈï∑ÔºàÈÅéÂéª 1 Â∞èÊôÇÔºâ
    one_hour_ago = datetime.utcnow() - timedelta(hours=1)
    avg_duration = db.query(
        func.avg(Execution.duration_seconds)
    ).filter(
        Execution.completed_at >= one_hour_ago,
        Execution.status == "completed"
    ).scalar()
    
    return {
        "running_executions": len(running_executions),
        "pending_executions": pending_executions,
        "recent_executions": recent_executions,
        "average_duration_seconds": round(avg_duration, 2) if avg_duration else None,
        "active_workflows": [
            {
                "execution_id": ex.id,
                "workflow_id": ex.workflow_id,
                "started_at": ex.started_at,
                "current_step": ex.current_step
            }
            for ex in running_executions
        ]
    }
```

**3. Á≥ªÁµ±ÂÅ•Â∫∑ÁãÄÊÖã API**

```python
# app/api/v1/admin/health.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.api.deps import get_db
from app.core.config import settings
import redis
import psutil
import requests

router = APIRouter()

@router.get("/api/admin/health")
async def get_system_health(db: Session = Depends(get_db)):
    health_status = {
        "status": "healthy",
        "components": {}
    }
    
    # Ê™¢Êü•Êï∏ÊìöÂ∫´
    try:
        db.execute("SELECT 1")
        health_status["components"]["database"] = {
            "status": "up",
            "type": "PostgreSQL"
        }
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["components"]["database"] = {
            "status": "down",
            "error": str(e)
        }
    
    # Ê™¢Êü• Redis
    try:
        redis_client = redis.from_url(settings.REDIS_URL)
        redis_client.ping()
        health_status["components"]["redis"] = {
            "status": "up",
            "type": "Redis"
        }
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["components"]["redis"] = {
            "status": "down",
            "error": str(e)
        }
    
    # Ê™¢Êü• RabbitMQ
    try:
        response = requests.get(
            f"{settings.RABBITMQ_URL}/api/healthchecks/node",
            auth=(settings.RABBITMQ_USER, settings.RABBITMQ_PASS),
            timeout=5
        )
        if response.status_code == 200:
            health_status["components"]["rabbitmq"] = {
                "status": "up",
                "type": "RabbitMQ"
            }
        else:
            raise Exception("Health check failed")
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["components"]["rabbitmq"] = {
            "status": "down",
            "error": str(e)
        }
    
    # Á≥ªÁµ±Ë≥áÊ∫ê
    health_status["system"] = {
        "cpu_percent": psutil.cpu_percent(interval=1),
        "memory_percent": psutil.virtual_memory().percent,
        "disk_percent": psutil.disk_usage('/').percent
    }
    
    return health_status
```

**4. Áî®Êà∂ÁÆ°ÁêÜ API**

```python
# app/api/v1/admin/users.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.api.deps import get_db, require_admin
from app.models.user import User
from app.schemas.user import UserCreate, UserUpdate, UserResponse
from app.services.user_service import UserService

router = APIRouter()

@router.get("/api/admin/users/")
async def list_users(
    skip: int = 0,
    limit: int = 100,
    search: str = None,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    query = db.query(User)
    
    if search:
        query = query.filter(
            (User.email.contains(search)) | (User.name.contains(search))
        )
    
    total = query.count()
    users = query.offset(skip).limit(limit).all()
    
    return {
        "total": total,
        "users": users
    }

@router.post("/api/admin/users/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    user_service = UserService(db)
    
    # Ê™¢Êü• email ÊòØÂê¶Â∑≤Â≠òÂú®
    existing_user = db.query(User).filter(User.email == user_data.email).first()
    if existing_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    user = user_service.create_user(user_data)
    return user

@router.put("/api/admin/users/{user_id}")
async def update_user(
    user_id: str,
    user_data: UserUpdate,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    for key, value in user_data.dict(exclude_unset=True).items():
        setattr(user, key, value)
    
    db.commit()
    db.refresh(user)
    return user

@router.delete("/api/admin/users/{user_id}")
async def delete_user(
    user_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    # ËªüÂà™Èô§
    user.is_active = False
    user.deleted_at = datetime.utcnow()
    db.commit()
    
    return {"message": "User deleted successfully"}
```

#### Â≠ê‰ªªÂãô

1. [ ] ÂØ¶ÁèæÁµ±Ë®àÊï∏Êìö API
2. [ ] ÂØ¶ÁèæÂØ¶ÊôÇÊåáÊ®ô API
3. [ ] ÂØ¶ÁèæÁ≥ªÁµ±ÂÅ•Â∫∑ÁãÄÊÖã API
4. [ ] ÂØ¶ÁèæÁî®Êà∂ÁÆ°ÁêÜ API
5. [ ] Ê∑ªÂä† Redis Á∑©Â≠ò
6. [ ] Á∑®ÂØ´ÂñÆÂÖÉÊ∏¨Ë©¶
7. [ ] Á∑®ÂØ´ API ÊñáÊ™î

#### Ê∏¨Ë©¶Ë®àÂäÉ

```python
# tests/integration/test_admin_apis.py
def test_overview_statistics(client, admin_user):
    response = client.get(
        "/api/admin/statistics/overview",
        headers={"Authorization": f"Bearer {admin_user.token}"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "workflows" in data
    assert "executions" in data
    assert data["workflows"]["total"] >= 0

def test_non_admin_cannot_access(client, regular_user):
    response = client.get(
        "/api/admin/statistics/overview",
        headers={"Authorization": f"Bearer {regular_user.token}"}
    )
    
    assert response.status_code == 403
```

---

## üìà Sprint 2 Metrics

### Velocity Tracking
- **Ë®àÂäÉÈªûÊï∏**: 40
- **Ë™øÊï¥ÈªûÊï∏** (ÂÅáÊúü): 28-32
- **ÈóúÈçµ‰ªªÂãô**: S2-1, S2-3, S2-7 (P0)

### Risk Register
- üî¥ ÂÅáÊúüÊúüÈñì‰∫∫Âì°ÂèØÁî®ÊÄßÈôç‰Ωé
- üü° n8n Webhook Á∞ΩÂêçÈ©óË≠âË§áÈõúÂ∫¶
- üü° Teams API ÈôêÊµÅÂïèÈ°å

### Definition of Done
- [ ] ÊâÄÊúâ‰ª£Á¢ºÂ∑≤Âêà‰ΩµÂà∞ main
- [ ] ÂñÆÂÖÉÊ∏¨Ë©¶Ë¶ÜËìãÁéá ‚â• 80%
- [ ] ÈõÜÊàêÊ∏¨Ë©¶ÈÄöÈÅé
- [ ] API ÊñáÊ™îÂ∑≤Êõ¥Êñ∞
- [ ] ÈÉ®ÁΩ≤Âà∞ Staging ÊàêÂäü
- [ ] Code review Â∑≤ÊâπÂáÜ

---

**ÊñáÊ™îÁãÄÊÖã**: ‚úÖ Â∑≤ÂÆåÊàê  
**‰∏äÊ¨°Êõ¥Êñ∞**: 2025-11-19  
**‰∏ãÊ¨°ÂØ©Êü•**: Sprint 2 ÈñãÂßãÂâç (2025-12-23)