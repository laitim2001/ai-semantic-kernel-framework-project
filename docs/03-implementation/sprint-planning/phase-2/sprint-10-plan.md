# Sprint 10: å‹•æ…‹è¦åŠƒå¼•æ“ (Dynamic Planning & Autonomous Decision)

**Sprint ç›®æ¨™**: å¯¦ç¾è‡ªä¸»è¦åŠƒå’Œæ±ºç­–èƒ½åŠ›ï¼Œè®“ Agent èƒ½å¤ å‹•æ…‹åˆ†è§£ä»»å‹™ä¸¦è‡ªä¸»æ±ºç­–

**é€±æœŸ**: Week 21-22 (2 é€±)
**Story Points**: 42 é»
**å‰ç½®æ¢ä»¶**: Sprint 7-9 å®Œæˆ

---

## Sprint æ¦‚è¿°

### æ ¸å¿ƒäº¤ä»˜ç‰©

| ID | åŠŸèƒ½ | å„ªå…ˆç´š | Story Points | ç‹€æ…‹ |
|----|------|--------|--------------|------|
| P2-F8 | Dynamic Planning å‹•æ…‹è¦åŠƒ | ğŸŸ¡ ä¸­ | 21 | å¾…é–‹ç™¼ |
| P2-F9 | Autonomous Decision è‡ªä¸»æ±ºç­– | ğŸŸ¡ ä¸­ | 13 | å¾…é–‹ç™¼ |
| P2-F10 | Trial-and-Error è©¦éŒ¯æ©Ÿåˆ¶ | ğŸŸ¢ ä½ | 8 | å¾…é–‹ç™¼ |

### èˆ‡ Microsoft Agent Framework å°ç…§

```python
# Microsoft Agent Framework è‡ªä¸»è¦åŠƒæ¦‚å¿µ
# åƒè€ƒ AutoGen çš„ AssistantAgent è‡ªä¸»èƒ½åŠ›

from autogen import AssistantAgent, UserProxyAgent

# å…·æœ‰è¦åŠƒèƒ½åŠ›çš„ Agent
planner_agent = AssistantAgent(
    name="Planner",
    system_message="""
    You are a planning agent. Your job is to:
    1. Analyze the task
    2. Break it down into subtasks
    3. Assign subtasks to appropriate agents
    4. Monitor progress and adjust plan as needed
    """,
    llm_config={"model": "gpt-4"}
)

# å…·æœ‰åŸ·è¡Œå’Œåé¥‹èƒ½åŠ›çš„ Agent
executor_agent = AssistantAgent(
    name="Executor",
    system_message="You execute tasks and report results.",
    llm_config={"model": "gpt-4"}
)
```

---

## User Stories

### Story 10-1: Task Decomposer ä»»å‹™åˆ†è§£å™¨ (8 é»)

**ä½œç‚º** ç³»çµ±æ¶æ§‹å¸«
**æˆ‘å¸Œæœ›** å¯¦ç¾æ™ºèƒ½ä»»å‹™åˆ†è§£
**ä»¥ä¾¿** è¤‡é›œä»»å‹™å¯ä»¥è¢«è‡ªå‹•æ‹†è§£ç‚ºå¯åŸ·è¡Œçš„å­ä»»å‹™

#### æŠ€è¡“è¦æ ¼

```python
# backend/src/domain/orchestration/planning/task_decomposer.py

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from uuid import UUID, uuid4
from enum import Enum
from datetime import datetime


class TaskPriority(str, Enum):
    """ä»»å‹™å„ªå…ˆç´š"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class TaskStatus(str, Enum):
    """ä»»å‹™ç‹€æ…‹"""
    PENDING = "pending"
    READY = "ready"         # ä¾è³´æ»¿è¶³ï¼Œå¯åŸ·è¡Œ
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    BLOCKED = "blocked"     # ä¾è³´æœªæ»¿è¶³


class DependencyType(str, Enum):
    """ä¾è³´é¡å‹"""
    FINISH_TO_START = "finish_to_start"   # å‰ç½®ä»»å‹™å®Œæˆå¾Œé–‹å§‹
    START_TO_START = "start_to_start"     # å‰ç½®ä»»å‹™é–‹å§‹å¾Œé–‹å§‹
    FINISH_TO_FINISH = "finish_to_finish" # å‰ç½®ä»»å‹™å®Œæˆæ™‚å®Œæˆ
    DATA_DEPENDENCY = "data_dependency"    # éœ€è¦å‰ç½®ä»»å‹™çš„æ•¸æ“š


@dataclass
class SubTask:
    """å­ä»»å‹™"""
    id: UUID
    parent_task_id: UUID
    name: str
    description: str
    priority: TaskPriority
    status: TaskStatus = TaskStatus.PENDING
    assigned_agent_id: Optional[str] = None
    dependencies: List[UUID] = field(default_factory=list)
    dependency_type: DependencyType = DependencyType.FINISH_TO_START
    estimated_duration_minutes: int = 0
    actual_duration_minutes: Optional[int] = None
    inputs: Dict[str, Any] = field(default_factory=dict)
    outputs: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.utcnow)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": str(self.id),
            "parent_task_id": str(self.parent_task_id),
            "name": self.name,
            "description": self.description,
            "priority": self.priority.value,
            "status": self.status.value,
            "assigned_agent_id": self.assigned_agent_id,
            "dependencies": [str(d) for d in self.dependencies],
            "dependency_type": self.dependency_type.value,
            "estimated_duration_minutes": self.estimated_duration_minutes,
            "inputs": self.inputs,
            "outputs": self.outputs,
            "metadata": self.metadata
        }


@dataclass
class DecompositionResult:
    """åˆ†è§£çµæœ"""
    task_id: UUID
    original_task: str
    subtasks: List[SubTask]
    execution_order: List[List[UUID]]  # åˆ†å±¤åŸ·è¡Œé †åº
    estimated_total_duration: int
    confidence_score: float  # åˆ†è§£ä¿¡å¿ƒåˆ†æ•¸ 0-1
    decomposition_strategy: str
    metadata: Dict[str, Any] = field(default_factory=dict)


class TaskDecomposer:
    """
    ä»»å‹™åˆ†è§£å™¨

    ä½¿ç”¨ LLM æ™ºèƒ½åˆ†è§£è¤‡é›œä»»å‹™ç‚ºå¯åŸ·è¡Œçš„å­ä»»å‹™
    """

    def __init__(
        self,
        llm_service: Any,
        agent_registry: Any,
        max_subtasks: int = 20,
        max_depth: int = 3
    ):
        self.llm_service = llm_service
        self.agent_registry = agent_registry
        self.max_subtasks = max_subtasks
        self.max_depth = max_depth

        # åˆ†è§£ç­–ç•¥
        self._strategies = {
            "hierarchical": self._decompose_hierarchical,
            "sequential": self._decompose_sequential,
            "parallel": self._decompose_parallel,
            "hybrid": self._decompose_hybrid
        }

    async def decompose(
        self,
        task_description: str,
        context: Optional[Dict[str, Any]] = None,
        strategy: str = "hybrid"
    ) -> DecompositionResult:
        """
        åˆ†è§£ä»»å‹™

        Args:
            task_description: ä»»å‹™æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            strategy: åˆ†è§£ç­–ç•¥

        Returns:
            åˆ†è§£çµæœ
        """
        task_id = uuid4()

        # é¸æ“‡åˆ†è§£ç­–ç•¥
        decompose_fn = self._strategies.get(strategy, self._decompose_hybrid)

        # åŸ·è¡Œåˆ†è§£
        subtasks = await decompose_fn(task_id, task_description, context)

        # åˆ†æä¾è³´é—œä¿‚
        execution_order = self._analyze_execution_order(subtasks)

        # ä¼°ç®—ç¸½æ™‚é–“
        total_duration = self._estimate_total_duration(subtasks, execution_order)

        # è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
        confidence = await self._calculate_confidence(task_description, subtasks)

        return DecompositionResult(
            task_id=task_id,
            original_task=task_description,
            subtasks=subtasks,
            execution_order=execution_order,
            estimated_total_duration=total_duration,
            confidence_score=confidence,
            decomposition_strategy=strategy,
            metadata={"context": context} if context else {}
        )

    async def _decompose_hierarchical(
        self,
        task_id: UUID,
        task_description: str,
        context: Optional[Dict[str, Any]]
    ) -> List[SubTask]:
        """éšå±¤å¼åˆ†è§£"""
        prompt = self._build_decomposition_prompt(
            task_description,
            context,
            approach="hierarchical"
        )

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=2000
        )

        return self._parse_decomposition_response(task_id, response)

    async def _decompose_sequential(
        self,
        task_id: UUID,
        task_description: str,
        context: Optional[Dict[str, Any]]
    ) -> List[SubTask]:
        """é †åºå¼åˆ†è§£"""
        prompt = self._build_decomposition_prompt(
            task_description,
            context,
            approach="sequential"
        )

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=2000
        )

        subtasks = self._parse_decomposition_response(task_id, response)

        # è¨­ç½®é †åºä¾è³´
        for i in range(1, len(subtasks)):
            subtasks[i].dependencies = [subtasks[i-1].id]

        return subtasks

    async def _decompose_parallel(
        self,
        task_id: UUID,
        task_description: str,
        context: Optional[Dict[str, Any]]
    ) -> List[SubTask]:
        """ä¸¦è¡Œå¼åˆ†è§£"""
        prompt = self._build_decomposition_prompt(
            task_description,
            context,
            approach="parallel"
        )

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=2000
        )

        subtasks = self._parse_decomposition_response(task_id, response)

        # ä¸¦è¡Œä»»å‹™æ²’æœ‰ç›¸äº’ä¾è³´
        return subtasks

    async def _decompose_hybrid(
        self,
        task_id: UUID,
        task_description: str,
        context: Optional[Dict[str, Any]]
    ) -> List[SubTask]:
        """
        æ··åˆå¼åˆ†è§£

        çµåˆéšå±¤å’Œä¸¦è¡Œï¼Œæ™ºèƒ½è­˜åˆ¥å¯ä¸¦è¡Œçš„ä»»å‹™
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹ä»»å‹™ä¸¦å°‡å…¶åˆ†è§£ç‚ºå­ä»»å‹™ã€‚è­˜åˆ¥å“ªäº›ä»»å‹™å¯ä»¥ä¸¦è¡ŒåŸ·è¡Œï¼Œå“ªäº›å¿…é ˆé †åºåŸ·è¡Œã€‚

        ä»»å‹™: {task_description}

        ä¸Šä¸‹æ–‡: {context if context else "ç„¡é¡å¤–ä¸Šä¸‹æ–‡"}

        è«‹ä»¥ JSON æ ¼å¼è¿”å›åˆ†è§£çµæœï¼š
        {{
            "subtasks": [
                {{
                    "name": "å­ä»»å‹™åç¨±",
                    "description": "è©³ç´°æè¿°",
                    "priority": "high/medium/low",
                    "dependencies": ["ä¾è³´çš„å­ä»»å‹™åç¨±"],
                    "estimated_minutes": 30,
                    "required_capabilities": ["capability1", "capability2"]
                }}
            ],
            "reasoning": "åˆ†è§£ç†ç”±"
        }}

        æ³¨æ„äº‹é …ï¼š
        1. å­ä»»å‹™æ•¸é‡æ‡‰åœ¨ 3-{self.max_subtasks} ä¹‹é–“
        2. è­˜åˆ¥çœŸæ­£çš„ä¾è³´é—œä¿‚ï¼Œé¿å…éåº¦ä¸²è¡ŒåŒ–
        3. è€ƒæ…®ä»»å‹™çš„åŸå­æ€§å’Œå¯æ¸¬è©¦æ€§
        4. å„ªå…ˆç´šæ‡‰åŸºæ–¼æ¥­å‹™å½±éŸ¿å’Œä¾è³´é—œä¿‚
        """

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=3000
        )

        return self._parse_decomposition_response(task_id, response)

    def _build_decomposition_prompt(
        self,
        task_description: str,
        context: Optional[Dict[str, Any]],
        approach: str
    ) -> str:
        """æ§‹å»ºåˆ†è§£æç¤º"""
        approach_instructions = {
            "hierarchical": "ä½¿ç”¨éšå±¤å¼æ–¹æ³•ï¼Œå…ˆåˆ†è§£ç‚ºä¸»è¦éšæ®µï¼Œå†ç´°åˆ†æ¯å€‹éšæ®µ",
            "sequential": "æŒ‰åŸ·è¡Œé †åºåˆ†è§£ï¼Œæ¯å€‹æ­¥é©Ÿä¾è³´å‰ä¸€å€‹æ­¥é©Ÿ",
            "parallel": "è­˜åˆ¥å¯ä»¥åŒæ™‚åŸ·è¡Œçš„ç¨ç«‹ä»»å‹™"
        }

        return f"""
        ä»»å‹™åˆ†è§£è«‹æ±‚:

        ä»»å‹™æè¿°: {task_description}
        åˆ†è§£æ–¹æ³•: {approach_instructions.get(approach, "")}
        ä¸Šä¸‹æ–‡: {context if context else "ç„¡"}

        è«‹è¿”å› JSON æ ¼å¼çš„å­ä»»å‹™åˆ—è¡¨ã€‚
        """

    def _parse_decomposition_response(
        self,
        task_id: UUID,
        response: str
    ) -> List[SubTask]:
        """è§£æ LLM çš„åˆ†è§£å›æ‡‰"""
        import json

        try:
            data = json.loads(response)
            subtasks_data = data.get("subtasks", [])
        except json.JSONDecodeError:
            # å˜—è©¦å¾æ–‡æœ¬ä¸­æå–
            subtasks_data = self._extract_tasks_from_text(response)

        subtasks = []
        name_to_id = {}

        for task_data in subtasks_data[:self.max_subtasks]:
            subtask_id = uuid4()
            name = task_data.get("name", f"Subtask {len(subtasks) + 1}")
            name_to_id[name] = subtask_id

            subtask = SubTask(
                id=subtask_id,
                parent_task_id=task_id,
                name=name,
                description=task_data.get("description", ""),
                priority=TaskPriority(task_data.get("priority", "medium")),
                estimated_duration_minutes=task_data.get("estimated_minutes", 30),
                metadata={
                    "required_capabilities": task_data.get("required_capabilities", [])
                }
            )
            subtasks.append(subtask)

        # è§£æä¾è³´é—œä¿‚
        for i, task_data in enumerate(subtasks_data[:self.max_subtasks]):
            dep_names = task_data.get("dependencies", [])
            subtasks[i].dependencies = [
                name_to_id[name] for name in dep_names
                if name in name_to_id
            ]

        return subtasks

    def _extract_tasks_from_text(self, text: str) -> List[Dict[str, Any]]:
        """å¾ç´”æ–‡æœ¬ä¸­æå–ä»»å‹™"""
        tasks = []
        lines = text.strip().split('\n')

        for line in lines:
            if line.strip() and (line.startswith('-') or line.startswith('*') or line[0].isdigit()):
                task_text = line.lstrip('-*0123456789. ')
                tasks.append({
                    "name": task_text[:50],
                    "description": task_text,
                    "priority": "medium"
                })

        return tasks

    def _analyze_execution_order(
        self,
        subtasks: List[SubTask]
    ) -> List[List[UUID]]:
        """
        åˆ†æåŸ·è¡Œé †åº

        ä½¿ç”¨æ‹“æ’²æ’åºç¢ºå®šåŸ·è¡Œå±¤ç´š

        Returns:
            åˆ†å±¤çš„ä»»å‹™ ID åˆ—è¡¨ï¼ŒåŒä¸€å±¤å¯ä¸¦è¡ŒåŸ·è¡Œ
        """
        # å»ºç«‹ä»»å‹™ç´¢å¼•
        task_index = {task.id: task for task in subtasks}

        # è¨ˆç®—å…¥åº¦
        in_degree = {task.id: 0 for task in subtasks}
        for task in subtasks:
            for dep_id in task.dependencies:
                if dep_id in in_degree:
                    in_degree[task.id] += 1

        # æ‹“æ’²æ’åº
        execution_order = []
        remaining = set(in_degree.keys())

        while remaining:
            # æ‰¾å‡ºå…¥åº¦ç‚º 0 çš„ä»»å‹™ï¼ˆå¯ä¸¦è¡ŒåŸ·è¡Œï¼‰
            ready = [
                task_id for task_id in remaining
                if in_degree[task_id] == 0
            ]

            if not ready:
                # å­˜åœ¨å¾ªç’°ä¾è³´ï¼Œæ‰“ç ´å¾ªç’°
                ready = [min(remaining)]

            execution_order.append(ready)

            # æ›´æ–°å…¥åº¦
            for task_id in ready:
                remaining.remove(task_id)
                task = task_index[task_id]
                for other_task in subtasks:
                    if task_id in other_task.dependencies:
                        in_degree[other_task.id] -= 1

        return execution_order

    def _estimate_total_duration(
        self,
        subtasks: List[SubTask],
        execution_order: List[List[UUID]]
    ) -> int:
        """
        ä¼°ç®—ç¸½åŸ·è¡Œæ™‚é–“

        è€ƒæ…®ä¸¦è¡ŒåŸ·è¡Œçš„ä»»å‹™
        """
        task_index = {task.id: task for task in subtasks}
        total = 0

        for layer in execution_order:
            # æ¯å±¤å–æœ€é•·çš„ä»»å‹™æ™‚é–“ï¼ˆä¸¦è¡ŒåŸ·è¡Œï¼‰
            layer_max = max(
                task_index[task_id].estimated_duration_minutes
                for task_id in layer
            ) if layer else 0
            total += layer_max

        return total

    async def _calculate_confidence(
        self,
        original_task: str,
        subtasks: List[SubTask]
    ) -> float:
        """è¨ˆç®—åˆ†è§£ä¿¡å¿ƒåˆ†æ•¸"""
        # åŸºæ–¼å¤šå€‹å› ç´ è©•ä¼°ä¿¡å¿ƒ
        factors = []

        # 1. å­ä»»å‹™æ•¸é‡åˆç†æ€§
        task_count = len(subtasks)
        if 3 <= task_count <= 10:
            factors.append(1.0)
        elif 2 <= task_count <= 15:
            factors.append(0.8)
        else:
            factors.append(0.5)

        # 2. æè¿°å®Œæ•´æ€§
        described = sum(1 for t in subtasks if len(t.description) > 20)
        factors.append(described / len(subtasks) if subtasks else 0)

        # 3. ä¾è³´é—œä¿‚åˆç†æ€§ï¼ˆç„¡å­¤ç«‹ä»»å‹™ï¼‰
        has_deps = sum(1 for t in subtasks if t.dependencies)
        if len(subtasks) > 1:
            factors.append(min(has_deps / (len(subtasks) - 1), 1.0))
        else:
            factors.append(1.0)

        return sum(factors) / len(factors)

    async def refine_decomposition(
        self,
        result: DecompositionResult,
        feedback: str
    ) -> DecompositionResult:
        """
        æ ¹æ“šåé¥‹ç²¾ç…‰åˆ†è§£çµæœ

        Args:
            result: åŸå§‹åˆ†è§£çµæœ
            feedback: æ”¹é€²åé¥‹

        Returns:
            ç²¾ç…‰å¾Œçš„åˆ†è§£çµæœ
        """
        prompt = f"""
        åŸå§‹ä»»å‹™: {result.original_task}

        ç•¶å‰åˆ†è§£:
        {[t.to_dict() for t in result.subtasks]}

        åé¥‹: {feedback}

        è«‹æ ¹æ“šåé¥‹æ”¹é€²ä»»å‹™åˆ†è§£ã€‚è¿”å›æ›´æ–°å¾Œçš„ JSON æ ¼å¼å­ä»»å‹™åˆ—è¡¨ã€‚
        """

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=3000
        )

        new_subtasks = self._parse_decomposition_response(result.task_id, response)
        new_execution_order = self._analyze_execution_order(new_subtasks)

        return DecompositionResult(
            task_id=result.task_id,
            original_task=result.original_task,
            subtasks=new_subtasks,
            execution_order=new_execution_order,
            estimated_total_duration=self._estimate_total_duration(new_subtasks, new_execution_order),
            confidence_score=await self._calculate_confidence(result.original_task, new_subtasks),
            decomposition_strategy=result.decomposition_strategy,
            metadata={**result.metadata, "refined": True, "feedback": feedback}
        )
```

#### é©—æ”¶æ¨™æº–
- [ ] æ”¯æ´ 4 ç¨®åˆ†è§£ç­–ç•¥
- [ ] æ­£ç¢ºè­˜åˆ¥ä»»å‹™ä¾è³´
- [ ] è¨ˆç®—åˆç†çš„åŸ·è¡Œé †åº
- [ ] ä¿¡å¿ƒåˆ†æ•¸æº–ç¢ºåæ˜ åˆ†è§£è³ªé‡
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ > 85%

---

### Story 10-2: Dynamic Planner å‹•æ…‹è¦åŠƒå™¨ (8 é»)

**ä½œç‚º** ç³»çµ±æ¶æ§‹å¸«
**æˆ‘å¸Œæœ›** å¯¦ç¾å‹•æ…‹è¦åŠƒå¼•æ“
**ä»¥ä¾¿** æ ¹æ“šåŸ·è¡Œæƒ…æ³å¯¦æ™‚èª¿æ•´è¨ˆåŠƒ

#### æŠ€è¡“è¦æ ¼

```python
# backend/src/domain/orchestration/planning/dynamic_planner.py

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from uuid import UUID, uuid4
from datetime import datetime
from enum import Enum
import asyncio


class PlanStatus(str, Enum):
    """è¨ˆåŠƒç‹€æ…‹"""
    DRAFT = "draft"
    APPROVED = "approved"
    EXECUTING = "executing"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    REPLANNING = "replanning"


class PlanEvent(str, Enum):
    """è¨ˆåŠƒäº‹ä»¶"""
    TASK_STARTED = "task_started"
    TASK_COMPLETED = "task_completed"
    TASK_FAILED = "task_failed"
    RESOURCE_UNAVAILABLE = "resource_unavailable"
    NEW_INFORMATION = "new_information"
    USER_INTERVENTION = "user_intervention"
    DEADLINE_APPROACHING = "deadline_approaching"


@dataclass
class PlanAdjustment:
    """è¨ˆåŠƒèª¿æ•´"""
    id: UUID
    plan_id: UUID
    trigger_event: PlanEvent
    original_state: Dict[str, Any]
    new_state: Dict[str, Any]
    reason: str
    timestamp: datetime = field(default_factory=datetime.utcnow)
    approved: bool = False
    approved_by: Optional[str] = None


@dataclass
class ExecutionPlan:
    """åŸ·è¡Œè¨ˆåŠƒ"""
    id: UUID
    name: str
    description: str
    goal: str
    decomposition: "DecompositionResult"
    status: PlanStatus = PlanStatus.DRAFT
    current_phase: int = 0
    progress_percentage: float = 0.0
    adjustments: List[PlanAdjustment] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.utcnow)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    deadline: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class DynamicPlanner:
    """
    å‹•æ…‹è¦åŠƒå™¨

    è² è²¬ï¼š
    - å»ºç«‹åŸ·è¡Œè¨ˆåŠƒ
    - ç›£æ§åŸ·è¡Œé€²åº¦
    - æ ¹æ“šæƒ…æ³å‹•æ…‹èª¿æ•´è¨ˆåŠƒ
    - è™•ç†ç•°å¸¸å’Œé‡æ–°è¦åŠƒ
    """

    def __init__(
        self,
        task_decomposer: "TaskDecomposer",
        decision_engine: "AutonomousDecisionEngine",
        llm_service: Any,
        require_approval_for_changes: bool = True
    ):
        self.decomposer = task_decomposer
        self.decision_engine = decision_engine
        self.llm_service = llm_service
        self.require_approval = require_approval_for_changes

        # è¨ˆåŠƒå­˜å„²
        self._plans: Dict[UUID, ExecutionPlan] = {}

        # äº‹ä»¶è™•ç†å™¨
        self._event_handlers: Dict[PlanEvent, List[Callable]] = {
            event: [] for event in PlanEvent
        }

        # ç›£æ§ä»»å‹™
        self._monitoring_tasks: Dict[UUID, asyncio.Task] = {}

    async def create_plan(
        self,
        goal: str,
        context: Optional[Dict[str, Any]] = None,
        deadline: Optional[datetime] = None
    ) -> ExecutionPlan:
        """
        å»ºç«‹åŸ·è¡Œè¨ˆåŠƒ

        Args:
            goal: ç›®æ¨™æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            deadline: æˆªæ­¢æ™‚é–“

        Returns:
            åŸ·è¡Œè¨ˆåŠƒ
        """
        # åˆ†è§£ä»»å‹™
        decomposition = await self.decomposer.decompose(
            task_description=goal,
            context=context,
            strategy="hybrid"
        )

        plan = ExecutionPlan(
            id=uuid4(),
            name=f"Plan for: {goal[:50]}...",
            description=goal,
            goal=goal,
            decomposition=decomposition,
            deadline=deadline
        )

        self._plans[plan.id] = plan
        return plan

    async def approve_plan(self, plan_id: UUID, approver: str) -> None:
        """æ‰¹å‡†è¨ˆåŠƒ"""
        plan = self._plans.get(plan_id)
        if not plan:
            raise ValueError(f"Plan {plan_id} not found")

        plan.status = PlanStatus.APPROVED
        plan.metadata["approved_by"] = approver
        plan.metadata["approved_at"] = datetime.utcnow().isoformat()

    async def execute_plan(
        self,
        plan_id: UUID,
        execution_callback: Callable[[SubTask], Any]
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œè¨ˆåŠƒ

        Args:
            plan_id: è¨ˆåŠƒ ID
            execution_callback: åŸ·è¡Œå­ä»»å‹™çš„å›èª¿å‡½æ•¸

        Returns:
            åŸ·è¡Œçµæœ
        """
        plan = self._plans.get(plan_id)
        if not plan:
            raise ValueError(f"Plan {plan_id} not found")

        if plan.status not in [PlanStatus.APPROVED, PlanStatus.PAUSED]:
            raise ValueError(f"Plan is not in executable state: {plan.status}")

        plan.status = PlanStatus.EXECUTING
        plan.started_at = plan.started_at or datetime.utcnow()

        # å•Ÿå‹•ç›£æ§
        self._start_monitoring(plan_id)

        results = []
        execution_order = plan.decomposition.execution_order

        try:
            for phase_index, phase_tasks in enumerate(execution_order):
                plan.current_phase = phase_index

                # ä¸¦è¡ŒåŸ·è¡ŒåŒä¸€å±¤ç´šçš„ä»»å‹™
                phase_results = await self._execute_phase(
                    plan=plan,
                    task_ids=phase_tasks,
                    callback=execution_callback
                )
                results.extend(phase_results)

                # æ›´æ–°é€²åº¦
                completed_count = sum(
                    1 for t in plan.decomposition.subtasks
                    if t.status == TaskStatus.COMPLETED
                )
                plan.progress_percentage = (
                    completed_count / len(plan.decomposition.subtasks) * 100
                )

                # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¦åŠƒ
                if await self._should_replan(plan, phase_results):
                    await self._replan(plan, phase_results)

            plan.status = PlanStatus.COMPLETED
            plan.completed_at = datetime.utcnow()

        except Exception as e:
            plan.status = PlanStatus.FAILED
            plan.metadata["failure_reason"] = str(e)
            raise

        finally:
            self._stop_monitoring(plan_id)

        return {
            "plan_id": str(plan_id),
            "status": plan.status.value,
            "results": results,
            "adjustments_made": len(plan.adjustments)
        }

    async def _execute_phase(
        self,
        plan: ExecutionPlan,
        task_ids: List[UUID],
        callback: Callable
    ) -> List[Dict[str, Any]]:
        """åŸ·è¡Œä¸€å€‹éšæ®µçš„ä»»å‹™"""
        task_index = {t.id: t for t in plan.decomposition.subtasks}

        async def execute_single_task(task_id: UUID):
            task = task_index[task_id]
            task.status = TaskStatus.IN_PROGRESS
            task.started_at = datetime.utcnow()

            await self._emit_event(PlanEvent.TASK_STARTED, plan, task)

            try:
                result = await callback(task)
                task.status = TaskStatus.COMPLETED
                task.completed_at = datetime.utcnow()
                task.outputs = result if isinstance(result, dict) else {"result": result}

                await self._emit_event(PlanEvent.TASK_COMPLETED, plan, task)

                return {"task_id": str(task_id), "status": "completed", "result": result}

            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error_message = str(e)

                await self._emit_event(PlanEvent.TASK_FAILED, plan, task)

                return {"task_id": str(task_id), "status": "failed", "error": str(e)}

        # ä¸¦è¡ŒåŸ·è¡Œ
        tasks = [execute_single_task(tid) for tid in task_ids]
        return await asyncio.gather(*tasks)

    async def _should_replan(
        self,
        plan: ExecutionPlan,
        phase_results: List[Dict[str, Any]]
    ) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦é‡æ–°è¦åŠƒ"""
        # æª¢æŸ¥å¤±æ•—ä»»å‹™
        failed_tasks = [r for r in phase_results if r["status"] == "failed"]
        if len(failed_tasks) > len(phase_results) * 0.3:  # è¶…é 30% å¤±æ•—
            return True

        # æª¢æŸ¥æˆªæ­¢æ™‚é–“
        if plan.deadline:
            remaining_tasks = sum(
                1 for t in plan.decomposition.subtasks
                if t.status in [TaskStatus.PENDING, TaskStatus.READY]
            )
            estimated_remaining = remaining_tasks * 30  # å‡è¨­æ¯å€‹ä»»å‹™ 30 åˆ†é˜

            from datetime import timedelta
            if datetime.utcnow() + timedelta(minutes=estimated_remaining) > plan.deadline:
                await self._emit_event(PlanEvent.DEADLINE_APPROACHING, plan, None)
                return True

        return False

    async def _replan(
        self,
        plan: ExecutionPlan,
        recent_results: List[Dict[str, Any]]
    ) -> None:
        """é‡æ–°è¦åŠƒ"""
        plan.status = PlanStatus.REPLANNING

        # åˆ†æç•¶å‰æƒ…æ³
        analysis = await self._analyze_situation(plan, recent_results)

        # ä½¿ç”¨æ±ºç­–å¼•æ“æ±ºå®šæœ€ä½³è¡Œå‹•
        decision = await self.decision_engine.make_decision(
            situation=analysis,
            options=[
                "retry_failed_tasks",
                "skip_failed_tasks",
                "modify_remaining_tasks",
                "abort_plan"
            ]
        )

        # è¨˜éŒ„èª¿æ•´
        adjustment = PlanAdjustment(
            id=uuid4(),
            plan_id=plan.id,
            trigger_event=PlanEvent.TASK_FAILED,
            original_state={"results": recent_results},
            new_state={"decision": decision},
            reason=analysis.get("reason", "Automatic replanning")
        )

        if self.require_approval:
            # ç­‰å¾…äººå·¥æ‰¹å‡†
            adjustment.approved = False
            plan.adjustments.append(adjustment)
            # é€™è£¡å¯ä»¥ç™¼é€é€šçŸ¥ç­‰å¾…æ‰¹å‡†
        else:
            adjustment.approved = True
            plan.adjustments.append(adjustment)
            await self._apply_adjustment(plan, decision)

        plan.status = PlanStatus.EXECUTING

    async def _analyze_situation(
        self,
        plan: ExecutionPlan,
        recent_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åˆ†æç•¶å‰æƒ…æ³"""
        failed_tasks = [r for r in recent_results if r["status"] == "failed"]
        completed_tasks = [r for r in recent_results if r["status"] == "completed"]

        prompt = f"""
        åˆ†æä»¥ä¸‹åŸ·è¡Œæƒ…æ³ä¸¦æä¾›å»ºè­°ï¼š

        è¨ˆåŠƒç›®æ¨™: {plan.goal}
        ç•¶å‰é€²åº¦: {plan.progress_percentage}%
        æˆªæ­¢æ™‚é–“: {plan.deadline}

        æœ€è¿‘çµæœ:
        - æˆåŠŸ: {len(completed_tasks)} å€‹ä»»å‹™
        - å¤±æ•—: {len(failed_tasks)} å€‹ä»»å‹™
        - å¤±æ•—è©³æƒ…: {[r.get('error') for r in failed_tasks]}

        è«‹åˆ†ææƒ…æ³ä¸¦å»ºè­°ä¸‹ä¸€æ­¥è¡Œå‹•ã€‚
        """

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=500
        )

        return {
            "analysis": response,
            "failed_count": len(failed_tasks),
            "success_rate": len(completed_tasks) / len(recent_results) if recent_results else 0,
            "reason": "Automatic situation analysis"
        }

    async def _apply_adjustment(
        self,
        plan: ExecutionPlan,
        decision: Dict[str, Any]
    ) -> None:
        """æ‡‰ç”¨è¨ˆåŠƒèª¿æ•´"""
        action = decision.get("action")

        if action == "retry_failed_tasks":
            # é‡ç½®å¤±æ•—ä»»å‹™
            for task in plan.decomposition.subtasks:
                if task.status == TaskStatus.FAILED:
                    task.status = TaskStatus.READY
                    task.error_message = None

        elif action == "skip_failed_tasks":
            # æ¨™è¨˜å¤±æ•—ä»»å‹™ç‚ºè·³é
            for task in plan.decomposition.subtasks:
                if task.status == TaskStatus.FAILED:
                    task.status = TaskStatus.COMPLETED
                    task.metadata["skipped"] = True

        elif action == "modify_remaining_tasks":
            # ä¿®æ”¹å‰©é¤˜ä»»å‹™
            modifications = decision.get("modifications", {})
            for task in plan.decomposition.subtasks:
                if task.status == TaskStatus.PENDING:
                    task.description = modifications.get(
                        str(task.id),
                        task.description
                    )

    def _start_monitoring(self, plan_id: UUID) -> None:
        """å•Ÿå‹•è¨ˆåŠƒç›£æ§"""
        async def monitor():
            while True:
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                plan = self._plans.get(plan_id)
                if not plan or plan.status != PlanStatus.EXECUTING:
                    break
                # å¯ä»¥æ·»åŠ é¡å¤–çš„ç›£æ§é‚è¼¯

        self._monitoring_tasks[plan_id] = asyncio.create_task(monitor())

    def _stop_monitoring(self, plan_id: UUID) -> None:
        """åœæ­¢è¨ˆåŠƒç›£æ§"""
        task = self._monitoring_tasks.pop(plan_id, None)
        if task:
            task.cancel()

    async def _emit_event(
        self,
        event: PlanEvent,
        plan: ExecutionPlan,
        task: Optional[SubTask]
    ) -> None:
        """ç™¼é€äº‹ä»¶"""
        for handler in self._event_handlers.get(event, []):
            try:
                await handler(plan, task)
            except Exception:
                pass

    def on_event(
        self,
        event: PlanEvent,
        handler: Callable
    ) -> None:
        """è¨»å†Šäº‹ä»¶è™•ç†å™¨"""
        self._event_handlers[event].append(handler)

    def get_plan_status(self, plan_id: UUID) -> Dict[str, Any]:
        """ç²å–è¨ˆåŠƒç‹€æ…‹"""
        plan = self._plans.get(plan_id)
        if not plan:
            return {"error": "Plan not found"}

        return {
            "id": str(plan.id),
            "name": plan.name,
            "status": plan.status.value,
            "progress": plan.progress_percentage,
            "current_phase": plan.current_phase,
            "total_phases": len(plan.decomposition.execution_order),
            "adjustments": len(plan.adjustments),
            "subtasks": [
                {
                    "id": str(t.id),
                    "name": t.name,
                    "status": t.status.value
                }
                for t in plan.decomposition.subtasks
            ]
        }
```

#### é©—æ”¶æ¨™æº–
- [ ] æ”¯æ´è¨ˆåŠƒå»ºç«‹å’ŒåŸ·è¡Œ
- [ ] å¯¦æ™‚é€²åº¦è¿½è¹¤
- [ ] è‡ªå‹•é‡æ–°è¦åŠƒ
- [ ] äº‹ä»¶é€šçŸ¥æ©Ÿåˆ¶
- [ ] äººå·¥å¯©æ‰¹æµç¨‹

---

### Story 10-3: Autonomous Decision Engine (8 é»)

**ä½œç‚º** ç³»çµ±æ¶æ§‹å¸«
**æˆ‘å¸Œæœ›** å¯¦ç¾è‡ªä¸»æ±ºç­–å¼•æ“
**ä»¥ä¾¿** Agent å¯ä»¥åœ¨åŸ·è¡Œéç¨‹ä¸­è‡ªä¸»åšå‡ºåˆç†æ±ºç­–

#### æŠ€è¡“è¦æ ¼

```python
# backend/src/domain/orchestration/planning/decision_engine.py

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from uuid import UUID, uuid4
from datetime import datetime
from enum import Enum
import json


class DecisionType(str, Enum):
    """æ±ºç­–é¡å‹"""
    ROUTING = "routing"           # è·¯ç”±æ±ºç­–
    RESOURCE = "resource"         # è³‡æºåˆ†é…
    ERROR_HANDLING = "error_handling"  # éŒ¯èª¤è™•ç†
    PRIORITY = "priority"         # å„ªå…ˆç´šèª¿æ•´
    ESCALATION = "escalation"     # å‡ç´šæ±ºç­–
    OPTIMIZATION = "optimization" # å„ªåŒ–æ±ºç­–


class DecisionConfidence(str, Enum):
    """æ±ºç­–ä¿¡å¿ƒç­‰ç´š"""
    HIGH = "high"       # > 80% ä¿¡å¿ƒï¼Œå¯è‡ªå‹•åŸ·è¡Œ
    MEDIUM = "medium"   # 50-80% ä¿¡å¿ƒï¼Œå»ºè­°äººå·¥ç¢ºèª
    LOW = "low"         # < 50% ä¿¡å¿ƒï¼Œéœ€è¦äººå·¥æ±ºç­–


@dataclass
class DecisionOption:
    """æ±ºç­–é¸é …"""
    id: str
    name: str
    description: str
    pros: List[str]
    cons: List[str]
    risk_level: float  # 0-1
    estimated_impact: float  # 0-1ï¼Œæ­£é¢å½±éŸ¿
    prerequisites: List[str] = field(default_factory=list)


@dataclass
class Decision:
    """æ±ºç­–çµæœ"""
    id: UUID
    decision_type: DecisionType
    situation: str
    options_considered: List[DecisionOption]
    selected_option: str
    confidence: DecisionConfidence
    reasoning: str
    risk_assessment: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.utcnow)
    human_approved: Optional[bool] = None
    execution_result: Optional[Dict[str, Any]] = None


class AutonomousDecisionEngine:
    """
    è‡ªä¸»æ±ºç­–å¼•æ“

    ä½¿ç”¨ LLM é€²è¡Œæ™ºèƒ½æ±ºç­–ï¼Œæ”¯æ´ï¼š
    - å¤šé¸é …è©•ä¼°
    - é¢¨éšªè©•ä¼°
    - ä¿¡å¿ƒè¨ˆç®—
    - å¯è§£é‡‹æ€§
    """

    def __init__(
        self,
        llm_service: Any,
        risk_threshold: float = 0.7,
        auto_decision_confidence: float = 0.8
    ):
        self.llm_service = llm_service
        self.risk_threshold = risk_threshold
        self.auto_decision_confidence = auto_decision_confidence

        # æ±ºç­–æ­·å²
        self._decision_history: List[Decision] = []

        # æ±ºç­–è¦å‰‡
        self._rules: Dict[str, Callable] = {}

    async def make_decision(
        self,
        situation: str,
        options: List[str],
        context: Optional[Dict[str, Any]] = None,
        decision_type: DecisionType = DecisionType.ROUTING
    ) -> Dict[str, Any]:
        """
        åšå‡ºæ±ºç­–

        Args:
            situation: æƒ…æ³æè¿°
            options: å¯é¸é¸é …
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            decision_type: æ±ºç­–é¡å‹

        Returns:
            æ±ºç­–çµæœ
        """
        # 1. æ“´å±•é¸é …ä¿¡æ¯
        expanded_options = await self._expand_options(options, situation, context)

        # 2. è©•ä¼°æ¯å€‹é¸é …
        evaluations = await self._evaluate_options(expanded_options, situation, context)

        # 3. é¸æ“‡æœ€ä½³é¸é …
        selected, reasoning = await self._select_best_option(evaluations)

        # 4. è¨ˆç®—ä¿¡å¿ƒå’Œé¢¨éšª
        confidence = self._calculate_confidence(evaluations, selected)
        risk_assessment = self._assess_risk(selected, evaluations)

        # 5. å»ºç«‹æ±ºç­–è¨˜éŒ„
        decision = Decision(
            id=uuid4(),
            decision_type=decision_type,
            situation=situation,
            options_considered=expanded_options,
            selected_option=selected.id,
            confidence=confidence,
            reasoning=reasoning,
            risk_assessment=risk_assessment
        )

        self._decision_history.append(decision)

        return {
            "decision_id": str(decision.id),
            "action": selected.id,
            "confidence": confidence.value,
            "reasoning": reasoning,
            "risk_level": risk_assessment.get("overall_risk", 0),
            "requires_approval": confidence != DecisionConfidence.HIGH,
            "options": [
                {
                    "id": opt.id,
                    "name": opt.name,
                    "score": evaluations.get(opt.id, {}).get("score", 0)
                }
                for opt in expanded_options
            ]
        }

    async def _expand_options(
        self,
        options: List[str],
        situation: str,
        context: Optional[Dict[str, Any]]
    ) -> List[DecisionOption]:
        """æ“´å±•é¸é …ä¿¡æ¯"""
        prompt = f"""
        é‡å°ä»¥ä¸‹æƒ…æ³ï¼Œåˆ†ææ¯å€‹é¸é …çš„å„ªç¼ºé»å’Œé¢¨éšªï¼š

        æƒ…æ³: {situation}
        ä¸Šä¸‹æ–‡: {context if context else "ç„¡"}

        é¸é …:
        {json.dumps(options, ensure_ascii=False)}

        è«‹ä»¥ JSON æ ¼å¼è¿”å›æ¯å€‹é¸é …çš„åˆ†æï¼š
        [
            {{
                "id": "é¸é …ID",
                "name": "é¸é …åç¨±",
                "description": "è©³ç´°æè¿°",
                "pros": ["å„ªé»1", "å„ªé»2"],
                "cons": ["ç¼ºé»1", "ç¼ºé»2"],
                "risk_level": 0.3,
                "estimated_impact": 0.7,
                "prerequisites": ["å‰ææ¢ä»¶"]
            }}
        ]
        """

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=1500
        )

        try:
            options_data = json.loads(response)
            return [
                DecisionOption(
                    id=opt.get("id", str(i)),
                    name=opt.get("name", options[i] if i < len(options) else f"Option {i}"),
                    description=opt.get("description", ""),
                    pros=opt.get("pros", []),
                    cons=opt.get("cons", []),
                    risk_level=opt.get("risk_level", 0.5),
                    estimated_impact=opt.get("estimated_impact", 0.5),
                    prerequisites=opt.get("prerequisites", [])
                )
                for i, opt in enumerate(options_data)
            ]
        except json.JSONDecodeError:
            # ç°¡å–®è™•ç†
            return [
                DecisionOption(
                    id=opt,
                    name=opt,
                    description="",
                    pros=[],
                    cons=[],
                    risk_level=0.5,
                    estimated_impact=0.5
                )
                for opt in options
            ]

    async def _evaluate_options(
        self,
        options: List[DecisionOption],
        situation: str,
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Dict[str, Any]]:
        """è©•ä¼°é¸é …"""
        evaluations = {}

        for option in options:
            # è¨ˆç®—ç¶œåˆåˆ†æ•¸
            # åˆ†æ•¸ = å½±éŸ¿ * (1 - é¢¨éšª) * å‰ææ¢ä»¶æ»¿è¶³åº¦
            prerequisites_met = 1.0  # å‡è¨­æ‰€æœ‰å‰ææ¢ä»¶æ»¿è¶³

            score = (
                option.estimated_impact *
                (1 - option.risk_level) *
                prerequisites_met
            )

            # è€ƒæ…®å„ªç¼ºé»æ•¸é‡
            pros_bonus = len(option.pros) * 0.05
            cons_penalty = len(option.cons) * 0.05
            score = score + pros_bonus - cons_penalty
            score = max(0, min(1, score))  # é™åˆ¶åœ¨ 0-1

            evaluations[option.id] = {
                "score": score,
                "risk": option.risk_level,
                "impact": option.estimated_impact,
                "pros_count": len(option.pros),
                "cons_count": len(option.cons)
            }

        return evaluations

    async def _select_best_option(
        self,
        evaluations: Dict[str, Dict[str, Any]]
    ) -> Tuple[DecisionOption, str]:
        """é¸æ“‡æœ€ä½³é¸é …"""
        if not evaluations:
            raise ValueError("No options to evaluate")

        # æŒ‰åˆ†æ•¸æ’åº
        sorted_options = sorted(
            evaluations.items(),
            key=lambda x: x[1]["score"],
            reverse=True
        )

        best_id = sorted_options[0][0]
        best_score = sorted_options[0][1]["score"]

        # ç”Ÿæˆç†ç”±
        reasoning = f"é¸æ“‡ {best_id}ï¼Œå› ç‚ºå®ƒçš„ç¶œåˆè©•åˆ†æœ€é«˜ ({best_score:.2f})ã€‚"

        if len(sorted_options) > 1:
            second_id = sorted_options[1][0]
            second_score = sorted_options[1][1]["score"]
            reasoning += f" ç›¸æ¯”ç¬¬äºŒé¸é … {second_id} ({second_score:.2f})ï¼Œæœ‰æ›´å¥½çš„é¢¨éšªæ”¶ç›Šæ¯”ã€‚"

        # é€™è£¡éœ€è¦æ‰¾åˆ°å°æ‡‰çš„ DecisionOption
        # å‡è¨­æˆ‘å€‘ä¿å­˜äº†é¸é …åˆ—è¡¨
        return DecisionOption(
            id=best_id,
            name=best_id,
            description="",
            pros=[],
            cons=[],
            risk_level=evaluations[best_id]["risk"],
            estimated_impact=evaluations[best_id]["impact"]
        ), reasoning

    def _calculate_confidence(
        self,
        evaluations: Dict[str, Dict[str, Any]],
        selected: DecisionOption
    ) -> DecisionConfidence:
        """è¨ˆç®—æ±ºç­–ä¿¡å¿ƒ"""
        if not evaluations:
            return DecisionConfidence.LOW

        scores = [e["score"] for e in evaluations.values()]
        max_score = max(scores)
        avg_score = sum(scores) / len(scores)

        # è¨ˆç®—é ˜å…ˆå„ªå‹¢
        lead = max_score - avg_score

        # è€ƒæ…®é¢¨éšª
        risk_factor = 1 - selected.risk_level

        # ç¶œåˆä¿¡å¿ƒåˆ†æ•¸
        confidence_score = (
            max_score * 0.4 +
            lead * 0.3 +
            risk_factor * 0.3
        )

        if confidence_score >= self.auto_decision_confidence:
            return DecisionConfidence.HIGH
        elif confidence_score >= 0.5:
            return DecisionConfidence.MEDIUM
        else:
            return DecisionConfidence.LOW

    def _assess_risk(
        self,
        selected: DecisionOption,
        evaluations: Dict[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        """è©•ä¼°é¢¨éšª"""
        return {
            "overall_risk": selected.risk_level,
            "risk_category": self._categorize_risk(selected.risk_level),
            "potential_issues": selected.cons,
            "mitigation_suggestions": self._generate_mitigations(selected.cons),
            "reversible": selected.risk_level < 0.5
        }

    def _categorize_risk(self, risk_level: float) -> str:
        """åˆ†é¡é¢¨éšªç­‰ç´š"""
        if risk_level < 0.3:
            return "low"
        elif risk_level < 0.6:
            return "medium"
        else:
            return "high"

    def _generate_mitigations(self, cons: List[str]) -> List[str]:
        """ç”Ÿæˆé¢¨éšªç·©è§£å»ºè­°"""
        mitigations = []
        for con in cons:
            if "time" in con.lower() or "slow" in con.lower():
                mitigations.append("è¨­ç½®è¶…æ™‚é™åˆ¶ï¼Œå¿…è¦æ™‚çµ‚æ­¢")
            elif "cost" in con.lower() or "expensive" in con.lower():
                mitigations.append("è¨­å®šé ç®—ä¸Šé™ï¼Œç›£æ§è³‡æºä½¿ç”¨")
            elif "fail" in con.lower() or "error" in con.lower():
                mitigations.append("å¯¦æ–½é‡è©¦æ©Ÿåˆ¶å’Œå‚™é¸æ–¹æ¡ˆ")
            else:
                mitigations.append(f"ç›£æ§ç›¸é—œæŒ‡æ¨™: {con}")
        return mitigations

    async def explain_decision(self, decision_id: UUID) -> str:
        """è§£é‡‹æ±ºç­–"""
        decision = next(
            (d for d in self._decision_history if d.id == decision_id),
            None
        )

        if not decision:
            return "Decision not found"

        explanation = f"""
        æ±ºç­–è§£é‡‹ï¼š

        æƒ…æ³: {decision.situation}

        è€ƒæ…®çš„é¸é …:
        """

        for opt in decision.options_considered:
            explanation += f"""
            - {opt.name}:
              å„ªé»: {', '.join(opt.pros)}
              ç¼ºé»: {', '.join(opt.cons)}
              é¢¨éšª: {opt.risk_level:.0%}
            """

        explanation += f"""

        é¸æ“‡: {decision.selected_option}

        ç†ç”±: {decision.reasoning}

        ä¿¡å¿ƒç­‰ç´š: {decision.confidence.value}

        é¢¨éšªè©•ä¼°: {decision.risk_assessment}
        """

        return explanation

    def add_rule(
        self,
        name: str,
        condition: Callable[[str, List[str]], bool],
        action: str
    ) -> None:
        """
        æ·»åŠ æ±ºç­–è¦å‰‡

        Args:
            name: è¦å‰‡åç¨±
            condition: æ¢ä»¶å‡½æ•¸
            action: è§¸ç™¼æ™‚çš„è¡Œå‹•
        """
        self._rules[name] = {"condition": condition, "action": action}

    async def apply_rules(
        self,
        situation: str,
        options: List[str]
    ) -> Optional[str]:
        """
        æ‡‰ç”¨æ±ºç­–è¦å‰‡

        Returns:
            å¦‚æœæœ‰è¦å‰‡åŒ¹é…ï¼Œè¿”å›å°æ‡‰è¡Œå‹•ï¼›å¦å‰‡è¿”å› None
        """
        for name, rule in self._rules.items():
            if rule["condition"](situation, options):
                return rule["action"]
        return None
```

#### é©—æ”¶æ¨™æº–
- [ ] æ”¯æ´å¤šé¸é …è©•ä¼°
- [ ] é¢¨éšªè©•ä¼°æº–ç¢º
- [ ] ä¿¡å¿ƒè¨ˆç®—åˆç†
- [ ] æ±ºç­–å¯è§£é‡‹
- [ ] æ”¯æ´è‡ªå®šç¾©è¦å‰‡

---

### Story 10-4: Trial-and-Error Engine (5 é»)

**ä½œç‚º** ç³»çµ±æ¶æ§‹å¸«
**æˆ‘å¸Œæœ›** å¯¦ç¾è©¦éŒ¯å­¸ç¿’æ©Ÿåˆ¶
**ä»¥ä¾¿** Agent å¯ä»¥å¾å¤±æ•—ä¸­å­¸ç¿’ä¸¦æ”¹é€²

#### æŠ€è¡“è¦æ ¼

```python
# backend/src/domain/orchestration/planning/trial_error.py

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from uuid import UUID, uuid4
from datetime import datetime
from enum import Enum
import json


class TrialStatus(str, Enum):
    """è©¦é©—ç‹€æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILURE = "failure"
    TIMEOUT = "timeout"


class LearningType(str, Enum):
    """å­¸ç¿’é¡å‹"""
    PARAMETER_TUNING = "parameter_tuning"  # åƒæ•¸èª¿æ•´
    STRATEGY_SWITCH = "strategy_switch"    # ç­–ç•¥åˆ‡æ›
    ERROR_PATTERN = "error_pattern"        # éŒ¯èª¤æ¨¡å¼è­˜åˆ¥
    SUCCESS_PATTERN = "success_pattern"    # æˆåŠŸæ¨¡å¼è­˜åˆ¥


@dataclass
class Trial:
    """è©¦é©—è¨˜éŒ„"""
    id: UUID
    task_id: UUID
    attempt_number: int
    parameters: Dict[str, Any]
    strategy: str
    status: TrialStatus = TrialStatus.PENDING
    result: Optional[Any] = None
    error: Optional[str] = None
    duration_ms: int = 0
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": str(self.id),
            "task_id": str(self.task_id),
            "attempt_number": self.attempt_number,
            "parameters": self.parameters,
            "strategy": self.strategy,
            "status": self.status.value,
            "result": self.result,
            "error": self.error,
            "duration_ms": self.duration_ms
        }


@dataclass
class LearningInsight:
    """å­¸ç¿’æ´å¯Ÿ"""
    id: UUID
    learning_type: LearningType
    pattern: str
    confidence: float
    evidence: List[UUID]  # ç›¸é—œè©¦é©— ID
    recommendation: str
    created_at: datetime = field(default_factory=datetime.utcnow)


class TrialAndErrorEngine:
    """
    è©¦éŒ¯å­¸ç¿’å¼•æ“

    è² è²¬ï¼š
    - ç®¡ç†è©¦é©—åŸ·è¡Œ
    - åˆ†æå¤±æ•—åŸå› 
    - è‡ªå‹•èª¿æ•´ç­–ç•¥
    - å­¸ç¿’å’Œæ”¹é€²
    """

    def __init__(
        self,
        llm_service: Any,
        max_retries: int = 3,
        learning_threshold: int = 5  # éœ€è¦å¤šå°‘è©¦é©—æ‰é–‹å§‹å­¸ç¿’
    ):
        self.llm_service = llm_service
        self.max_retries = max_retries
        self.learning_threshold = learning_threshold

        # è©¦é©—æ­·å²
        self._trials: Dict[UUID, List[Trial]] = {}  # task_id -> trials

        # å­¸ç¿’æ´å¯Ÿ
        self._insights: List[LearningInsight] = []

        # éŒ¯èª¤æ¨¡å¼å¿«å–
        self._error_patterns: Dict[str, List[str]] = {}

        # æˆåŠŸç­–ç•¥å¿«å–
        self._success_strategies: Dict[str, Dict[str, Any]] = {}

    async def execute_with_retry(
        self,
        task_id: UUID,
        execution_fn: Callable[..., Any],
        initial_params: Dict[str, Any],
        strategy: str = "default"
    ) -> Dict[str, Any]:
        """
        å¸¶é‡è©¦çš„åŸ·è¡Œ

        Args:
            task_id: ä»»å‹™ ID
            execution_fn: åŸ·è¡Œå‡½æ•¸
            initial_params: åˆå§‹åƒæ•¸
            strategy: ç­–ç•¥åç¨±

        Returns:
            åŸ·è¡Œçµæœ
        """
        if task_id not in self._trials:
            self._trials[task_id] = []

        params = initial_params.copy()
        last_error = None

        for attempt in range(1, self.max_retries + 1):
            trial = Trial(
                id=uuid4(),
                task_id=task_id,
                attempt_number=attempt,
                parameters=params.copy(),
                strategy=strategy
            )

            trial.status = TrialStatus.RUNNING
            trial.started_at = datetime.utcnow()

            try:
                import time
                start_time = time.time()

                result = await execution_fn(**params)

                trial.status = TrialStatus.SUCCESS
                trial.result = result
                trial.duration_ms = int((time.time() - start_time) * 1000)
                trial.completed_at = datetime.utcnow()

                self._trials[task_id].append(trial)

                # è¨˜éŒ„æˆåŠŸç­–ç•¥
                self._record_success(task_id, params, strategy)

                return {
                    "success": True,
                    "result": result,
                    "attempts": attempt,
                    "final_params": params
                }

            except Exception as e:
                trial.status = TrialStatus.FAILURE
                trial.error = str(e)
                trial.completed_at = datetime.utcnow()

                self._trials[task_id].append(trial)
                last_error = e

                # åˆ†æéŒ¯èª¤ä¸¦èª¿æ•´
                if attempt < self.max_retries:
                    adjustment = await self._analyze_and_adjust(
                        task_id, trial, params, strategy
                    )
                    params = adjustment.get("new_params", params)
                    strategy = adjustment.get("new_strategy", strategy)

        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
        return {
            "success": False,
            "error": str(last_error),
            "attempts": self.max_retries,
            "trials": [t.to_dict() for t in self._trials[task_id]]
        }

    async def _analyze_and_adjust(
        self,
        task_id: UUID,
        failed_trial: Trial,
        current_params: Dict[str, Any],
        current_strategy: str
    ) -> Dict[str, Any]:
        """åˆ†æå¤±æ•—ä¸¦èª¿æ•´"""
        # æª¢æŸ¥æ˜¯å¦æœ‰å·²çŸ¥çš„éŒ¯èª¤æ¨¡å¼
        known_fix = self._check_known_patterns(failed_trial.error)
        if known_fix:
            return known_fix

        # ä½¿ç”¨ LLM åˆ†æ
        prompt = f"""
        åˆ†æä»¥ä¸‹åŸ·è¡Œå¤±æ•—ä¸¦å»ºè­°èª¿æ•´ï¼š

        ä»»å‹™ ID: {task_id}
        å˜—è©¦æ¬¡æ•¸: {failed_trial.attempt_number}
        ç•¶å‰åƒæ•¸: {json.dumps(current_params, ensure_ascii=False)}
        ç•¶å‰ç­–ç•¥: {current_strategy}
        éŒ¯èª¤ä¿¡æ¯: {failed_trial.error}

        ä¹‹å‰çš„å˜—è©¦:
        {[t.to_dict() for t in self._trials.get(task_id, [])[:-1]]}

        è«‹å»ºè­°ï¼š
        1. åƒæ•¸èª¿æ•´
        2. æ˜¯å¦éœ€è¦åˆ‡æ›ç­–ç•¥
        3. å¯èƒ½çš„æ ¹æœ¬åŸå› 

        ä»¥ JSON æ ¼å¼è¿”å›ï¼š
        {{
            "new_params": {{}},
            "new_strategy": "strategy_name",
            "analysis": "åŸå› åˆ†æ",
            "confidence": 0.8
        }}
        """

        response = await self.llm_service.generate(
            prompt=prompt,
            max_tokens=500
        )

        try:
            adjustment = json.loads(response)
            # è¨˜éŒ„éŒ¯èª¤æ¨¡å¼
            self._record_error_pattern(
                failed_trial.error,
                adjustment.get("analysis", ""),
                adjustment.get("new_params", {})
            )
            return adjustment
        except json.JSONDecodeError:
            # ç°¡å–®çš„åƒæ•¸èª¿æ•´
            return {
                "new_params": self._simple_param_adjustment(current_params),
                "new_strategy": current_strategy
            }

    def _check_known_patterns(
        self,
        error: str
    ) -> Optional[Dict[str, Any]]:
        """æª¢æŸ¥å·²çŸ¥çš„éŒ¯èª¤æ¨¡å¼"""
        error_lower = error.lower()

        # å…§å»ºçš„å¸¸è¦‹éŒ¯èª¤è™•ç†
        patterns = {
            "timeout": {
                "new_params": {"timeout": "increase"},
                "analysis": "å¢åŠ è¶…æ™‚æ™‚é–“"
            },
            "rate limit": {
                "new_params": {"delay": "increase"},
                "analysis": "å¢åŠ è«‹æ±‚é–“éš”"
            },
            "memory": {
                "new_params": {"batch_size": "decrease"},
                "analysis": "æ¸›å°‘æ‰¹æ¬¡å¤§å°"
            },
            "connection": {
                "new_strategy": "retry_with_backoff",
                "analysis": "ä½¿ç”¨æŒ‡æ•¸é€€é¿é‡è©¦"
            }
        }

        for pattern, fix in patterns.items():
            if pattern in error_lower:
                return fix

        # æª¢æŸ¥å­¸ç¿’åˆ°çš„æ¨¡å¼
        for error_pattern, fixes in self._error_patterns.items():
            if error_pattern in error_lower and fixes:
                return {"analysis": f"å·²çŸ¥æ¨¡å¼: {fixes[0]}"}

        return None

    def _simple_param_adjustment(
        self,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç°¡å–®çš„åƒæ•¸èª¿æ•´"""
        adjusted = params.copy()

        # èª¿æ•´æ•¸å€¼åƒæ•¸
        for key, value in adjusted.items():
            if isinstance(value, (int, float)):
                # å¢åŠ  20%
                adjusted[key] = value * 1.2
            elif isinstance(value, bool):
                # ç¿»è½‰å¸ƒçˆ¾å€¼
                adjusted[key] = not value

        return adjusted

    def _record_success(
        self,
        task_id: UUID,
        params: Dict[str, Any],
        strategy: str
    ) -> None:
        """è¨˜éŒ„æˆåŠŸç­–ç•¥"""
        key = self._generate_task_key(task_id)
        self._success_strategies[key] = {
            "params": params,
            "strategy": strategy,
            "timestamp": datetime.utcnow().isoformat()
        }

    def _record_error_pattern(
        self,
        error: str,
        analysis: str,
        fix: Dict[str, Any]
    ) -> None:
        """è¨˜éŒ„éŒ¯èª¤æ¨¡å¼"""
        # æå–éŒ¯èª¤é—œéµè©
        keywords = self._extract_error_keywords(error)

        for keyword in keywords:
            if keyword not in self._error_patterns:
                self._error_patterns[keyword] = []
            self._error_patterns[keyword].append(analysis)

    def _extract_error_keywords(self, error: str) -> List[str]:
        """æå–éŒ¯èª¤é—œéµè©"""
        # ç°¡å–®å¯¦ç¾ï¼šæå–å¸¸è¦‹éŒ¯èª¤é¡å‹
        keywords = []
        common_errors = [
            "timeout", "connection", "memory", "permission",
            "not found", "invalid", "failed", "error"
        ]

        error_lower = error.lower()
        for keyword in common_errors:
            if keyword in error_lower:
                keywords.append(keyword)

        return keywords

    def _generate_task_key(self, task_id: UUID) -> str:
        """ç”Ÿæˆä»»å‹™éµ"""
        return str(task_id)

    async def learn_from_history(self) -> List[LearningInsight]:
        """
        å¾æ­·å²è©¦é©—ä¸­å­¸ç¿’

        åˆ†ææ‰€æœ‰è©¦é©—æ­·å²ï¼Œæå–æ´å¯Ÿ
        """
        if sum(len(trials) for trials in self._trials.values()) < self.learning_threshold:
            return []

        insights = []

        # åˆ†ææˆåŠŸæ¨¡å¼
        success_insight = await self._analyze_success_patterns()
        if success_insight:
            insights.append(success_insight)

        # åˆ†æå¤±æ•—æ¨¡å¼
        failure_insight = await self._analyze_failure_patterns()
        if failure_insight:
            insights.append(failure_insight)

        # åˆ†æåƒæ•¸æ•ˆæœ
        param_insight = await self._analyze_parameter_effects()
        if param_insight:
            insights.append(param_insight)

        self._insights.extend(insights)
        return insights

    async def _analyze_success_patterns(self) -> Optional[LearningInsight]:
        """åˆ†ææˆåŠŸæ¨¡å¼"""
        successful_trials = [
            trial
            for trials in self._trials.values()
            for trial in trials
            if trial.status == TrialStatus.SUCCESS
        ]

        if len(successful_trials) < 3:
            return None

        # æ‰¾å‡ºå…±åŒåƒæ•¸
        common_params = self._find_common_parameters(
            [t.parameters for t in successful_trials]
        )

        if common_params:
            return LearningInsight(
                id=uuid4(),
                learning_type=LearningType.SUCCESS_PATTERN,
                pattern=f"æˆåŠŸæ¡ˆä¾‹çš„å…±åŒåƒæ•¸: {common_params}",
                confidence=len(common_params) / 10,  # ç°¡åŒ–çš„ä¿¡å¿ƒè¨ˆç®—
                evidence=[t.id for t in successful_trials[:5]],
                recommendation=f"å»ºè­°ä½¿ç”¨åƒæ•¸: {common_params}"
            )

        return None

    async def _analyze_failure_patterns(self) -> Optional[LearningInsight]:
        """åˆ†æå¤±æ•—æ¨¡å¼"""
        failed_trials = [
            trial
            for trials in self._trials.values()
            for trial in trials
            if trial.status == TrialStatus.FAILURE
        ]

        if len(failed_trials) < 3:
            return None

        # çµ±è¨ˆéŒ¯èª¤é¡å‹
        error_counts: Dict[str, int] = {}
        for trial in failed_trials:
            keywords = self._extract_error_keywords(trial.error or "")
            for kw in keywords:
                error_counts[kw] = error_counts.get(kw, 0) + 1

        if error_counts:
            most_common = max(error_counts.items(), key=lambda x: x[1])
            return LearningInsight(
                id=uuid4(),
                learning_type=LearningType.ERROR_PATTERN,
                pattern=f"æœ€å¸¸è¦‹éŒ¯èª¤: {most_common[0]} (å‡ºç¾ {most_common[1]} æ¬¡)",
                confidence=most_common[1] / len(failed_trials),
                evidence=[t.id for t in failed_trials[:5]],
                recommendation=f"å„ªå…ˆè™•ç† {most_common[0]} ç›¸é—œå•é¡Œ"
            )

        return None

    async def _analyze_parameter_effects(self) -> Optional[LearningInsight]:
        """åˆ†æåƒæ•¸æ•ˆæœ"""
        all_trials = [
            trial
            for trials in self._trials.values()
            for trial in trials
        ]

        if len(all_trials) < 5:
            return None

        # ç°¡åŒ–åˆ†æï¼šæ¯”è¼ƒæˆåŠŸå’Œå¤±æ•—çš„åƒæ•¸å·®ç•°
        success_params = [
            t.parameters for t in all_trials
            if t.status == TrialStatus.SUCCESS
        ]
        failure_params = [
            t.parameters for t in all_trials
            if t.status == TrialStatus.FAILURE
        ]

        if not success_params or not failure_params:
            return None

        # æ‰¾å‡ºå·®ç•°
        differences = self._find_parameter_differences(
            success_params, failure_params
        )

        if differences:
            return LearningInsight(
                id=uuid4(),
                learning_type=LearningType.PARAMETER_TUNING,
                pattern=f"å½±éŸ¿æˆåŠŸç‡çš„åƒæ•¸: {differences}",
                confidence=0.7,
                evidence=[t.id for t in all_trials[:5]],
                recommendation=f"èª¿æ•´åƒæ•¸: {differences}"
            )

        return None

    def _find_common_parameters(
        self,
        param_list: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ‰¾å‡ºå…±åŒåƒæ•¸"""
        if not param_list:
            return {}

        common = {}
        first = param_list[0]

        for key, value in first.items():
            if all(p.get(key) == value for p in param_list):
                common[key] = value

        return common

    def _find_parameter_differences(
        self,
        success_params: List[Dict[str, Any]],
        failure_params: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ‰¾å‡ºæˆåŠŸå’Œå¤±æ•—çš„åƒæ•¸å·®ç•°"""
        differences = {}

        # è¨ˆç®—æ¯å€‹åƒæ•¸çš„æˆåŠŸç‡
        all_keys = set()
        for p in success_params + failure_params:
            all_keys.update(p.keys())

        for key in all_keys:
            success_values = [p.get(key) for p in success_params if key in p]
            failure_values = [p.get(key) for p in failure_params if key in p]

            if success_values and failure_values:
                # ç°¡åŒ–ï¼šå¦‚æœå€¼ä¸åŒï¼Œè¨˜éŒ„
                if set(str(v) for v in success_values) != set(str(v) for v in failure_values):
                    differences[key] = {
                        "success_common": success_values[0],
                        "failure_common": failure_values[0]
                    }

        return differences

    def get_recommendations(
        self,
        task_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ç²å–å»ºè­°"""
        recommendations = []

        for insight in self._insights:
            rec = {
                "type": insight.learning_type.value,
                "pattern": insight.pattern,
                "recommendation": insight.recommendation,
                "confidence": insight.confidence
            }
            recommendations.append(rec)

        # æŒ‰ä¿¡å¿ƒæ’åº
        recommendations.sort(key=lambda x: x["confidence"], reverse=True)

        return recommendations
```

#### é©—æ”¶æ¨™æº–
- [ ] æ”¯æ´è‡ªå‹•é‡è©¦
- [ ] éŒ¯èª¤æ¨¡å¼è­˜åˆ¥
- [ ] è‡ªå‹•åƒæ•¸èª¿æ•´
- [ ] å­¸ç¿’æ´å¯Ÿæå–
- [ ] å»ºè­°ç”Ÿæˆ

---

### Story 10-5: Planning API è·¯ç”± (5 é»)

**ä½œç‚º** å‰ç«¯é–‹ç™¼è€…
**æˆ‘å¸Œæœ›** æœ‰å®Œæ•´çš„è¦åŠƒ API
**ä»¥ä¾¿** åœ¨ UI ä¸­å±•ç¤ºå’Œç®¡ç†åŸ·è¡Œè¨ˆåŠƒ

#### æŠ€è¡“è¦æ ¼

```python
# backend/src/api/v1/planning/routes.py

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from typing import List, Optional
from uuid import UUID
from pydantic import BaseModel, Field
from datetime import datetime

router = APIRouter(prefix="/planning", tags=["Planning"])


# ============ Schemas ============

class DecomposeTaskRequest(BaseModel):
    """ä»»å‹™åˆ†è§£è«‹æ±‚"""
    task_description: str = Field(..., description="ä»»å‹™æè¿°")
    context: Optional[dict] = Field(None, description="ä¸Šä¸‹æ–‡ä¿¡æ¯")
    strategy: str = Field(default="hybrid", description="åˆ†è§£ç­–ç•¥")

    class Config:
        json_schema_extra = {
            "example": {
                "task_description": "å¯¦ç¾ç”¨æˆ¶èªè­‰ç³»çµ±",
                "context": {"framework": "FastAPI", "database": "PostgreSQL"},
                "strategy": "hybrid"
            }
        }


class CreatePlanRequest(BaseModel):
    """å»ºç«‹è¨ˆåŠƒè«‹æ±‚"""
    goal: str = Field(..., description="ç›®æ¨™æè¿°")
    context: Optional[dict] = Field(None, description="ä¸Šä¸‹æ–‡")
    deadline: Optional[datetime] = Field(None, description="æˆªæ­¢æ™‚é–“")


class DecisionRequest(BaseModel):
    """æ±ºç­–è«‹æ±‚"""
    situation: str = Field(..., description="æƒ…æ³æè¿°")
    options: List[str] = Field(..., description="å¯é¸é¸é …")
    context: Optional[dict] = Field(None, description="ä¸Šä¸‹æ–‡")
    decision_type: str = Field(default="routing", description="æ±ºç­–é¡å‹")


class SubTaskResponse(BaseModel):
    """å­ä»»å‹™å›æ‡‰"""
    id: str
    name: str
    description: str
    priority: str
    status: str
    dependencies: List[str]
    estimated_duration_minutes: int


class DecompositionResponse(BaseModel):
    """åˆ†è§£çµæœå›æ‡‰"""
    task_id: str
    original_task: str
    subtasks: List[SubTaskResponse]
    execution_order: List[List[str]]
    estimated_total_duration: int
    confidence_score: float
    strategy: str


class PlanResponse(BaseModel):
    """è¨ˆåŠƒå›æ‡‰"""
    id: str
    name: str
    goal: str
    status: str
    progress: float
    current_phase: int
    total_phases: int
    subtasks_count: int
    created_at: datetime


class DecisionResponse(BaseModel):
    """æ±ºç­–å›æ‡‰"""
    decision_id: str
    action: str
    confidence: str
    reasoning: str
    risk_level: float
    requires_approval: bool


# ============ Routes ============

@router.post("/decompose", response_model=DecompositionResponse)
async def decompose_task(
    request: DecomposeTaskRequest,
    decomposer: TaskDecomposer = Depends(get_task_decomposer)
):
    """
    åˆ†è§£ä»»å‹™

    å°‡è¤‡é›œä»»å‹™åˆ†è§£ç‚ºå¯åŸ·è¡Œçš„å­ä»»å‹™
    """
    try:
        result = await decomposer.decompose(
            task_description=request.task_description,
            context=request.context,
            strategy=request.strategy
        )

        return DecompositionResponse(
            task_id=str(result.task_id),
            original_task=result.original_task,
            subtasks=[
                SubTaskResponse(
                    id=str(t.id),
                    name=t.name,
                    description=t.description,
                    priority=t.priority.value,
                    status=t.status.value,
                    dependencies=[str(d) for d in t.dependencies],
                    estimated_duration_minutes=t.estimated_duration_minutes
                )
                for t in result.subtasks
            ],
            execution_order=[[str(tid) for tid in layer] for layer in result.execution_order],
            estimated_total_duration=result.estimated_total_duration,
            confidence_score=result.confidence_score,
            strategy=result.decomposition_strategy
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/decompose/{task_id}/refine")
async def refine_decomposition(
    task_id: UUID,
    feedback: str,
    decomposer: TaskDecomposer = Depends(get_task_decomposer)
):
    """æ ¹æ“šåé¥‹ç²¾ç…‰åˆ†è§£çµæœ"""
    # éœ€è¦ä¿å­˜åŸå§‹çµæœä»¥ä¾¿ç²¾ç…‰
    # é€™è£¡ç°¡åŒ–è™•ç†
    raise HTTPException(status_code=501, detail="Not implemented yet")


@router.post("/plans", response_model=PlanResponse)
async def create_plan(
    request: CreatePlanRequest,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """å»ºç«‹åŸ·è¡Œè¨ˆåŠƒ"""
    try:
        plan = await planner.create_plan(
            goal=request.goal,
            context=request.context,
            deadline=request.deadline
        )

        return PlanResponse(
            id=str(plan.id),
            name=plan.name,
            goal=plan.goal,
            status=plan.status.value,
            progress=plan.progress_percentage,
            current_phase=plan.current_phase,
            total_phases=len(plan.decomposition.execution_order),
            subtasks_count=len(plan.decomposition.subtasks),
            created_at=plan.created_at
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/plans/{plan_id}", response_model=PlanResponse)
async def get_plan(
    plan_id: UUID,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """ç²å–è¨ˆåŠƒè©³æƒ…"""
    status = planner.get_plan_status(plan_id)
    if "error" in status:
        raise HTTPException(status_code=404, detail=status["error"])

    return status


@router.post("/plans/{plan_id}/approve")
async def approve_plan(
    plan_id: UUID,
    approver: str,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """æ‰¹å‡†è¨ˆåŠƒ"""
    await planner.approve_plan(plan_id, approver)
    return {"status": "approved", "plan_id": str(plan_id)}


@router.post("/plans/{plan_id}/execute")
async def execute_plan(
    plan_id: UUID,
    background_tasks: BackgroundTasks,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """
    é–‹å§‹åŸ·è¡Œè¨ˆåŠƒ

    åœ¨èƒŒæ™¯åŸ·è¡Œï¼Œç«‹å³è¿”å›
    """
    async def execution_callback(subtask):
        # å¯¦éš›çš„ä»»å‹™åŸ·è¡Œé‚è¼¯
        import asyncio
        await asyncio.sleep(1)  # æ¨¡æ“¬åŸ·è¡Œ
        return {"executed": subtask.name}

    # åœ¨èƒŒæ™¯åŸ·è¡Œ
    background_tasks.add_task(
        planner.execute_plan,
        plan_id,
        execution_callback
    )

    return {
        "status": "started",
        "plan_id": str(plan_id),
        "message": "Plan execution started in background"
    }


@router.get("/plans/{plan_id}/status")
async def get_plan_execution_status(
    plan_id: UUID,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """ç²å–è¨ˆåŠƒåŸ·è¡Œç‹€æ…‹"""
    return planner.get_plan_status(plan_id)


@router.post("/plans/{plan_id}/pause")
async def pause_plan(
    plan_id: UUID,
    planner: DynamicPlanner = Depends(get_dynamic_planner)
):
    """æš«åœè¨ˆåŠƒåŸ·è¡Œ"""
    # å¯¦ç¾æš«åœé‚è¼¯
    return {"status": "paused", "plan_id": str(plan_id)}


@router.post("/decisions", response_model=DecisionResponse)
async def make_decision(
    request: DecisionRequest,
    decision_engine: AutonomousDecisionEngine = Depends(get_decision_engine)
):
    """
    è«‹æ±‚æ±ºç­–

    æ ¹æ“šæƒ…æ³å’Œé¸é …åšå‡ºæœ€ä½³æ±ºç­–
    """
    try:
        from src.domain.orchestration.planning.decision_engine import DecisionType

        result = await decision_engine.make_decision(
            situation=request.situation,
            options=request.options,
            context=request.context,
            decision_type=DecisionType(request.decision_type)
        )

        return DecisionResponse(
            decision_id=result["decision_id"],
            action=result["action"],
            confidence=result["confidence"],
            reasoning=result["reasoning"],
            risk_level=result["risk_level"],
            requires_approval=result["requires_approval"]
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/decisions/{decision_id}/explain")
async def explain_decision(
    decision_id: UUID,
    decision_engine: AutonomousDecisionEngine = Depends(get_decision_engine)
):
    """è§£é‡‹æ±ºç­–"""
    explanation = await decision_engine.explain_decision(decision_id)
    return {"explanation": explanation}


@router.post("/trial")
async def execute_with_trial(
    task_id: UUID,
    params: dict,
    strategy: str = "default",
    trial_engine: TrialAndErrorEngine = Depends(get_trial_engine)
):
    """
    ä½¿ç”¨è©¦éŒ¯æ©Ÿåˆ¶åŸ·è¡Œä»»å‹™
    """
    async def dummy_execution(**kwargs):
        import random
        if random.random() < 0.3:  # 30% å¤±æ•—ç‡
            raise Exception("Random failure for testing")
        return {"success": True, **kwargs}

    result = await trial_engine.execute_with_retry(
        task_id=task_id,
        execution_fn=dummy_execution,
        initial_params=params,
        strategy=strategy
    )

    return result


@router.get("/trial/insights")
async def get_learning_insights(
    trial_engine: TrialAndErrorEngine = Depends(get_trial_engine)
):
    """ç²å–å­¸ç¿’æ´å¯Ÿ"""
    insights = await trial_engine.learn_from_history()

    return {
        "insights": [
            {
                "id": str(i.id),
                "type": i.learning_type.value,
                "pattern": i.pattern,
                "confidence": i.confidence,
                "recommendation": i.recommendation
            }
            for i in insights
        ]
    }


@router.get("/recommendations")
async def get_recommendations(
    task_type: Optional[str] = None,
    trial_engine: TrialAndErrorEngine = Depends(get_trial_engine)
):
    """ç²å–åŸ·è¡Œå»ºè­°"""
    return {"recommendations": trial_engine.get_recommendations(task_type)}
```

#### é©—æ”¶æ¨™æº–
- [ ] ä»»å‹™åˆ†è§£ API å®Œæ•´
- [ ] è¨ˆåŠƒç®¡ç† API å®Œæ•´
- [ ] æ±ºç­– API å®Œæ•´
- [ ] è©¦éŒ¯åŸ·è¡Œ API å®Œæ•´
- [ ] API æ–‡æª”å®Œæ•´

---

## æ¸¬è©¦è¨ˆåŠƒ

### å–®å…ƒæ¸¬è©¦

```python
# tests/unit/test_task_decomposer.py

import pytest
from unittest.mock import AsyncMock, MagicMock
from uuid import uuid4

from src.domain.orchestration.planning.task_decomposer import (
    TaskDecomposer,
    TaskPriority,
    DependencyType
)


@pytest.fixture
def mock_llm_service():
    service = MagicMock()
    service.generate = AsyncMock(return_value="""
    {
        "subtasks": [
            {
                "name": "è¨­è¨ˆè³‡æ–™åº«æ¶æ§‹",
                "description": "è¨­è¨ˆç”¨æˆ¶è¡¨å’Œèªè­‰ç›¸é—œè¡¨",
                "priority": "high",
                "dependencies": [],
                "estimated_minutes": 60
            },
            {
                "name": "å¯¦ç¾ç”¨æˆ¶è¨»å†Š",
                "description": "å»ºç«‹è¨»å†Š API å’Œé©—è­‰é‚è¼¯",
                "priority": "high",
                "dependencies": ["è¨­è¨ˆè³‡æ–™åº«æ¶æ§‹"],
                "estimated_minutes": 120
            },
            {
                "name": "å¯¦ç¾ç”¨æˆ¶ç™»å…¥",
                "description": "å»ºç«‹ç™»å…¥ API å’Œ JWT ç”Ÿæˆ",
                "priority": "high",
                "dependencies": ["è¨­è¨ˆè³‡æ–™åº«æ¶æ§‹"],
                "estimated_minutes": 90
            }
        ],
        "reasoning": "æŒ‰ç…§ä¾è³´é—œä¿‚åˆ†è§£"
    }
    """)
    return service


@pytest.fixture
def decomposer(mock_llm_service):
    return TaskDecomposer(
        llm_service=mock_llm_service,
        agent_registry=MagicMock(),
        max_subtasks=20
    )


@pytest.mark.asyncio
async def test_decompose_task(decomposer):
    """æ¸¬è©¦ä»»å‹™åˆ†è§£"""
    result = await decomposer.decompose(
        task_description="å¯¦ç¾ç”¨æˆ¶èªè­‰ç³»çµ±",
        strategy="hybrid"
    )

    assert result.original_task == "å¯¦ç¾ç”¨æˆ¶èªè­‰ç³»çµ±"
    assert len(result.subtasks) == 3
    assert result.confidence_score > 0


@pytest.mark.asyncio
async def test_execution_order(decomposer):
    """æ¸¬è©¦åŸ·è¡Œé †åº"""
    result = await decomposer.decompose(
        task_description="æ¸¬è©¦ä»»å‹™",
        strategy="sequential"
    )

    # æ‡‰è©²æœ‰åˆ†å±¤çš„åŸ·è¡Œé †åº
    assert len(result.execution_order) > 0

    # ç¬¬ä¸€å±¤æ‡‰è©²æ²’æœ‰ä¾è³´
    first_layer = result.execution_order[0]
    for task_id in first_layer:
        task = next(t for t in result.subtasks if t.id == task_id)
        assert len(task.dependencies) == 0


@pytest.mark.asyncio
async def test_duration_estimation(decomposer):
    """æ¸¬è©¦æ™‚é–“ä¼°ç®—"""
    result = await decomposer.decompose(
        task_description="æ¸¬è©¦ä»»å‹™",
        strategy="parallel"
    )

    # ä¸¦è¡Œä»»å‹™çš„ç¸½æ™‚é–“æ‡‰è©²ç­‰æ–¼æœ€é•·è·¯å¾‘
    assert result.estimated_total_duration > 0
    assert result.estimated_total_duration <= sum(
        t.estimated_duration_minutes for t in result.subtasks
    )


# tests/unit/test_decision_engine.py

@pytest.mark.asyncio
async def test_make_decision():
    """æ¸¬è©¦æ±ºç­–"""
    llm_service = MagicMock()
    llm_service.generate = AsyncMock(return_value="""
    [
        {
            "id": "option_a",
            "name": "Option A",
            "description": "First option",
            "pros": ["Fast", "Simple"],
            "cons": ["Limited"],
            "risk_level": 0.2,
            "estimated_impact": 0.8
        },
        {
            "id": "option_b",
            "name": "Option B",
            "description": "Second option",
            "pros": ["Comprehensive"],
            "cons": ["Complex", "Slow"],
            "risk_level": 0.5,
            "estimated_impact": 0.9
        }
    ]
    """)

    engine = AutonomousDecisionEngine(
        llm_service=llm_service
    )

    result = await engine.make_decision(
        situation="é¸æ“‡å¯¦ç¾æ–¹æ¡ˆ",
        options=["option_a", "option_b"]
    )

    assert "action" in result
    assert "confidence" in result
    assert "reasoning" in result
    assert result["action"] in ["option_a", "option_b"]


@pytest.mark.asyncio
async def test_decision_with_rules():
    """æ¸¬è©¦å¸¶è¦å‰‡çš„æ±ºç­–"""
    engine = AutonomousDecisionEngine(
        llm_service=MagicMock()
    )

    # æ·»åŠ è¦å‰‡
    engine.add_rule(
        name="urgent_rule",
        condition=lambda s, o: "urgent" in s.lower(),
        action="immediate_action"
    )

    # æ¸¬è©¦è¦å‰‡åŒ¹é…
    action = await engine.apply_rules(
        situation="This is urgent!",
        options=["a", "b", "c"]
    )

    assert action == "immediate_action"
```

### æ•´åˆæ¸¬è©¦

```python
# tests/integration/test_planning_flow.py

import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_full_planning_flow(client: AsyncClient):
    """æ¸¬è©¦å®Œæ•´çš„è¦åŠƒæµç¨‹"""
    # 1. åˆ†è§£ä»»å‹™
    response = await client.post(
        "/api/v1/planning/decompose",
        json={
            "task_description": "å»ºç«‹ REST API æœå‹™",
            "strategy": "hybrid"
        }
    )
    assert response.status_code == 200
    decomposition = response.json()
    assert len(decomposition["subtasks"]) > 0

    # 2. å»ºç«‹è¨ˆåŠƒ
    response = await client.post(
        "/api/v1/planning/plans",
        json={
            "goal": "å»ºç«‹ REST API æœå‹™"
        }
    )
    assert response.status_code == 200
    plan = response.json()
    plan_id = plan["id"]

    # 3. æ‰¹å‡†è¨ˆåŠƒ
    response = await client.post(
        f"/api/v1/planning/plans/{plan_id}/approve",
        params={"approver": "test_user"}
    )
    assert response.status_code == 200

    # 4. ç²å–ç‹€æ…‹
    response = await client.get(
        f"/api/v1/planning/plans/{plan_id}/status"
    )
    assert response.status_code == 200
    assert response.json()["status"] == "approved"
```

---

## è³‡æ–™åº«é·ç§»

```sql
-- migrations/versions/010_planning_tables.sql

-- ä»»å‹™åˆ†è§£è¡¨
CREATE TABLE task_decompositions (
    id UUID PRIMARY KEY,
    original_task TEXT NOT NULL,
    strategy VARCHAR(50) NOT NULL,
    confidence_score DECIMAL(3,2),
    estimated_total_duration INTEGER,
    context JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å­ä»»å‹™è¡¨
CREATE TABLE subtasks (
    id UUID PRIMARY KEY,
    decomposition_id UUID REFERENCES task_decompositions(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    priority VARCHAR(20) NOT NULL DEFAULT 'medium',
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    assigned_agent_id UUID REFERENCES agents(id),
    dependencies UUID[] DEFAULT '{}',
    dependency_type VARCHAR(50) DEFAULT 'finish_to_start',
    estimated_duration_minutes INTEGER DEFAULT 30,
    actual_duration_minutes INTEGER,
    inputs JSONB DEFAULT '{}',
    outputs JSONB DEFAULT '{}',
    metadata JSONB DEFAULT '{}',
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åŸ·è¡Œè¨ˆåŠƒè¡¨
CREATE TABLE execution_plans (
    id UUID PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    goal TEXT NOT NULL,
    decomposition_id UUID REFERENCES task_decompositions(id),
    status VARCHAR(50) NOT NULL DEFAULT 'draft',
    current_phase INTEGER DEFAULT 0,
    progress_percentage DECIMAL(5,2) DEFAULT 0,
    deadline TIMESTAMP,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- è¨ˆåŠƒèª¿æ•´è¡¨
CREATE TABLE plan_adjustments (
    id UUID PRIMARY KEY,
    plan_id UUID REFERENCES execution_plans(id) ON DELETE CASCADE,
    trigger_event VARCHAR(50) NOT NULL,
    original_state JSONB NOT NULL,
    new_state JSONB NOT NULL,
    reason TEXT,
    approved BOOLEAN DEFAULT false,
    approved_by VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ±ºç­–è¨˜éŒ„è¡¨
CREATE TABLE decisions (
    id UUID PRIMARY KEY,
    decision_type VARCHAR(50) NOT NULL,
    situation TEXT NOT NULL,
    options_considered JSONB NOT NULL,
    selected_option VARCHAR(255) NOT NULL,
    confidence VARCHAR(20) NOT NULL,
    reasoning TEXT,
    risk_assessment JSONB DEFAULT '{}',
    human_approved BOOLEAN,
    execution_result JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è©¦é©—è¨˜éŒ„è¡¨
CREATE TABLE trials (
    id UUID PRIMARY KEY,
    task_id UUID NOT NULL,
    attempt_number INTEGER NOT NULL,
    parameters JSONB NOT NULL,
    strategy VARCHAR(100),
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    result JSONB,
    error TEXT,
    duration_ms INTEGER,
    metadata JSONB DEFAULT '{}',
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å­¸ç¿’æ´å¯Ÿè¡¨
CREATE TABLE learning_insights (
    id UUID PRIMARY KEY,
    learning_type VARCHAR(50) NOT NULL,
    pattern TEXT NOT NULL,
    confidence DECIMAL(3,2),
    evidence UUID[] DEFAULT '{}',
    recommendation TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_subtasks_decomposition ON subtasks(decomposition_id);
CREATE INDEX idx_subtasks_status ON subtasks(status);
CREATE INDEX idx_execution_plans_status ON execution_plans(status);
CREATE INDEX idx_decisions_type ON decisions(decision_type);
CREATE INDEX idx_trials_task ON trials(task_id);
CREATE INDEX idx_trials_status ON trials(status);
```

---

## é¢¨éšªèˆ‡ç·©è§£

| é¢¨éšª | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|------|----------|
| LLM åˆ†è§£è³ªé‡ä¸ç©©å®š | é«˜ | å¤šæ¬¡åˆ†è§£å–æœ€ä½³ã€äººå·¥å¯©æ ¸ |
| è‡ªä¸»æ±ºç­–éŒ¯èª¤ | é«˜ | ä¿¡å¿ƒé–¾å€¼ã€äººå·¥ç¢ºèªæ©Ÿåˆ¶ |
| ç„¡é™é‡è©¦å¾ªç’° | ä¸­ | æœ€å¤§é‡è©¦æ¬¡æ•¸é™åˆ¶ |
| è¦åŠƒæ™‚é–“éé•· | ä¸­ | ç•°æ­¥åŸ·è¡Œã€é€²åº¦åé¥‹ |
| å­¸ç¿’æ•¸æ“šä¸è¶³ | ä½ | è¨­ç½®æœ€å°é–¾å€¼ã€æä¾›é è¨­è¦å‰‡ |

---

## Definition of Done

- [ ] æ‰€æœ‰ User Stories å®Œæˆ
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ > 85%
- [ ] æ•´åˆæ¸¬è©¦é€šé
- [ ] API æ–‡æª”æ›´æ–°
- [ ] è³‡æ–™åº«é·ç§»è…³æœ¬æº–å‚™å®Œæˆ
- [ ] ç¨‹å¼ç¢¼å¯©æŸ¥å®Œæˆ
- [ ] æ•ˆèƒ½æ¸¬è©¦é€šéï¼ˆåˆ†è§£ < 10ç§’ï¼Œæ±ºç­– < 5ç§’ï¼‰

---

**ä¸‹ä¸€æ­¥**: [Sprint 11 - åµŒå¥—å·¥ä½œæµ](./sprint-11-plan.md)
