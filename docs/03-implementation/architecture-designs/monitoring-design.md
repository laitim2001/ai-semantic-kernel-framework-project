# Monitoring ç›£æ§æ¶æ§‹è¨­è¨ˆ

**Story**: S0-8 - Monitoring Setup (Hybrid)
**ç›®æ¨™**: é…ç½®æ··åˆç›£æ§æ–¹æ¡ˆï¼ˆAzure Monitor + Application Insights + Prometheusï¼‰
**Story Points**: 5

---

## ğŸ“‹ ç›®éŒ„

1. [ç›£æ§ç­–ç•¥æ¦‚è¿°](#ç›£æ§ç­–ç•¥æ¦‚è¿°)
2. [æ¶æ§‹è¨­è¨ˆ](#æ¶æ§‹è¨­è¨ˆ)
3. [Azure Monitor é…ç½®](#azure-monitor-é…ç½®)
4. [Application Insights é…ç½®](#application-insights-é…ç½®)
5. [OpenTelemetry æ•´åˆ](#opentelemetry-æ•´åˆ)
6. [Prometheus Metricsï¼ˆå¯é¸ï¼‰](#prometheus-metricså¯é¸)
7. [å¥åº·æª¢æŸ¥ç«¯é»](#å¥åº·æª¢æŸ¥ç«¯é»)
8. [å‘Šè­¦è¦å‰‡](#å‘Šè­¦è¦å‰‡)
9. [å„€è¡¨æ¿è¨­è¨ˆ](#å„€è¡¨æ¿è¨­è¨ˆ)
10. [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)

---

## ç›£æ§ç­–ç•¥æ¦‚è¿°

### æ··åˆç›£æ§æ–¹æ¡ˆ

æ¡ç”¨ **Azure åŸç”Ÿ + é–‹æºè£œå……** çš„æ··åˆç­–ç•¥ï¼š

| ç›£æ§é¡å‹ | ä¸»è¦å·¥å…· | è£œå……å·¥å…· | ç”¨é€” |
|---------|---------|---------|------|
| **åŸºç¤ç›£æ§** | Azure Monitor | - | CPUã€è¨˜æ†¶é«”ã€ç¶²è·¯ã€ç£ç¢Ÿ |
| **æ‡‰ç”¨ç›£æ§** | Application Insights | - | è«‹æ±‚è¿½è¹¤ã€ä¾è³´é—œä¿‚ã€ç•°å¸¸ |
| **æ—¥èªŒç®¡ç†** | Application Insights | - | é›†ä¸­å¼æ—¥èªŒã€æŸ¥è©¢åˆ†æ |
| **æ¥­å‹™æŒ‡æ¨™** | Application Insights | Prometheus | è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™ |
| **åˆ†æ•£å¼è¿½è¹¤** | Application Insights | - | ç«¯åˆ°ç«¯è«‹æ±‚è¿½è¹¤ |

### ç‚ºä»€éº¼é¸æ“‡æ··åˆæ–¹æ¡ˆï¼Ÿ

#### Azure Monitor + Application Insights å„ªå‹¢

âœ… **ç„¡ç¸«æ•´åˆ**: èˆ‡ Azure App Service åŸç”Ÿæ•´åˆï¼Œé›¶é…ç½®ç›£æ§
âœ… **è‡ªå‹•æª¢æ¸¬**: è‡ªå‹•è¿½è¹¤ HTTP è«‹æ±‚ã€ä¾è³´é—œä¿‚ã€ç•°å¸¸
âœ… **æ™ºèƒ½åˆ†æ**: Application Mapã€Live Metricsã€æ™ºèƒ½æª¢æ¸¬
âœ… **ä½ç¶­è­·æˆæœ¬**: ç„¡éœ€è‡ªå»ºåŸºç¤è¨­æ–½
âœ… **çµ±ä¸€ç®¡ç†**: Azure Portal çµ±ä¸€æŸ¥çœ‹æ‰€æœ‰ç›£æ§æ•¸æ“š

#### Prometheus è£œå……ï¼ˆå¯é¸ï¼‰

âœ… **æ¥­å‹™æŒ‡æ¨™**: è‡ªå®šç¾©æ¥­å‹™ç›¸é—œçš„ç´°ç²’åº¦æŒ‡æ¨™
âœ… **éˆæ´»æŸ¥è©¢**: PromQL å¼·å¤§çš„æŸ¥è©¢èªè¨€
âœ… **é–‹æºç”Ÿæ…‹**: èˆ‡ Grafana å®Œç¾æ•´åˆ
âœ… **æœªä¾†é·ç§»**: ä¿ç•™éé›²ä¾›æ‡‰å•†é–å®šçš„é¸é …

---

## æ¶æ§‹è¨­è¨ˆ

### æ•´é«”æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   FastAPI    â”‚  â”‚  Background  â”‚  â”‚   Workers    â”‚      â”‚
â”‚  â”‚   Server     â”‚  â”‚    Tasks     â”‚  â”‚              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                            â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ OpenTelemetry  â”‚      â”‚   Prometheus     â”‚
        â”‚   Exporter     â”‚      â”‚   Client         â”‚
        â”‚                â”‚      â”‚  (Optional)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Application   â”‚      â”‚   Prometheus     â”‚
        â”‚   Insights     â”‚      â”‚    Server        â”‚
        â”‚                â”‚      â”‚  (Optional)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Azure Monitor                     â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
        â”‚  â”‚  Alerts  â”‚  â”‚   Logs   â”‚  â”‚ Metrics â”‚â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Azure Portal  â”‚      â”‚     Grafana      â”‚
        â”‚   Dashboard    â”‚      â”‚   (Optional)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•¸æ“šæµ

```
Application â†’ OpenTelemetry SDK â†’ Application Insights â†’ Azure Monitor
     â”‚
     â””â”€â†’ Prometheus Client â†’ Prometheus Server â†’ Grafana (Optional)
```

---

## Azure Monitor é…ç½®

### 1. Application Insights è³‡æº

#### ä½¿ç”¨ Terraform å‰µå»º

```hcl
# infrastructure/terraform/monitoring.tf

resource "azurerm_application_insights" "app_insights" {
  name                = "ai-framework-appinsights-${var.environment}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  application_type    = "web"

  # å·¥ä½œå€æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰
  workspace_id = azurerm_log_analytics_workspace.main.id

  # è³‡æ–™ä¿ç•™æœŸé™
  retention_in_days = var.environment == "production" ? 90 : 30

  # æ¡æ¨£ç‡ï¼ˆç”Ÿç”¢ç’°å¢ƒå»ºè­°å•Ÿç”¨ï¼‰
  sampling_percentage = var.environment == "production" ? 20 : 100

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# Log Analytics Workspace
resource "azurerm_log_analytics_workspace" "main" {
  name                = "ai-framework-logs-${var.environment}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  sku                 = "PerGB2018"
  retention_in_days   = var.environment == "production" ? 90 : 30

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# Output connection string
output "appinsights_connection_string" {
  value     = azurerm_application_insights.app_insights.connection_string
  sensitive = true
}

output "appinsights_instrumentation_key" {
  value     = azurerm_application_insights.app_insights.instrumentation_key
  sensitive = true
}
```

### 2. App Service æ•´åˆ

```hcl
# App Service è‡ªå‹•å•Ÿç”¨ Application Insights
resource "azurerm_linux_web_app" "backend" {
  # ... å…¶ä»–é…ç½® ...

  app_settings = {
    # Application Insights
    "APPLICATIONINSIGHTS_CONNECTION_STRING" = azurerm_application_insights.app_insights.connection_string
    "ApplicationInsightsAgent_EXTENSION_VERSION" = "~3"
    "XDT_MicrosoftApplicationInsights_Mode" = "recommended"

    # OpenTelemetry é…ç½®
    "OTEL_EXPORTER_OTLP_ENDPOINT" = "https://dc.services.visualstudio.com/v2/track"
    "OTEL_SERVICE_NAME" = "ai-framework-backend-${var.environment}"
  }
}
```

---

## Application Insights é…ç½®

### 1. Python SDK æ•´åˆ

#### å®‰è£ä¾è³´

```txt
# requirements.txt
azure-monitor-opentelemetry==1.2.0
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-instrumentation-fastapi==0.42b0
opentelemetry-instrumentation-sqlalchemy==0.42b0
opentelemetry-instrumentation-redis==0.42b0
opentelemetry-instrumentation-httpx==0.42b0
```

#### é…ç½®ä»£ç¢¼

```python
# backend/src/core/telemetry.py
"""
OpenTelemetry é…ç½®
"""
import logging
from typing import Optional

from azure.monitor.opentelemetry import configure_azure_monitor
from opentelemetry import trace, metrics
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor
from opentelemetry.sdk.resources import Resource, SERVICE_NAME, SERVICE_VERSION

from src.core.config import settings

logger = logging.getLogger(__name__)


def setup_telemetry(app) -> None:
    """
    é…ç½® OpenTelemetry å’Œ Application Insights

    Args:
        app: FastAPI application instance
    """
    if not settings.appinsights_connection_string:
        logger.warning("Application Insights not configured")
        return

    try:
        # é…ç½® Azure Monitor
        configure_azure_monitor(
            connection_string=settings.appinsights_connection_string,
            resource=Resource.create({
                SERVICE_NAME: settings.app_name,
                SERVICE_VERSION: settings.app_version,
                "deployment.environment": settings.environment,
            }),
            # æ—¥èªŒç´šåˆ¥
            logging_level=logging.INFO if settings.environment == "production" else logging.DEBUG,
            # æ¡æ¨£ç‡ï¼ˆç”Ÿç”¢ç’°å¢ƒé™ä½æˆæœ¬ï¼‰
            trace_sampler=get_sampler(),
        )

        # è‡ªå‹•æª¢æ¸¬ FastAPI
        FastAPIInstrumentor.instrument_app(
            app,
            excluded_urls="health,metrics,readiness,liveness",  # æ’é™¤å¥åº·æª¢æŸ¥
        )

        # è‡ªå‹•æª¢æ¸¬ SQLAlchemyï¼ˆåœ¨ engine å‰µå»ºå¾Œèª¿ç”¨ï¼‰
        # SQLAlchemyInstrumentor().instrument(
        #     engine=engine,
        #     service="ai-framework-db"
        # )

        # è‡ªå‹•æª¢æ¸¬ Redis
        RedisInstrumentor().instrument()

        # è‡ªå‹•æª¢æ¸¬ HTTPXï¼ˆå¤–éƒ¨ HTTP èª¿ç”¨ï¼‰
        HTTPXClientInstrumentor().instrument()

        logger.info("Application Insights configured successfully")

    except Exception as e:
        logger.error(f"Failed to configure Application Insights: {e}")


def get_sampler():
    """ç²å–æ¡æ¨£å™¨é…ç½®"""
    from opentelemetry.sdk.trace.sampling import (
        ParentBasedTraceIdRatioBased,
        ALWAYS_ON,
    )

    if settings.environment == "production":
        # ç”Ÿç”¢ç’°å¢ƒï¼š20% æ¡æ¨£ç‡
        return ParentBasedTraceIdRatioBased(0.2)
    else:
        # é–‹ç™¼/æ¸¬è©¦ç’°å¢ƒï¼š100% æ¡æ¨£
        return ALWAYS_ON


def get_tracer(name: str) -> trace.Tracer:
    """
    ç²å– Tracer å¯¦ä¾‹

    Args:
        name: Tracer åç¨±

    Returns:
        Tracer instance
    """
    return trace.get_tracer(name)


def get_meter(name: str) -> metrics.Meter:
    """
    ç²å– Meter å¯¦ä¾‹ï¼ˆç”¨æ–¼è‡ªå®šç¾©æŒ‡æ¨™ï¼‰

    Args:
        name: Meter åç¨±

    Returns:
        Meter instance
    """
    return metrics.get_meter(name)
```

### 2. ä¸»æ‡‰ç”¨é›†æˆ

```python
# backend/main.py
from src.core.telemetry import setup_telemetry

app = FastAPI(
    title="IPA Platform API",
    # ...
)

# é…ç½®ç›£æ§ï¼ˆåœ¨æ‰€æœ‰ä¸­é–“ä»¶å’Œè·¯ç”±ä¹‹å¾Œï¼‰
setup_telemetry(app)

# CORS ç­‰å…¶ä»–ä¸­é–“ä»¶...
```

### 3. è‡ªå®šç¾©è¿½è¹¤ç¯„ä¾‹

```python
# backend/src/domain/workflow/workflow_service.py
from opentelemetry import trace
from src.core.telemetry import get_tracer

tracer = get_tracer(__name__)

class WorkflowService:
    async def execute_workflow(self, workflow_id: str):
        # å‰µå»ºè‡ªå®šç¾© Span
        with tracer.start_as_current_span("execute_workflow") as span:
            span.set_attribute("workflow.id", workflow_id)
            span.set_attribute("workflow.type", "automated")

            try:
                # åŸ·è¡Œå·¥ä½œæµé‚è¼¯
                result = await self._do_execute(workflow_id)

                span.set_attribute("workflow.status", "success")
                span.set_attribute("workflow.duration_ms", result.duration)

                return result

            except Exception as e:
                span.set_attribute("workflow.status", "failed")
                span.set_attribute("workflow.error", str(e))
                span.record_exception(e)
                raise
```

### 4. è‡ªå®šç¾©æŒ‡æ¨™ç¯„ä¾‹

```python
# backend/src/infrastructure/metrics/custom_metrics.py
"""
è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™
"""
from opentelemetry import metrics
from src.core.telemetry import get_meter

meter = get_meter(__name__)

# Counter: è¨ˆæ•¸å™¨ï¼ˆåªå¢ä¸æ¸›ï¼‰
workflow_executions_total = meter.create_counter(
    name="workflow.executions.total",
    description="Total number of workflow executions",
    unit="1",
)

workflow_failures_total = meter.create_counter(
    name="workflow.failures.total",
    description="Total number of workflow failures",
    unit="1",
)

# Histogram: ç›´æ–¹åœ–ï¼ˆåˆ†ä½ˆçµ±è¨ˆï¼‰
workflow_duration = meter.create_histogram(
    name="workflow.duration",
    description="Workflow execution duration",
    unit="ms",
)

# UpDownCounter: å¯å¢å¯æ¸›è¨ˆæ•¸å™¨
active_workflows = meter.create_up_down_counter(
    name="workflow.active",
    description="Number of currently active workflows",
    unit="1",
)

# ä½¿ç”¨ç¯„ä¾‹
def record_workflow_execution(workflow_id: str, duration_ms: float, success: bool):
    """è¨˜éŒ„å·¥ä½œæµåŸ·è¡ŒæŒ‡æ¨™"""
    attributes = {
        "workflow.id": workflow_id,
        "workflow.status": "success" if success else "failure",
    }

    workflow_executions_total.add(1, attributes)
    workflow_duration.record(duration_ms, attributes)

    if not success:
        workflow_failures_total.add(1, attributes)
```

---

## Prometheus Metricsï¼ˆå¯é¸ï¼‰

### 1. ç‚ºä»€éº¼éœ€è¦ Prometheusï¼Ÿ

é›–ç„¶ Application Insights å·²ç¶“æä¾›äº†å®Œæ•´çš„ç›£æ§èƒ½åŠ›ï¼Œä½† Prometheus æä¾›ï¼š

- **æ¥­å‹™æŒ‡æ¨™**: æ›´ç´°ç²’åº¦çš„è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™
- **é–‹æºç”Ÿæ…‹**: èˆ‡ Grafana å®Œç¾æ•´åˆ
- **PromQL**: å¼·å¤§çš„æŸ¥è©¢èªè¨€
- **éé›²é–å®š**: ä¿ç•™æœªä¾†é·ç§»å½ˆæ€§

### 2. Prometheus Client æ•´åˆ

#### å®‰è£ä¾è³´

```txt
# requirements.txt
prometheus-client==0.19.0
prometheus-fastapi-instrumentator==6.1.0
```

#### é…ç½®ä»£ç¢¼

```python
# backend/src/infrastructure/metrics/prometheus_metrics.py
"""
Prometheus æŒ‡æ¨™é…ç½®
"""
from prometheus_client import Counter, Histogram, Gauge, Info
from prometheus_fastapi_instrumentator import Instrumentator, metrics

# è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™
workflow_executions = Counter(
    'workflow_executions_total',
    'Total workflow executions',
    ['workflow_type', 'status']
)

workflow_duration = Histogram(
    'workflow_duration_seconds',
    'Workflow execution duration',
    ['workflow_type'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
)

active_workflows = Gauge(
    'active_workflows',
    'Number of currently active workflows',
    ['workflow_type']
)

queue_depth = Gauge(
    'queue_depth',
    'Message queue depth',
    ['queue_name']
)

cache_hits = Counter(
    'cache_hits_total',
    'Total cache hits',
    ['cache_type']
)

cache_misses = Counter(
    'cache_misses_total',
    'Total cache misses',
    ['cache_type']
)

# ç³»çµ±ä¿¡æ¯
app_info = Info('app', 'Application information')
app_info.info({
    'version': '0.1.0',
    'environment': 'production',
})


def setup_prometheus(app):
    """
    é…ç½® Prometheus metrics

    Args:
        app: FastAPI application
    """
    instrumentator = Instrumentator(
        should_group_status_codes=True,
        should_ignore_untemplated=True,
        should_respect_env_var=True,
        should_instrument_requests_inprogress=True,
        excluded_handlers=["/health", "/metrics", "/readiness", "/liveness"],
        inprogress_name="http_requests_inprogress",
        inprogress_labels=True,
    )

    # æ·»åŠ é»˜èªæŒ‡æ¨™
    instrumentator.add(
        metrics.request_size(
            should_include_handler=True,
            should_include_method=True,
            should_include_status=True,
        )
    )
    instrumentator.add(
        metrics.response_size(
            should_include_handler=True,
            should_include_method=True,
            should_include_status=True,
        )
    )
    instrumentator.add(
        metrics.latency(
            should_include_handler=True,
            should_include_method=True,
            should_include_status=True,
        )
    )
    instrumentator.add(metrics.requests())

    # æš´éœ² /metrics ç«¯é»
    instrumentator.instrument(app).expose(app, endpoint="/metrics")
```

### 3. ä¸»æ‡‰ç”¨é›†æˆ

```python
# backend/main.py
from src.infrastructure.metrics.prometheus_metrics import setup_prometheus

app = FastAPI(...)

# é…ç½® Prometheusï¼ˆå¯é¸ï¼‰
if settings.prometheus_enabled:
    setup_prometheus(app)
```

### 4. Prometheus Server é…ç½®ï¼ˆDocker Composeï¼‰

```yaml
# docker-compose.yml
services:
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: ai-framework-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    networks:
      - ai-framework-network

  grafana:
    image: grafana/grafana:10.2.2
    container_name: ai-framework-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./infrastructure/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - ai-framework-network

volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
```

```yaml
# infrastructure/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'ai-framework-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
```

---

## å¥åº·æª¢æŸ¥ç«¯é»

### å®Œæ•´çš„å¥åº·æª¢æŸ¥å¯¦ç¾

```python
# backend/src/api/v1/health/__init__.py
from .routes import router

__all__ = ["router"]
```

```python
# backend/src/api/v1/health/routes.py
"""
å¥åº·æª¢æŸ¥ç«¯é»
"""
import asyncio
from datetime import datetime
from typing import Dict, Any

from fastapi import APIRouter, Depends, status
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.config import settings
from src.infrastructure.database.session import get_session
from src.infrastructure.cache.redis_cache import get_cache
from src.infrastructure.queue.queue_manager import get_queue_provider

router = APIRouter(prefix="/health", tags=["Health"])


@router.get("/", status_code=status.HTTP_200_OK)
async def health_check():
    """
    åŸºæœ¬å¥åº·æª¢æŸ¥

    Returns:
        ç°¡å–®çš„å¥åº·ç‹€æ…‹
    """
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.app_version,
        "environment": settings.environment,
    }


@router.get("/liveness", status_code=status.HTTP_200_OK)
async def liveness():
    """
    Kubernetes Liveness Probe

    æª¢æŸ¥æ‡‰ç”¨ç¨‹åºæ˜¯å¦å­˜æ´»ï¼ˆä¸æª¢æŸ¥ä¾è³´ï¼‰

    Returns:
        å­˜æ´»ç‹€æ…‹
    """
    return {"status": "alive"}


@router.get("/readiness")
async def readiness(
    session: AsyncSession = Depends(get_session)
):
    """
    Kubernetes Readiness Probe

    æª¢æŸ¥æ‡‰ç”¨ç¨‹åºæ˜¯å¦æº–å‚™å¥½æ¥æ”¶æµé‡ï¼ˆæª¢æŸ¥æ‰€æœ‰ä¾è³´ï¼‰

    Returns:
        æº–å‚™ç‹€æ…‹å’Œä¾è³´æª¢æŸ¥çµæœ
    """
    checks = {}
    overall_status = "ready"

    # æª¢æŸ¥æ•¸æ“šåº«
    try:
        await session.execute("SELECT 1")
        checks["database"] = {"status": "healthy", "message": "Connection OK"}
    except Exception as e:
        checks["database"] = {"status": "unhealthy", "message": str(e)}
        overall_status = "not_ready"

    # æª¢æŸ¥ Redis
    try:
        cache = get_cache()
        if cache:
            await cache.set("health_check", "ok", ttl=10)
            value = await cache.get("health_check")
            if value == "ok":
                checks["redis"] = {"status": "healthy", "message": "Connection OK"}
            else:
                raise Exception("Read/write test failed")
        else:
            checks["redis"] = {"status": "skipped", "message": "Redis not configured"}
    except Exception as e:
        checks["redis"] = {"status": "unhealthy", "message": str(e)}
        overall_status = "not_ready"

    # æª¢æŸ¥æ¶ˆæ¯éšŠåˆ—
    try:
        queue_provider = get_queue_provider()
        # ç°¡å–®çš„é€£æ¥æª¢æŸ¥ï¼ˆä¸ç™¼é€å¯¦éš›æ¶ˆæ¯ï¼‰
        checks["queue"] = {"status": "healthy", "message": "Connection OK"}
    except Exception as e:
        checks["queue"] = {"status": "unhealthy", "message": str(e)}
        overall_status = "not_ready"

    # è¿”å›çµæœ
    status_code = status.HTTP_200_OK if overall_status == "ready" else status.HTTP_503_SERVICE_UNAVAILABLE

    return JSONResponse(
        status_code=status_code,
        content={
            "status": overall_status,
            "timestamp": datetime.utcnow().isoformat(),
            "checks": checks,
        }
    )


@router.get("/detailed")
async def detailed_health(
    session: AsyncSession = Depends(get_session)
):
    """
    è©³ç´°å¥åº·æª¢æŸ¥

    åŒ…å«æ‰€æœ‰ç³»çµ±çµ„ä»¶çš„è©³ç´°ç‹€æ…‹

    Returns:
        è©³ç´°çš„ç³»çµ±å¥åº·å ±å‘Š
    """
    checks = {}

    # æ•¸æ“šåº«æª¢æŸ¥ï¼ˆåŒ…å«å»¶é²ï¼‰
    try:
        start = datetime.utcnow()
        await session.execute("SELECT 1")
        latency = (datetime.utcnow() - start).total_seconds() * 1000
        checks["database"] = {
            "status": "healthy",
            "latency_ms": round(latency, 2),
            "message": "Connection OK"
        }
    except Exception as e:
        checks["database"] = {
            "status": "unhealthy",
            "message": str(e)
        }

    # Redis æª¢æŸ¥ï¼ˆåŒ…å«å»¶é²ï¼‰
    try:
        cache = get_cache()
        if cache:
            start = datetime.utcnow()
            await cache.set("health_check_detailed", "ok", ttl=10)
            await cache.get("health_check_detailed")
            latency = (datetime.utcnow() - start).total_seconds() * 1000

            # ç²å– Redis ä¿¡æ¯
            info = await cache._client.info() if hasattr(cache, '_client') else {}

            checks["redis"] = {
                "status": "healthy",
                "latency_ms": round(latency, 2),
                "connected_clients": info.get("connected_clients", "N/A"),
                "used_memory_human": info.get("used_memory_human", "N/A"),
                "message": "Connection OK"
            }
        else:
            checks["redis"] = {"status": "skipped", "message": "Redis not configured"}
    except Exception as e:
        checks["redis"] = {
            "status": "unhealthy",
            "message": str(e)
        }

    # æ¶ˆæ¯éšŠåˆ—æª¢æŸ¥
    try:
        queue_provider = get_queue_provider()
        checks["queue"] = {
            "status": "healthy",
            "provider": settings.mq_provider,
            "message": "Connection OK"
        }
    except Exception as e:
        checks["queue"] = {
            "status": "unhealthy",
            "message": str(e)
        }

    # è¨ˆç®—æ•´é«”ç‹€æ…‹
    unhealthy_count = sum(1 for check in checks.values() if check.get("status") == "unhealthy")
    overall_status = "healthy" if unhealthy_count == 0 else "degraded" if unhealthy_count < len(checks) else "unhealthy"

    return {
        "status": overall_status,
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.app_version,
        "environment": settings.environment,
        "uptime_seconds": 0,  # TODO: å¯¦ç¾å•Ÿå‹•æ™‚é–“è¿½è¹¤
        "checks": checks,
    }
```

---

## å‘Šè­¦è¦å‰‡

### Azure Monitor Alert Rules

```hcl
# infrastructure/terraform/monitoring_alerts.tf

# HTTP 5xx éŒ¯èª¤å‘Šè­¦
resource "azurerm_monitor_metric_alert" "http_5xx" {
  name                = "http-5xx-errors-${var.environment}"
  resource_group_name = azurerm_resource_group.main.name
  scopes              = [azurerm_linux_web_app.backend.id]
  description         = "Alert when HTTP 5xx errors exceed threshold"
  severity            = 2

  criteria {
    metric_namespace = "Microsoft.Web/sites"
    metric_name      = "Http5xx"
    aggregation      = "Total"
    operator         = "GreaterThan"
    threshold        = var.environment == "production" ? 10 : 5
  }

  window_size        = "PT5M"
  frequency          = "PT1M"
  auto_mitigate      = true

  action {
    action_group_id = azurerm_monitor_action_group.main.id
  }
}

# é«˜ CPU ä½¿ç”¨ç‡å‘Šè­¦
resource "azurerm_monitor_metric_alert" "high_cpu" {
  name                = "high-cpu-usage-${var.environment}"
  resource_group_name = azurerm_resource_group.main.name
  scopes              = [azurerm_linux_web_app.backend.id]
  description         = "Alert when CPU usage is high"
  severity            = 3

  criteria {
    metric_namespace = "Microsoft.Web/sites"
    metric_name      = "CpuPercentage"
    aggregation      = "Average"
    operator         = "GreaterThan"
    threshold        = 80
  }

  window_size   = "PT5M"
  frequency     = "PT1M"
  auto_mitigate = true

  action {
    action_group_id = azurerm_monitor_action_group.main.id
  }
}

# é«˜è¨˜æ†¶é«”ä½¿ç”¨ç‡å‘Šè­¦
resource "azurerm_monitor_metric_alert" "high_memory" {
  name                = "high-memory-usage-${var.environment}"
  resource_group_name = azurerm_resource_group.main.name
  scopes              = [azurerm_linux_web_app.backend.id]
  description         = "Alert when memory usage is high"
  severity            = 3

  criteria {
    metric_namespace = "Microsoft.Web/sites"
    metric_name      = "MemoryPercentage"
    aggregation      = "Average"
    operator         = "GreaterThan"
    threshold        = 85
  }

  window_size   = "PT5M"
  frequency     = "PT1M"
  auto_mitigate = true

  action {
    action_group_id = azurerm_monitor_action_group.main.id
  }
}

# éŸ¿æ‡‰æ™‚é–“å‘Šè­¦
resource "azurerm_monitor_metric_alert" "slow_response" {
  name                = "slow-response-time-${var.environment}"
  resource_group_name = azurerm_resource_group.main.name
  scopes              = [azurerm_linux_web_app.backend.id]
  description         = "Alert when average response time is slow"
  severity            = 3

  criteria {
    metric_namespace = "Microsoft.Web/sites"
    metric_name      = "ResponseTime"
    aggregation      = "Average"
    operator         = "GreaterThan"
    threshold        = 2000  # 2 ç§’
  }

  window_size   = "PT5M"
  frequency     = "PT1M"
  auto_mitigate = true

  action {
    action_group_id = azurerm_monitor_action_group.main.id
  }
}

# Action Groupï¼ˆé€šçŸ¥ç¾¤çµ„ï¼‰
resource "azurerm_monitor_action_group" "main" {
  name                = "ai-framework-alerts-${var.environment}"
  resource_group_name = azurerm_resource_group.main.name
  short_name          = "aiframework"

  # Email é€šçŸ¥
  email_receiver {
    name                    = "DevOps Team"
    email_address           = var.alert_email
    use_common_alert_schema = true
  }

  # Webhook é€šçŸ¥ï¼ˆå¯é¸ï¼šSlack, Teams, PagerDutyï¼‰
  webhook_receiver {
    name        = "Slack Webhook"
    service_uri = var.slack_webhook_url
  }
}
```

---

## å„€è¡¨æ¿è¨­è¨ˆ

### Azure Monitor Dashboard

é€šé Azure Portal å‰µå»ºè‡ªå®šç¾©å„€è¡¨æ¿ï¼ŒåŒ…å«ï¼š

1. **Overview æ¦‚è¦½**
   - æ‡‰ç”¨å¥åº·ç‹€æ…‹
   - è«‹æ±‚ç¸½æ•¸
   - å¹³å‡éŸ¿æ‡‰æ™‚é–“
   - éŒ¯èª¤ç‡

2. **Performance æ€§èƒ½**
   - CPU ä½¿ç”¨ç‡
   - è¨˜æ†¶é«”ä½¿ç”¨ç‡
   - ç¶²è·¯ I/O
   - ç£ç¢Ÿ I/O

3. **Requests è«‹æ±‚**
   - è«‹æ±‚é€Ÿç‡
   - éŸ¿æ‡‰æ™‚é–“åˆ†ä½ˆ
   - ç«¯é»ç†±åœ–

4. **Failures å¤±æ•—**
   - ç•°å¸¸æ•¸é‡
   - å¤±æ•—è«‹æ±‚ç‡
   - éŒ¯èª¤é¡å‹åˆ†ä½ˆ

5. **Dependencies ä¾è³´**
   - æ•¸æ“šåº«æŸ¥è©¢æ€§èƒ½
   - Redis èª¿ç”¨
   - å¤–éƒ¨ API èª¿ç”¨

---

## æœ€ä½³å¯¦è¸

### 1. ç›£æ§åˆ†å±¤

- **åŸºç¤ç›£æ§**: Azure Monitorï¼ˆCPUã€è¨˜æ†¶é«”ã€ç¶²è·¯ï¼‰
- **æ‡‰ç”¨ç›£æ§**: Application Insightsï¼ˆè«‹æ±‚ã€ç•°å¸¸ã€ä¾è³´ï¼‰
- **æ¥­å‹™ç›£æ§**: è‡ªå®šç¾©æŒ‡æ¨™ï¼ˆå·¥ä½œæµã€ç”¨æˆ¶è¡Œç‚ºï¼‰

### 2. æ¡æ¨£ç­–ç•¥

```python
# ç”Ÿç”¢ç’°å¢ƒæ¡æ¨£é…ç½®
SAMPLING_RATE = {
    "development": 1.0,    # 100%
    "staging": 0.5,        # 50%
    "production": 0.2,     # 20%
}
```

### 3. æˆæœ¬å„ªåŒ–

- âœ… å•Ÿç”¨æ¡æ¨£ï¼ˆç”Ÿç”¢ç’°å¢ƒ 20%ï¼‰
- âœ… è¨­ç½®é©ç•¶çš„è³‡æ–™ä¿ç•™æœŸé™ï¼ˆ30-90å¤©ï¼‰
- âœ… æ’é™¤å¥åº·æª¢æŸ¥ç«¯é»
- âœ… ä½¿ç”¨ Log Analytics Workspace æ¨¡å¼

### 4. éš±ç§å’Œå®‰å…¨

- âŒ ä¸è¨˜éŒ„æ•æ„Ÿæ•¸æ“šï¼ˆå¯†ç¢¼ã€Tokenï¼‰
- âœ… ä½¿ç”¨å±¬æ€§æ¨™è¨˜è€Œéå®Œæ•´æ•¸æ“š
- âœ… å®šæœŸå¯©æŸ¥æ—¥èªŒå…§å®¹

---

## é…ç½®æª¢æŸ¥æ¸…å–®

### å¿…é ˆé…ç½®

- [ ] Application Insights è³‡æº
- [ ] Log Analytics Workspace
- [ ] OpenTelemetry SDK æ•´åˆ
- [ ] å¥åº·æª¢æŸ¥ç«¯é»
- [ ] åŸºæœ¬å‘Šè­¦è¦å‰‡

### å¯é¸é…ç½®

- [ ] Prometheus + Grafana
- [ ] è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™
- [ ] Slack/Teams é€šçŸ¥
- [ ] è‡ªå®šç¾©å„€è¡¨æ¿

---

**ä¸‹ä¸€æ­¥**: å¯¦ç¾ OpenTelemetry æ•´åˆå’Œå¥åº·æª¢æŸ¥ç«¯é»
