# UAT 測試任務 Prompt 模板

本文件提供標準化的 UAT 測試 prompt 模板，確保 AI 助手能正確理解和執行測試任務。

---

## 模板類型

| 模板 | 用途 | 適用場景 |
|------|------|----------|
| PROMPT-UAT-01 | 單一功能測試 | 驗證單一 Feature 的功能 |
| PROMPT-UAT-02 | 整合流程測試 | 端到端業務流程測試 |
| PROMPT-UAT-03 | 回歸測試 | 修復後的回歸驗證 |
| PROMPT-UAT-04 | 效能基準測試 | 效能指標驗證 |
| PROMPT-UAT-05 | 探索性測試 | 自由探索找問題 |

---

## PROMPT-UAT-01: 單一功能測試

```markdown
# UAT 測試任務：[功能名稱] 驗證

---

## 測試範圍
- **Feature ID**: #XX
- **Feature 名稱**: [功能名稱]
- **測試類型**: 單一功能驗證
- **優先級**: P0/P1/P2

## 必讀文件 (請依序閱讀)
1. `docs/03-implementation/sprint-planning/[相關 sprint]/stories/[story-file].md`
2. `claudedocs/uat/test_plans/[test-plan-file].md`
3. `scripts/uat/[相關測試腳本].py` (了解測試實現)

## 參考文件 (測試時查閱)
- `CLAUDE.md` - 項目配置和 API 使用規範
- `claudedocs/uat/sessions/` - 歷史測試結果參考
- `backend/src/api/v1/[相關模組]/` - API 實現細節

## 測試環境要求

### 🔴 強制要求
- [ ] **真實 LLM**: 所有 AI 呼叫必須使用真實 Azure OpenAI (不可使用 mock/simulation)
- [ ] **環境變數**: 確認 `AZURE_OPENAI_*` 環境變數已正確設置
- [ ] **後端服務**: FastAPI 服務運行於 `http://localhost:8000`
- [ ] **資料庫**: PostgreSQL + Redis 服務正常運行

### 環境檢查命令
```bash
# 檢查後端健康狀態
curl http://localhost:8000/health

# 檢查 Docker 服務
docker-compose ps

# 驗證 Azure OpenAI 配置
python scripts/test_azure_openai_connection.py
```

## 測試執行要求

### 輸入準備
1. [描述測試輸入資料]
2. [描述前置條件]

### 預期結果
1. [描述預期輸出]
2. [描述成功標準]

### 執行步驟
1. 執行測試腳本: `python scripts/uat/[test_script].py`
2. 觀察執行過程中的每個步驟
3. 記錄所有 API 響應和 LLM 輸出
4. 驗證結果符合預期

## 結果記錄要求

### 必須記錄
- [ ] 測試開始/結束時間
- [ ] 每個步驟的輸入/輸出
- [ ] LLM 實際回應內容
- [ ] 發現的任何異常或警告
- [ ] 測試結論 (PASS/FAIL)

### 結果保存
- JSON 結果: `claudedocs/uat/sessions/[category]_[test-id]_[timestamp].json`
- 如有異常: 截取錯誤訊息和堆疊追蹤

---

## 🚨 強制完成檢查（不可跳過）

> ⚠️ **重要**: 以下所有項目完成前，測試不視為完成。

### 1. 環境驗證
- [ ] 確認使用真實 Azure OpenAI (非 mock)
- [ ] API 健康檢查通過
- [ ] 相關服務正常運行

### 2. 測試執行
- [ ] 完整執行測試腳本
- [ ] 記錄所有步驟的輸入/輸出
- [ ] 記錄 LLM 實際回應

### 3. 結果分析
- [ ] 分析測試結果是否符合預期
- [ ] 標記任何發現的問題
- [ ] 提供詳細的測試報告

### 4. 文檔更新
- [ ] 測試結果 JSON 已保存
- [ ] 如有 bug → 記錄到 issue tracker
- [ ] 如有發現 → 更新測試計劃

**⛔ 未完成以上所有步驟，禁止回報測試完成。**
```

---

## PROMPT-UAT-02: 整合流程測試

```markdown
# UAT 整合測試任務：[流程名稱] 端到端驗證

---

## 測試範圍
- **測試 ID**: [e.g., integrated-YYYYMMDD_HHMMSS]
- **流程名稱**: [e.g., IT 工單完整生命週期]
- **測試類型**: 端到端整合測試
- **涵蓋功能**: [列出所有涉及的 Feature IDs]

## 必讀文件 (請依序閱讀)
1. `claudedocs/uat/test_plans/[integrated-test-plan].md`
2. `scripts/uat/[integrated_test_script].py` (了解完整測試流程)
3. `docs/02-architecture/technical-architecture.md` (理解系統架構)

## 參考文件 (測試時查閱)
- `CLAUDE.md` - 項目配置和 API 使用規範
- `claudedocs/uat/sessions/` - 歷史測試結果參考
- 各階段相關的 API 文件

## 測試環境要求

### 🔴 強制要求 (Critical)
| 要求 | 檢查方式 | 狀態 |
|------|----------|------|
| 真實 Azure OpenAI | 檢查 LLM adapter 初始化訊息 | [ ] |
| FastAPI 後端運行 | `curl http://localhost:8000/health` | [ ] |
| PostgreSQL 正常 | Docker 服務狀態 | [ ] |
| Redis 正常 | Docker 服務狀態 | [ ] |
| 環境變數完整 | 檢查 `.env` 文件 | [ ] |

### 環境準備命令
```bash
# 啟動所有服務
docker-compose up -d

# 檢查服務狀態
docker-compose ps

# 驗證 API 健康
curl http://localhost:8000/health

# 啟動後端 (如需單獨啟動)
cd backend && uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## 整合測試流程概覽

### 階段與功能對應
| 階段 | 名稱 | 整合功能 |
|------|------|----------|
| Phase 1 | [階段名稱] | [功能 IDs] |
| Phase 2 | [階段名稱] | [功能 IDs] |
| ... | ... | ... |

### 🔑 關鍵驗證點
1. **功能整合性**: 功能必須在真實業務流程中測試，非獨立測試
2. **資料流連續性**: 前一階段的輸出必須正確傳遞到下一階段
3. **狀態一致性**: 系統狀態在各階段間保持一致
4. **真實 LLM 響應**: 所有 AI 呼叫必須得到真實回應

## 測試執行要求

### 執行命令
```bash
python scripts/uat/[integrated_test_script].py
```

### 執行過程監控
1. 觀察每個階段的開始/結束訊息
2. 記錄每個 LLM 呼叫的輸入/輸出
3. 追蹤創建的資源 ID (workflow, execution, checkpoint 等)
4. 注意任何警告或錯誤訊息

## 結果報告要求

### 報告必須包含

#### 1. 測試概覽
- 測試 ID、時間、總執行時間
- 整體狀態 (PASS/FAIL)
- 階段通過率

#### 2. 各階段詳情
每個階段必須記錄：
- **輸入**: 該階段接收的資料
- **處理**: 執行的操作和 API 呼叫
- **LLM 響應**: 真實 AI 回應內容 (如有)
- **輸出**: 該階段產生的結果
- **功能驗證**: 該階段驗證的功能及結果

#### 3. 功能驗證摘要
- 總功能數 vs 驗證通過數
- 每個功能的驗證詳情
- 未通過功能的原因分析

#### 4. LLM 使用統計
- 總呼叫次數
- 總 Token 數
- 預估成本

#### 5. 創建的資源清單
- 列出所有創建的資源 ID

---

## 🚨 強制完成檢查（不可跳過）

### 1. 測試準備
- [ ] 環境檢查全部通過
- [ ] 確認使用真實 Azure OpenAI
- [ ] 理解測試流程和各階段目標

### 2. 測試執行
- [ ] 完整執行整合測試腳本
- [ ] 所有階段都有執行 (無跳過)
- [ ] 記錄每個階段的詳細結果

### 3. 結果分析
- [ ] 提供階段說明 + 實際執行內容的整合報告
- [ ] 分析每個功能的驗證結果
- [ ] 識別並記錄所有問題

### 4. 報告輸出
- [ ] JSON 結果已自動保存
- [ ] 提供人類可讀的詳細報告
- [ ] 報告包含所有必要資訊

**⛔ 未完成以上所有步驟，禁止回報測試完成。**
```

---

## PROMPT-UAT-03: 回歸測試

```markdown
# UAT 回歸測試任務：[修復項目] 驗證

---

## 測試背景
- **原始問題**: [描述原始 bug 或問題]
- **修復 PR/Commit**: [相關連結]
- **修復日期**: [日期]
- **測試類型**: 回歸驗證

## 必讀文件
1. 原始 bug 報告或 issue
2. 修復相關的 PR 或 commit
3. 受影響功能的測試計劃

## 回歸測試範圍

### 直接驗證
- [ ] 原始問題已修復
- [ ] 修復行為符合預期

### 間接驗證 (防止副作用)
- [ ] 相關功能未受影響
- [ ] 相依模組正常運作

## 測試步驟

### Step 1: 重現原始問題 (應該失敗)
```
[描述如何在修復前重現問題]
```

### Step 2: 驗證修復 (應該成功)
```
[描述修復後的預期行為]
```

### Step 3: 驗證無副作用
```
[描述需要檢查的相關功能]
```

---

## 🚨 強制完成檢查

- [ ] 原始問題確認已修復
- [ ] 相關功能無副作用
- [ ] 測試結果已記錄
- [ ] 如發現新問題 → 開新 issue

**⛔ 回歸測試必須完整執行所有驗證步驟。**
```

---

## PROMPT-UAT-04: 效能基準測試

```markdown
# UAT 效能測試任務：[測試項目] 基準驗證

---

## 測試範圍
- **測試項目**: [e.g., LLM 響應時間、API 吞吐量]
- **測試類型**: 效能基準測試
- **基準標準**: [定義的效能指標]

## 效能指標定義

| 指標 | 基準值 | 警戒值 | 不可接受值 |
|------|--------|--------|------------|
| [指標1] | < Xms | < Yms | > Zms |
| [指標2] | > X/s | > Y/s | < Z/s |

## 測試執行

### 測試條件
- 並發數: [N]
- 測試持續時間: [M 分鐘]
- 資料量: [描述]

### 執行命令
```bash
[測試命令]
```

## 結果記錄

### 必須記錄
- [ ] 各指標實際數值
- [ ] 與基準的比較
- [ ] 效能瓶頸分析 (如有)

---

## 🚨 強制完成檢查

- [ ] 所有效能指標都有測量
- [ ] 結果與基準比較完成
- [ ] 效能報告已生成
```

---

## PROMPT-UAT-05: 探索性測試

```markdown
# UAT 探索性測試任務：[測試範圍]

---

## 測試目標
- **測試範圍**: [e.g., Agent Handoff 功能]
- **測試類型**: 探索性測試
- **時間限制**: [X 分鐘]
- **探索重點**: [邊界條件、異常處理、使用者體驗]

## 探索方向

### 建議探索
1. **邊界條件**: [描述]
2. **異常輸入**: [描述]
3. **併發情況**: [描述]
4. **錯誤恢復**: [描述]

### 探索記錄格式
```
時間: [HH:MM]
操作: [執行的操作]
輸入: [使用的輸入]
結果: [觀察到的結果]
發現: [任何問題或值得注意的行為]
```

## 發現記錄

### 問題分類
- 🔴 **Critical**: 系統崩潰、資料損失
- 🟡 **Major**: 功能失效、嚴重體驗問題
- 🟢 **Minor**: 小問題、改善建議

---

## 🚨 強制完成檢查

- [ ] 所有探索方向都有嘗試
- [ ] 發現的問題都有記錄
- [ ] 問題已分類和標記嚴重程度
- [ ] 探索報告已完成
```

---

## 通用注意事項

### 🔴 所有 UAT 測試的強制要求

1. **真實 LLM 使用**
   - 絕對不可使用 mock 或 simulation
   - 必須驗證 Azure OpenAI 連線
   - LLM 響應必須完整記錄

2. **環境一致性**
   - 使用標準測試環境
   - 記錄環境配置
   - 確保服務正常運行

3. **結果可追溯**
   - 所有測試結果保存為 JSON
   - 包含完整的輸入/輸出
   - 記錄時間戳和測試 ID

4. **報告完整性**
   - 提供人類可讀的報告
   - 包含階段說明和實際執行內容
   - 明確標示 PASS/FAIL 狀態

### 測試結果存放位置
```
claudedocs/
└── uat/
    ├── test_plans/      # 測試計劃文件
    ├── sessions/        # 測試執行結果 (JSON)
    └── reports/         # 人類可讀報告 (Markdown)
```

---

**最後更新**: 2025-12-19
**版本**: 1.0
