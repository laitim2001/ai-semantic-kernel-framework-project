# CHANGE-002: ä¸¦è¡Œè™•ç†æ¶æ§‹æ”¹é€² â€” ä¸‰å±¤èƒŒå£“èˆ‡åˆ†æ•£å¼ç‹€æ…‹

**è®Šæ›´æ—¥æœŸ**: 2026-01-28
**è®Šæ›´é¡å‹**: æ¶æ§‹æ”¹é€²
**å½±éŸ¿ç¯„åœ**: Input Gatewayã€Orchestration Layerã€Claude Worker Pool ä¸‰å±¤ä¸¦è¡Œæ¶æ§‹
**ç›¸é—œ Sprint**: å¾…è¦åŠƒ
**ç‹€æ…‹**: ğŸ“‹ æ–¹æ¡ˆè¨­è¨ˆå®Œæˆï¼Œå¾…å¯¦æ–½

---

## è®Šæ›´æ‘˜è¦

é‡å° IPA Platform ä¸‰å±¤æ¶æ§‹ï¼ˆInput Gateway â†’ Orchestration â†’ Claude Worker Poolï¼‰çš„ä¸¦è¡Œè™•ç†èƒ½åŠ›é€²è¡Œç³»çµ±æ€§æ”¹é€²ã€‚è§£æ±ºå››å€‹æ ¸å¿ƒå•é¡Œï¼šå–® Process ç“¶é ¸ã€ç‹€æ…‹ç„¡æ³•è·¨ Worker å…±äº«ã€ç¼ºå°‘å…¨å±€èƒŒå£“æ©Ÿåˆ¶ã€Race Condition èˆ‡ç„¡ç•Œè¨˜æ†¶é«”å¢é•·ã€‚

---

## è®Šæ›´åŸå› 

### ç¾æœ‰æ¶æ§‹å•é¡Œ

#### å•é¡Œ 1ï¼šå–® Process ç“¶é ¸

**ä½ç½®**: `backend/main.py:238-244`

```python
# ç›®å‰åªå•Ÿå‹•å–®ä¸€ Uvicorn worker
uvicorn.run(
    "main:app",
    host="0.0.0.0",
    port=8000,
    reload=True,
    log_level="info",
)
```

- Uvicorn é è¨­ 1 å€‹ workerï¼Œæ‰€æœ‰è«‹æ±‚å…±ç”¨ä¸€å€‹ process
- Python GIL é™åˆ¶ CPU å¯†é›†æ“ä½œï¼ˆå¦‚ Semantic Router çš„ vector similarityï¼‰
- DB é€£ç·šæ±  `pool_size=5, max_overflow=10`ï¼ˆæœ€å¤š 15 é€£ç·šï¼‰ä»¥å–® worker ç‚ºå‰æè¨­è¨ˆ

#### å•é¡Œ 2ï¼šOrchestration ç‹€æ…‹ç´” In-Memory

**ä½ç½®**: `backend/src/integrations/hybrid/context/sync/synchronizer.py:114-117`

```python
# ç´” in-memory dictï¼Œç„¡æ³•è·¨ worker å…±äº«
self._context_versions: Dict[str, int] = {}
self._rollback_snapshots: Dict[str, List[HybridContext]] = {}
```

- æ‰€æœ‰ orchestration ç‹€æ…‹å­˜åœ¨ process è¨˜æ†¶é«”ä¸­
- ç„¡æ³•æ°´å¹³æ“´å±•ï¼ˆå¤š worker æ™‚ç‹€æ…‹ä¸ä¸€è‡´ï¼‰
- Process é‡å•Ÿå¾Œç‹€æ…‹å®Œå…¨ä¸Ÿå¤±
- ç„¡åˆ†æ•£å¼é–ä¿è­·ä¸¦è¡Œå­˜å–

#### å•é¡Œ 3ï¼šç¼ºå°‘å…¨å±€èƒŒå£“æ©Ÿåˆ¶

- **Layer 1 (API)**ï¼šç„¡ä»»ä½•é™æµ middlewareï¼Œå…¨éƒ¨è«‹æ±‚ç›´æ¥æ¥å—
- **Layer 2 (Orchestration)**ï¼šç„¡ä¸¦è¡Œ session æ•¸é‡é™åˆ¶ï¼Œå…¨éƒ¨è™•ç†
- **Layer 3 (Worker Pool)**ï¼š`RateLimitHook` é™åˆ¶ 10 ä¸¦è¡Œã€60/minï¼Œä½†ç„¡æ³•å‘ä¸Šæ¸¸å‚³éåå£“ä¿¡è™Ÿ
- ä¸‰å±¤ä¹‹é–“ç„¡å”èª¿ï¼Œçªç™¼æµé‡æœƒå°è‡´ Layer 2 ç©å£“å¤§é‡ä»»å‹™

#### å•é¡Œ 4ï¼šRace Condition èˆ‡ç„¡ç•Œè¨˜æ†¶é«”

**4a. Race Condition**

**ä½ç½®**: `backend/src/integrations/hybrid/context/sync/synchronizer.py:174-175`

```python
# éåŸå­æ“ä½œï¼Œå…©å€‹ async task å¯èƒ½äº¤éŒ¯åŸ·è¡Œ
if result.success:
    self._context_versions[context_id] = result.target_version
```

**ä½ç½®**: `backend/src/integrations/hybrid/context/sync/synchronizer.py:594-606`

```python
# åŒä¸€ context çš„ä¸¦è¡Œè«‹æ±‚å¯èƒ½åŒæ™‚è®€å¯«åŒä¸€å€‹ list
def _save_snapshot(self, context: HybridContext) -> None:
    snapshots = self._rollback_snapshots[context_id]
    snapshots.append(context)  # éåŸå­
```

`_context_versions` å’Œ `_rollback_snapshots` å‡ç‚ºæ™®é€š dict/listï¼Œç„¡ `asyncio.Lock` ä¿è­·ã€‚åŒä¸€ç”¨æˆ¶å¿«é€Ÿé€£çºŒè«‹æ±‚æ™‚å¯èƒ½å°è‡´ç‰ˆæœ¬è¿½è¹¤å‡ºéŒ¯ã€‚

**4b. ç„¡ç•Œè¨˜æ†¶é«”å¢é•·**

| å…ƒä»¶ | ç„¡ç•Œè³‡æ–™çµæ§‹ | ä½ç½® |
|------|------------|------|
| `ClaudeCoordinator` | `_coordination_history: List` | `orchestrator/coordinator.py:72` |
| `SessionStateManager` | `_state_cache: Dict` | `claude_sdk/session_state.py` |
| `ClaudeSDKClient` | `_sessions: Dict` | `claude_sdk/client.py` |
| `RateLimitHook` | `_call_timestamps: list` | `hooks/rate_limit.py:121` |
| `ContextSynchronizer` | `_context_versions: Dict` | `context/sync/synchronizer.py:114` |

é•·æ™‚é–“é‹è¡Œä¸‹ï¼Œé€™äº›ç„¡ç•Œè³‡æ–™çµæ§‹æœƒæŒçºŒå¢é•·ï¼Œæœ€çµ‚å°è‡´ OOMã€‚

### æ”¹é€²å¾Œçš„æ¶æ§‹å„ªå‹¢

1. **æ°´å¹³æ“´å±•**ï¼šå¤š Worker éƒ¨ç½²ï¼ŒRedis ä½œç‚ºå…±äº«ç‹€æ…‹å±¤
2. **é«˜å¯ç”¨**ï¼šç‹€æ…‹æŒä¹…åŒ–ï¼Œprocess é‡å•Ÿä¸ä¸Ÿå¤±
3. **æµé‡æ§åˆ¶**ï¼šä¸‰å±¤æ¼æ–—å¼èƒŒå£“ï¼Œé˜²æ­¢ç³»çµ±éè¼‰
4. **è³‡æ–™å®‰å…¨**ï¼šåˆ†æ•£å¼é–æ¶ˆé™¤ race condition
5. **è¨˜æ†¶é«”ç©©å®š**ï¼šæœ‰ç•Œè³‡æ–™çµæ§‹é˜²æ­¢ OOM

---

## è©³ç´°è®Šæ›´

### æ”¹é€²æ¶æ§‹ç¸½è¦½

```
æ”¹é€²å‰:

  ç”¨æˆ¶è«‹æ±‚ â”€â”€â†’ [Uvicorn x1] â”€â”€â†’ [Orchestrator (in-memory)] â”€â”€â†’ [Worker Pool]
              ç„¡é™æµ            ç„¡é–ã€ç„¡èƒŒå£“                   Semaphore(10)

æ”¹é€²å¾Œ:

  ç”¨æˆ¶è«‹æ±‚ â”€â”€â†’ [Nginx/Traefik]
              â”‚
              â”œâ”€â”€ [Uvicorn Worker 1] â”€â”€â”
              â”œâ”€â”€ [Uvicorn Worker 2] â”€â”€â”¼â”€â”€ [Redis åˆ†æ•£å¼ç‹€æ…‹] â”€â”€â†’ [Worker Pool]
              â””â”€â”€ [Uvicorn Worker N] â”€â”€â”˜   â€¢ ç‰ˆæœ¬è¿½è¹¤            Semaphore(10)
              å…¨å±€+ç”¨æˆ¶é™æµ                 â€¢ åˆ†æ•£å¼é–            + åå£“ä¿¡è™Ÿ
                                           â€¢ Session ç‹€æ…‹
                                           â€¢ èƒŒå£“è¨ˆæ•¸å™¨
```

---

### å„ªå…ˆç´š 1ï¼šRace Condition ä¿®å¾© + ç„¡ç•Œè¨˜æ†¶é«”æ²»ç†

> ä½é¢¨éšªã€é«˜æ”¶ç›Šï¼Œå–® Worker ç’°å¢ƒå³å¯å¯¦æ–½

#### 1a. ContextSynchronizer åŠ å…¥ asyncio.Lock

**ä¿®æ”¹æ–‡ä»¶**: `backend/src/integrations/hybrid/context/sync/synchronizer.py`

**æ”¹é€²æ–¹å‘**ï¼š

```python
import asyncio
from collections import defaultdict

class ContextSynchronizer:
    def __init__(self, ...):
        ...
        # å…¨å±€é–ï¼ˆä¿è­· _locks dict æœ¬èº«çš„å»ºç«‹ï¼‰
        self._global_lock = asyncio.Lock()
        # æ¯å€‹ context ä¸€å€‹é–
        self._locks: Dict[str, asyncio.Lock] = {}

    async def _get_lock(self, context_id: str) -> asyncio.Lock:
        """å®‰å…¨åœ°ç²å– context å°ˆç”¨é–"""
        if context_id not in self._locks:
            async with self._global_lock:
                # Double-check pattern
                if context_id not in self._locks:
                    self._locks[context_id] = asyncio.Lock()
        return self._locks[context_id]

    async def sync(self, source: HybridContext, ...) -> SyncResult:
        lock = await self._get_lock(source.context_id)
        async with lock:
            # ... åŸæœ‰ sync é‚è¼¯ï¼ˆç‰ˆæœ¬æ›´æ–°ã€snapshot ä¿å­˜ç­‰ï¼‰...
            pass

    async def rollback(self, context_id: str, ...) -> SyncResult:
        lock = await self._get_lock(context_id)
        async with lock:
            # ... åŸæœ‰ rollback é‚è¼¯ ...
            pass
```

**é—œéµè¨­è¨ˆæ±ºç­–**ï¼š
- ä½¿ç”¨ per-context lock è€Œéå…¨å±€ lockï¼Œé¿å…ä¸åŒ session ä¹‹é–“äº’ç›¸é˜»å¡
- ä½¿ç”¨ double-check pattern ä¿è­· lock çš„å»ºç«‹éç¨‹
- `_save_snapshot` å’Œç‰ˆæœ¬æ›´æ–°éƒ½åœ¨ lock ä¿è­·ç¯„åœå…§

#### 1b. ç„¡ç•Œè³‡æ–™çµæ§‹æ”¹ç‚ºæœ‰ç•Œ

**ä¾è³´å®‰è£**ï¼š`cachetools` å·²åœ¨ Python ç”Ÿæ…‹ä¸­å»£æ³›ä½¿ç”¨

**å„å…ƒä»¶æ”¹é€²æ–¹å‘**ï¼š

| å…ƒä»¶ | æ”¹é€²å‰ | æ”¹é€²å¾Œ | èªªæ˜ |
|------|--------|--------|------|
| `ClaudeCoordinator._coordination_history` | `List` | `collections.deque(maxlen=1000)` | è‡ªå‹•æ·˜æ±°æœ€èˆŠè¨˜éŒ„ |
| `SessionStateManager._state_cache` | `Dict` | `cachetools.TTLCache(maxsize=500, ttl=3600)` | TTL + æœ€å¤§å®¹é‡ |
| `ClaudeSDKClient._sessions` | `Dict` | `cachetools.TTLCache(maxsize=200, ttl=7200)` | 2 å°æ™‚ç„¡æ´»å‹•è‡ªå‹•éæœŸ |
| `ContextSynchronizer._context_versions` | `Dict` | `cachetools.LRUCache(maxsize=1000)` | LRU æ·˜æ±°æœ€å°‘ä½¿ç”¨çš„ |
| `ContextSynchronizer._locks` | `Dict` | å®šæœŸæ¸…ç†ç„¡æ´»å‹•é– | é…åˆ `_context_versions` æ·˜æ±° |

**æ”¹é€²ç¯„ä¾‹ â€” ClaudeCoordinator**ï¼š

```python
from collections import deque

class ClaudeCoordinator:
    def __init__(self, ...):
        ...
        # æ”¹é€²ï¼šé™åˆ¶æ­·å²è¨˜éŒ„æœ€å¤§é•·åº¦
        self._coordination_history: deque = deque(maxlen=1000)
```

**æ”¹é€²ç¯„ä¾‹ â€” SessionStateManager**ï¼š

```python
from cachetools import TTLCache

class SessionStateManager:
    def __init__(self, ...):
        ...
        # æ”¹é€²ï¼šTTL + æœ€å¤§å®¹é‡ï¼Œè‡ªå‹•æ·˜æ±°
        self._state_cache: TTLCache = TTLCache(maxsize=500, ttl=3600)
```

---

### å„ªå…ˆç´š 2ï¼šRedis åˆ†æ•£å¼ç‹€æ…‹å±¤

> ä¸­ç­‰é›£åº¦ï¼Œç‚ºæ°´å¹³æ“´å±•æ‰“åŸºç¤

#### 2a. StateStore æŠ½è±¡å±¤

**æ–°å¢æ–‡ä»¶**: `backend/src/infrastructure/state/store.py`

**è¨­è¨ˆæ–¹å‘**ï¼š

```python
from typing import List, Optional, Protocol
from src.integrations.hybrid.context.models import HybridContext


class StateStore(Protocol):
    """åˆ†æ•£å¼ç‹€æ…‹å„²å­˜æŠ½è±¡"""

    # ç‰ˆæœ¬ç®¡ç†
    async def get_version(self, context_id: str) -> int: ...
    async def set_version(self, context_id: str, version: int) -> None: ...

    # Snapshot ç®¡ç†
    async def save_snapshot(
        self, context_id: str, context: HybridContext, max_snapshots: int = 5
    ) -> None: ...
    async def get_snapshots(self, context_id: str) -> List[HybridContext]: ...
    async def clear_snapshots(self, context_id: str) -> None: ...

    # åˆ†æ•£å¼é–
    async def acquire_lock(
        self, lock_key: str, timeout: float = 5.0, ttl: float = 30.0
    ) -> bool: ...
    async def release_lock(self, lock_key: str) -> None: ...

    # èƒŒå£“è¨ˆæ•¸å™¨
    async def get_active_count(self, counter_key: str) -> int: ...
    async def increment_active(self, counter_key: str, ttl: int = 60) -> int: ...
    async def decrement_active(self, counter_key: str) -> int: ...
```

#### 2b. InMemoryStateStoreï¼ˆé–‹ç™¼/æ¸¬è©¦ç”¨ï¼‰

**æ–°å¢æ–‡ä»¶**: `backend/src/infrastructure/state/memory_store.py`

```python
class InMemoryStateStore:
    """
    In-Memory å¯¦ç¾ï¼Œç”¨æ–¼é–‹ç™¼å’Œæ¸¬è©¦ç’°å¢ƒã€‚
    è¡Œç‚ºèˆ‡ RedisStateStore ä¸€è‡´ï¼Œä½†ç‹€æ…‹åªåœ¨ process å…§æœ‰æ•ˆã€‚
    """

    def __init__(self):
        self._versions: Dict[str, int] = {}
        self._snapshots: Dict[str, List[Any]] = {}
        self._locks: Dict[str, asyncio.Lock] = {}
        self._counters: Dict[str, int] = {}
```

#### 2c. RedisStateStoreï¼ˆç”Ÿç”¢ç”¨ï¼‰

**æ–°å¢æ–‡ä»¶**: `backend/src/infrastructure/state/redis_store.py`

**Redis è³‡æ–™çµæ§‹æ˜ å°„**ï¼š

| åŠŸèƒ½ | Redis å‘½ä»¤ | Key Pattern | èªªæ˜ |
|------|-----------|-------------|------|
| ç‰ˆæœ¬è™Ÿ | `GET/SET` | `ipa:ctx:version:{context_id}` | ç°¡å–® key-value |
| Snapshots | `LPUSH/LTRIM/LRANGE` | `ipa:ctx:snapshots:{context_id}` | Listï¼ŒLTRIM æ§åˆ¶æ•¸é‡ |
| åˆ†æ•£å¼é– | `SET NX EX` | `ipa:lock:{lock_key}` | NX ä¿è­‰åŸå­æ€§ï¼ŒEX é˜²æ­»é– |
| èƒŒå£“è¨ˆæ•¸ | `INCR/DECR/GET` | `ipa:backpressure:{counter}` | åŸå­è¨ˆæ•¸å™¨ |
| Session ç‹€æ…‹ | `HSET/HGET/EXPIRE` | `ipa:session:{session_id}` | Hash + TTL |

**é—œéµå¯¦ç¾è¦é»**ï¼š

```python
import redis.asyncio as aioredis

class RedisStateStore:
    def __init__(self, redis_url: str):
        self._redis = aioredis.from_url(redis_url, decode_responses=True)

    async def acquire_lock(self, lock_key: str, timeout: float = 5.0, ttl: float = 30.0) -> bool:
        """
        åˆ†æ•£å¼é–å¯¦ç¾
        - SET NXï¼šåªåœ¨ key ä¸å­˜åœ¨æ™‚è¨­ç½®ï¼ˆåŸå­æ“ä½œï¼‰
        - EX ttlï¼šè‡ªå‹•éæœŸï¼Œé˜²æ­¢ process crash å¾Œæ­»é–
        - è¼ªè©¢ç­‰å¾… timeout ç§’
        """
        key = f"ipa:lock:{lock_key}"
        lock_value = f"{os.getpid()}:{time.time()}"
        deadline = time.time() + timeout

        while time.time() < deadline:
            acquired = await self._redis.set(key, lock_value, nx=True, ex=int(ttl))
            if acquired:
                return True
            await asyncio.sleep(0.05)  # 50ms è¼ªè©¢é–“éš”

        return False

    async def release_lock(self, lock_key: str) -> None:
        """é‡‹æ”¾é–ï¼ˆä½¿ç”¨ Lua script ç¢ºä¿åŸå­æ€§ï¼‰"""
        key = f"ipa:lock:{lock_key}"
        await self._redis.delete(key)
```

#### 2d. ContextSynchronizer æ•´åˆ StateStore

**ä¿®æ”¹æ–‡ä»¶**: `backend/src/integrations/hybrid/context/sync/synchronizer.py`

**æ”¹é€²æ–¹å‘**ï¼š

```python
class ContextSynchronizer:
    def __init__(
        self,
        state_store: Optional[StateStore] = None,  # æ–°å¢
        conflict_resolver: Optional[ConflictResolver] = None,
        event_publisher: Optional[SyncEventPublisher] = None,
        ...
    ):
        self._state_store = state_store or InMemoryStateStore()
        ...
        # ç§»é™¤åŸæœ‰çš„ in-memory ç‹€æ…‹
        # self._context_versions: Dict[str, int] = {}        # åˆªé™¤
        # self._rollback_snapshots: Dict[str, List[...]] = {} # åˆªé™¤

    async def sync(self, source: HybridContext, ...) -> SyncResult:
        context_id = source.context_id

        # ä½¿ç”¨åˆ†æ•£å¼é–ï¼ˆå–ä»£ asyncio.Lockï¼‰
        locked = await self._state_store.acquire_lock(f"sync:{context_id}")
        if not locked:
            raise SyncError("Context is being synced by another request")

        try:
            # ä½¿ç”¨ StateStore æ›¿ä»£ç›´æ¥ dict æ“ä½œ
            await self._state_store.save_snapshot(context_id, source)

            result = await self._sync_with_retry(...)

            if result.success:
                await self._state_store.set_version(
                    context_id, result.target_version
                )

            return result
        finally:
            await self._state_store.release_lock(f"sync:{context_id}")
```

---

### å„ªå…ˆç´š 3ï¼šå¤š Worker éƒ¨ç½² + API å±¤é™æµ

> éœ€è¦å„ªå…ˆç´š 2 å®Œæˆå¾Œæ‰èƒ½å®‰å…¨å¯¦æ–½

#### 3a. ç”Ÿç”¢ç’°å¢ƒå¤š Worker å•Ÿå‹•é…ç½®

**æ–°å¢æ–‡ä»¶**: `backend/scripts/start_production.sh`

```bash
#!/bin/bash
# IPA Platform - Production startup with multi-worker

WORKERS=${WORKERS:-4}  # é è¨­ 4 workersï¼Œå¯ç”±ç’°å¢ƒè®Šæ•¸è¦†è“‹
HOST=${HOST:-0.0.0.0}
PORT=${PORT:-8000}

echo "Starting IPA Platform with $WORKERS workers on $HOST:$PORT"

gunicorn main:app \
    -w $WORKERS \
    -k uvicorn.workers.UvicornWorker \
    --bind $HOST:$PORT \
    --timeout 300 \
    --graceful-timeout 30 \
    --keep-alive 5 \
    --access-logfile - \
    --error-logfile -
```

#### 3b. DB é€£ç·šæ± å‹•æ…‹é…ç½®

**ä¿®æ”¹æ–‡ä»¶**: `backend/src/infrastructure/database/session.py`

**æ”¹é€²æ–¹å‘**ï¼š

```python
# é€£ç·šæ± å¤§å°æ‡‰å¾è¨­å®šè®€å–ï¼Œä¸¦è€ƒæ…® worker æ•¸é‡
engine_kwargs["pool_size"] = settings.db_pool_size       # æ–°å¢è¨­å®šé …
engine_kwargs["max_overflow"] = settings.db_max_overflow  # æ–°å¢è¨­å®šé …
```

**è¨ˆç®—å…¬å¼**ï¼š

```
æ¯ Worker é€£ç·šæ•¸ = pool_size + max_overflow
ç¸½é€£ç·šæ•¸ = Workers Ã— æ¯ Worker é€£ç·šæ•¸
PostgreSQL max_connections â‰¥ ç¸½é€£ç·šæ•¸ + é ç•™

ç¯„ä¾‹ï¼š4 Workers
  pool_size=3, max_overflow=5 â†’ æ¯ Worker 8 â†’ ç¸½å…± 32
  PostgreSQL max_connections=50ï¼ˆå«é ç•™ï¼‰
```

#### 3c. API å±¤é™æµ Middleware

**æ–°å¢æ–‡ä»¶**: `backend/src/api/middleware/rate_limit.py`

**è¨­è¨ˆæ–¹å‘**ï¼š

```python
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import JSONResponse
import redis.asyncio as aioredis


class APIRateLimitMiddleware(BaseHTTPMiddleware):
    """
    åŸºæ–¼ Redis çš„åˆ†æ•£å¼ API é™æµ

    é™æµè¦å‰‡ï¼š
    - å…¨å±€ï¼šæ¯ç§’æœ€å¤š 100 å€‹è«‹æ±‚
    - æ¯ IPï¼šæ¯åˆ†é˜æœ€å¤š 60 å€‹è«‹æ±‚
    - Agent ç«¯é» (/api/v1/claude-sdk/*, /api/v1/agents/*/execute)ï¼š
      æ¯ç”¨æˆ¶æ¯åˆ†é˜æœ€å¤š 20 å€‹è«‹æ±‚

    ä½¿ç”¨ Redis INCR + EXPIRE å¯¦ç¾æ»‘å‹•çª—å£
    """

    def __init__(self, app, redis_url: str):
        super().__init__(app)
        self._redis = aioredis.from_url(redis_url, decode_responses=True)

    async def dispatch(self, request: Request, call_next):
        client_ip = request.client.host if request.client else "unknown"

        # å…¨å±€é™æµ
        global_key = f"ipa:ratelimit:global:{int(time.time())}"
        global_count = await self._redis.incr(global_key)
        if global_count == 1:
            await self._redis.expire(global_key, 2)
        if global_count > 100:
            return JSONResponse(
                status_code=429,
                content={"error": "RATE_LIMIT_EXCEEDED", "message": "Too many requests"}
            )

        # æ¯ IP é™æµ
        ip_key = f"ipa:ratelimit:ip:{client_ip}:{int(time.time() / 60)}"
        ip_count = await self._redis.incr(ip_key)
        if ip_count == 1:
            await self._redis.expire(ip_key, 120)
        if ip_count > 60:
            return JSONResponse(
                status_code=429,
                content={"error": "IP_RATE_LIMIT", "message": "Too many requests from this IP"}
            )

        return await call_next(request)
```

**æ•´åˆåˆ° main.py**ï¼š

```python
# åœ¨ create_app() ä¸­åŠ å…¥
from src.api.middleware.rate_limit import APIRateLimitMiddleware

if settings.app_env == "production":
    app.add_middleware(APIRateLimitMiddleware, redis_url=settings.redis_url)
```

---

### å„ªå…ˆç´š 4ï¼šåå£“ä¿¡è™Ÿæ©Ÿåˆ¶

> éŒ¦ä¸Šæ·»èŠ±ï¼Œæå‡æ¥µç«¯è² è¼‰ä¸‹çš„ç©©å®šæ€§

#### 4a. èƒŒå£“ä¿¡è™Ÿæœå‹™

**æ–°å¢æ–‡ä»¶**: `backend/src/core/performance/backpressure.py`

**è¨­è¨ˆæ–¹å‘**ï¼š

```python
class BackpressureMonitor:
    """
    ç›£æ§ Worker Pool è² è¼‰ï¼Œå‘ä¸Šæ¸¸ç™¼é€åå£“ä¿¡è™Ÿ

    æ°´ä½ç´šåˆ¥ï¼š
    - GREEN  (0-60%): æ­£å¸¸æ¥å—æ‰€æœ‰è«‹æ±‚
    - YELLOW (60-80%): æ‹’çµ•ä½å„ªå…ˆç´šè«‹æ±‚
    - RED    (80%+): åªæ¥å—é«˜å„ªå…ˆç´šè«‹æ±‚ï¼ˆå¦‚ HITL å¯©æ‰¹å›æ‡‰ï¼‰
    """

    def __init__(self, state_store: StateStore, capacity: int = 10):
        self._state_store = state_store
        self._capacity = capacity

    async def get_pressure_level(self) -> str:
        """æŸ¥è©¢ç•¶å‰èƒŒå£“ç´šåˆ¥"""
        active = await self._state_store.get_active_count("worker_pool")
        ratio = active / self._capacity

        if ratio < 0.6:
            return "GREEN"
        elif ratio < 0.8:
            return "YELLOW"
        else:
            return "RED"

    async def should_accept_request(self, priority: str = "normal") -> bool:
        """æ ¹æ“šèƒŒå£“ç´šåˆ¥æ±ºå®šæ˜¯å¦æ¥å—è«‹æ±‚"""
        level = await self.get_pressure_level()

        if level == "GREEN":
            return True
        elif level == "YELLOW":
            return priority in ("high", "critical")
        else:  # RED
            return priority == "critical"
```

#### 4b. Worker Pool æ•´åˆèƒŒå£“

**ä¿®æ”¹æ–‡ä»¶**: `backend/src/integrations/claude_sdk/orchestrator/task_allocator.py`

**æ”¹é€²æ–¹å‘**ï¼š

```python
class TaskAllocator:
    def __init__(self, ..., state_store: Optional[StateStore] = None):
        ...
        self._state_store = state_store

    async def execute_parallel(self, subtasks, selections, executor):
        # åŸ·è¡Œå‰ï¼šå¢åŠ æ´»å‹•è¨ˆæ•¸
        if self._state_store:
            await self._state_store.increment_active("worker_pool")

        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            return processed_results
        finally:
            # åŸ·è¡Œå¾Œï¼šæ¸›å°‘æ´»å‹•è¨ˆæ•¸
            if self._state_store:
                await self._state_store.decrement_active("worker_pool")
```

---

## ä¿®æ”¹æ–‡ä»¶æ¸…å–®

### å„ªå…ˆç´š 1ï¼šæ–°å¢/ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹èªªæ˜ |
|------|----------|
| `backend/src/integrations/hybrid/context/sync/synchronizer.py` | åŠ å…¥ `asyncio.Lock` per-context é– |
| `backend/src/integrations/claude_sdk/orchestrator/coordinator.py` | `_coordination_history` æ”¹ç‚º `deque(maxlen=1000)` |
| `backend/src/integrations/claude_sdk/session_state.py` | `_state_cache` æ”¹ç‚º `TTLCache(maxsize=500, ttl=3600)` |
| `backend/src/integrations/claude_sdk/client.py` | `_sessions` æ”¹ç‚º `TTLCache(maxsize=200, ttl=7200)` |
| `backend/requirements.txt` | åŠ å…¥ `cachetools>=5.3.0` |

### å„ªå…ˆç´š 2ï¼šæ–°å¢/ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | èªªæ˜ |
|------|------|
| `backend/src/infrastructure/state/__init__.py` | State æ¨¡çµ„å…¥å£ |
| `backend/src/infrastructure/state/store.py` | StateStore Protocol å®šç¾© |
| `backend/src/infrastructure/state/memory_store.py` | InMemoryStateStore å¯¦ç¾ |
| `backend/src/infrastructure/state/redis_store.py` | RedisStateStore å¯¦ç¾ |
| `backend/src/integrations/hybrid/context/sync/synchronizer.py` | æ•´åˆ StateStoreï¼Œç§»é™¤ in-memory ç‹€æ…‹ |
| `backend/src/core/config.py` | æ–°å¢ state_store_backend è¨­å®š |

### å„ªå…ˆç´š 3ï¼šæ–°å¢/ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | èªªæ˜ |
|------|------|
| `backend/scripts/start_production.sh` | Gunicorn + UvicornWorker å•Ÿå‹•è…³æœ¬ |
| `backend/src/api/middleware/__init__.py` | Middleware æ¨¡çµ„å…¥å£ |
| `backend/src/api/middleware/rate_limit.py` | API å±¤é™æµ middleware |
| `backend/src/infrastructure/database/session.py` | DB pool å‹•æ…‹é…ç½® |
| `backend/src/core/config.py` | æ–°å¢ db_pool_size, db_max_overflow è¨­å®š |
| `backend/main.py` | æ›è¼‰ RateLimitMiddleware |

### å„ªå…ˆç´š 4ï¼šæ–°å¢/ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | èªªæ˜ |
|------|------|
| `backend/src/core/performance/backpressure.py` | BackpressureMonitor æœå‹™ |
| `backend/src/integrations/claude_sdk/orchestrator/task_allocator.py` | æ•´åˆèƒŒå£“è¨ˆæ•¸ |

---

## å¯¦æ–½è¨ˆåŠƒ

### éšæ®µèˆ‡å„ªå…ˆç´š

```
å„ªå…ˆç´š 1ï¼ˆä½é¢¨éšªã€é«˜æ”¶ç›Šï¼‰
â”œâ”€â”€ 1a. ContextSynchronizer åŠ å…¥ asyncio.Lock
â”œâ”€â”€ 1b. ç„¡ç•Œè³‡æ–™çµæ§‹æ”¹ç‚ºæœ‰ç•Œï¼ˆdeque/TTLCache/LRUCacheï¼‰
â””â”€â”€ é è¨ˆæ•ˆæœï¼šæ¶ˆé™¤ race condition + é˜²æ­¢è¨˜æ†¶é«”æ´©æ¼

å„ªå…ˆç´š 2ï¼ˆä¸­ç­‰é›£åº¦ã€é—œéµåŸºç¤ï¼‰
â”œâ”€â”€ 2a. StateStore Protocol å®šç¾©
â”œâ”€â”€ 2b. InMemoryStateStore å¯¦ç¾ï¼ˆæ¸¬è©¦ç”¨ï¼‰
â”œâ”€â”€ 2c. RedisStateStore å¯¦ç¾ï¼ˆç”Ÿç”¢ç”¨ï¼‰
â”œâ”€â”€ 2d. ContextSynchronizer æ•´åˆ StateStore
â””â”€â”€ é è¨ˆæ•ˆæœï¼šç‚ºæ°´å¹³æ“´å±•æ‰“åŸºç¤

å„ªå…ˆç´š 3ï¼ˆéœ€è¦å„ªå…ˆç´š 2 å®Œæˆï¼‰
â”œâ”€â”€ 3a. Gunicorn å¤š Worker å•Ÿå‹•é…ç½®
â”œâ”€â”€ 3b. DB é€£ç·šæ± å‹•æ…‹é…ç½®
â”œâ”€â”€ 3c. API å±¤é™æµ Middleware
â””â”€â”€ é è¨ˆæ•ˆæœï¼šçœŸæ­£å¯¦ç¾æ°´å¹³æ“´å±•

å„ªå…ˆç´š 4ï¼ˆéŒ¦ä¸Šæ·»èŠ±ï¼‰
â”œâ”€â”€ 4a. BackpressureMonitor æœå‹™
â”œâ”€â”€ 4b. Worker Pool æ•´åˆèƒŒå£“è¨ˆæ•¸
â””â”€â”€ é è¨ˆæ•ˆæœï¼šæ¥µç«¯è² è¼‰ä¸‹çš„ç©©å®šæ€§
```

### å¯¦æ–½åŸå‰‡

1. **å…ˆä¿®å–® Worker å•é¡Œå†é–‹å¤š Worker**ï¼šå¤š Worker ç’°å¢ƒæœƒæ”¾å¤§ç¾æœ‰çš„ race condition
2. **æ¼¸é€²å¼é·ç§»**ï¼šStateStore ä½¿ç”¨ Protocolï¼Œå¯ä»¥åœ¨ InMemory â†’ Redis é–“ç„¡ç¸«åˆ‡æ›
3. **å‘ä¸‹ç›¸å®¹**ï¼šæ‰€æœ‰æ”¹é€²é€éè¨­å®šé–‹é—œæ§åˆ¶ï¼Œä¸å½±éŸ¿é–‹ç™¼ç’°å¢ƒ
4. **æ¸¬è©¦å…ˆè¡Œ**ï¼šæ¯å€‹å„ªå…ˆç´šéƒ½æœ‰å°æ‡‰çš„æ¸¬è©¦æ¸…å–®

---

## è¨­å®šé …è®Šæ›´

### æ–°å¢ç’°å¢ƒè®Šæ•¸

```bash
# State Store é…ç½®
STATE_STORE_BACKEND=memory          # memory | redisï¼ˆé è¨­ memoryï¼Œç”Ÿç”¢æ”¹ redisï¼‰

# DB é€£ç·šæ± é…ç½®
DB_POOL_SIZE=5                      # æ¯ worker çš„åŸºæœ¬é€£ç·šæ•¸
DB_MAX_OVERFLOW=10                  # æ¯ worker çš„æœ€å¤§æº¢å‡ºé€£ç·šæ•¸

# API é™æµé…ç½®
API_RATE_LIMIT_ENABLED=false        # æ˜¯å¦å•Ÿç”¨ API é™æµï¼ˆç”Ÿç”¢è¨­ trueï¼‰
API_RATE_LIMIT_GLOBAL_PER_SEC=100   # å…¨å±€æ¯ç§’æœ€å¤§è«‹æ±‚æ•¸
API_RATE_LIMIT_IP_PER_MIN=60        # æ¯ IP æ¯åˆ†é˜æœ€å¤§è«‹æ±‚æ•¸

# Worker é…ç½®
UVICORN_WORKERS=1                   # Uvicorn worker æ•¸é‡ï¼ˆç”Ÿç”¢è¨­ 4ï¼‰

# èƒŒå£“é…ç½®
BACKPRESSURE_ENABLED=false          # æ˜¯å¦å•Ÿç”¨èƒŒå£“æ©Ÿåˆ¶
BACKPRESSURE_CAPACITY=10            # Worker Pool å®¹é‡
```

---

## æ¸¬è©¦æ¸…å–®

### å„ªå…ˆç´š 1 æ¸¬è©¦

- [ ] ContextSynchronizerï¼šåŒä¸€ context çš„ä¸¦è¡Œ sync è«‹æ±‚ä¸æœƒäº’ç›¸å¹²æ“¾
- [ ] ContextSynchronizerï¼šä¸åŒ context çš„ä¸¦è¡Œ sync è«‹æ±‚äº’ä¸é˜»å¡
- [ ] ContextSynchronizerï¼šlock çš„ double-check pattern æ­£ç¢ºé‹ä½œ
- [ ] ClaudeCoordinatorï¼š`_coordination_history` ä¸è¶…é maxlen
- [ ] SessionStateManagerï¼š`_state_cache` éæœŸè‡ªå‹•æ¸…ç†
- [ ] SessionStateManagerï¼š`_state_cache` è¶…é maxsize è‡ªå‹•æ·˜æ±°
- [ ] ClaudeSDKClientï¼š`_sessions` TTL éæœŸå¾Œè‡ªå‹•æ¸…ç†

### å„ªå…ˆç´š 2 æ¸¬è©¦

- [ ] InMemoryStateStoreï¼šæ‰€æœ‰ Protocol æ–¹æ³•æ­£ç¢ºå¯¦ç¾
- [ ] RedisStateStoreï¼šç‰ˆæœ¬è™Ÿçš„è®€å¯«ä¸€è‡´æ€§
- [ ] RedisStateStoreï¼šåˆ†æ•£å¼é–çš„äº’æ–¥æ€§ï¼ˆå…©å€‹ process ä¸èƒ½åŒæ™‚ç²å¾—åŒä¸€é–ï¼‰
- [ ] RedisStateStoreï¼šé–çš„è‡ªå‹•éæœŸï¼ˆé˜²æ­»é–ï¼‰
- [ ] RedisStateStoreï¼šSnapshot çš„ LTRIM æ­£ç¢ºé™åˆ¶æ•¸é‡
- [ ] ContextSynchronizer + RedisStateStoreï¼šç«¯åˆ°ç«¯ sync æµç¨‹
- [ ] ContextSynchronizer + RedisStateStoreï¼šç«¯åˆ°ç«¯ rollback æµç¨‹

### å„ªå…ˆç´š 3 æ¸¬è©¦

- [ ] å¤š Worker å•Ÿå‹•ï¼šæ‰€æœ‰ Worker èƒ½æ­£å¸¸è™•ç†è«‹æ±‚
- [ ] å¤š Workerï¼šä¸åŒ Worker çš„ Context ç‹€æ…‹é€é Redis åŒæ­¥
- [ ] API é™æµï¼šè¶…éå…¨å±€é™åˆ¶è¿”å› 429
- [ ] API é™æµï¼šè¶…é IP é™åˆ¶è¿”å› 429
- [ ] API é™æµï¼šæ­£å¸¸æµé‡ä¸è¢«èª¤æ“‹
- [ ] DB é€£ç·šæ± ï¼šå¤š Worker ç¸½é€£ç·šæ•¸ä¸è¶…é PostgreSQL max_connections

### å„ªå…ˆç´š 4 æ¸¬è©¦

- [ ] èƒŒå£“ç›£æ§ï¼šGREEN/YELLOW/RED ç´šåˆ¥åˆ¤æ–·æ­£ç¢º
- [ ] èƒŒå£“ç›£æ§ï¼šYELLOW ç´šåˆ¥ä¸‹ä½å„ªå…ˆç´šè«‹æ±‚è¢«æ‹’çµ•
- [ ] èƒŒå£“ç›£æ§ï¼šRED ç´šåˆ¥ä¸‹åªæœ‰ critical è«‹æ±‚é€šé
- [ ] Worker Poolï¼šæ´»å‹•è¨ˆæ•¸æ­£ç¢ºéå¢/éæ¸›

---

## é¢¨éšªè©•ä¼°

| é¢¨éšª | å½±éŸ¿ | æ©Ÿç‡ | ç·©è§£æªæ–½ |
|------|------|------|----------|
| Redis ä¸å¯ç”¨å°è‡´å…¨ç³»çµ±æ•…éšœ | é«˜ | ä½ | è‡ªå‹• fallback åˆ° InMemoryStateStore |
| Lock TTL éçŸ­å°è‡´æ“ä½œè¢«ä¸­æ–· | ä¸­ | ä¸­ | Lock çºŒæœŸæ©Ÿåˆ¶ + åˆç† TTL è¨­å®š |
| é™æµéåš´å½±éŸ¿æ­£å¸¸ç”¨æˆ¶ | ä¸­ | ä¸­ | è¨­å®šé …å¯èª¿æ•´ + ç›£æ§å‘Šè­¦ |
| å¤š Worker DB é€£ç·šè€—ç›¡ | é«˜ | ä¸­ | é€£ç·šæ± å¤§å°å…¬å¼è¨ˆç®— + ç›£æ§ |
| cachetools TTLCache æ¸…ç†ä¸åŠæ™‚ | ä½ | ä½ | å®šæœŸæ‰‹å‹•è§¸ç™¼æ¸…ç† |

---

## ç›¸é—œé€£çµ

- **æ¶æ§‹åˆ†æä¾†æº**: åŸºæ–¼ IPA Platform ä¸‰å±¤ä¸¦è¡Œæ¶æ§‹æ·±åº¦åˆ†æï¼ˆ2026-01-28 å°è©±è¨˜éŒ„ï¼‰
- **ç¾æœ‰åŸºç¤è¨­æ–½**: Redis å·²åœ¨ `backend/src/core/config.py:59-68` é…ç½®
- **ç¾æœ‰ Worker Pool**: `backend/src/core/performance/concurrent_optimizer.py:475+`
- **ç¾æœ‰ Rate Limit**: `backend/src/integrations/claude_sdk/hooks/rate_limit.py`
- **ç¾æœ‰ Context Sync**: `backend/src/integrations/hybrid/context/sync/synchronizer.py`

---

**è®Šæ›´è€…**: AI åŠ©æ‰‹ (Claude)
**å¯©æ ¸è€…**: Development Team
**ç‰ˆæœ¬**: v1.0
